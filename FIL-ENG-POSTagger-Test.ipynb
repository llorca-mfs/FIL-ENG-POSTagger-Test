{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc8b4b7d",
   "metadata": {},
   "source": [
    "# Testing Different Monolingual Filipino and English Part of Speech (POS) Taggers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62008160",
   "metadata": {},
   "source": [
    "### PLEASE TAKE NOTE!!!\n",
    "- [IMPORTANT] Always refresh kernel, clear outputs, and save before exiting to avoid git conflicts\n",
    "- Current formatting of this .ipynb is not final, will reformat when testing sample data from FilWordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e9a8e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lingua import Language, LanguageDetectorBuilder #used for language identification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfbc41b",
   "metadata": {},
   "source": [
    "Initialize language Identification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ebb1186",
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = [Language.ENGLISH, Language.TAGALOG]\n",
    "detector = LanguageDetectorBuilder.from_languages(*languages).build()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7935269c",
   "metadata": {},
   "source": [
    "Initialize the dataframe that will hold the sentences and its pos tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e071b57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_format = {\n",
    "    \"text\": [],\n",
    "    \"general_tags\": [],\n",
    "    \"specific_tags\": [],\n",
    "    \"token_tagset\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d488a09f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>general_tags</th>\n",
       "      <th>specific_tags</th>\n",
       "      <th>token_tagset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [text, general_tags, specific_tags, token_tagset]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>general_tags</th>\n",
       "      <th>specific_tags</th>\n",
       "      <th>token_tagset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [text, general_tags, specific_tags, token_tagset]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tagged_texts_combi1 = pd.DataFrame(df_format)\n",
    "tagged_texts_combi2 = pd.DataFrame(df_format)\n",
    "\n",
    "display(tagged_texts_combi1)\n",
    "display(tagged_texts_combi2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c92704",
   "metadata": {},
   "source": [
    "## Loading the test data\n",
    "\n",
    "Let us load the .json input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dcf2ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'token': 'San', 'tag': 'PROPN'}</td>\n",
       "      <td>{'token': 'Felipe', 'tag': 'PROPN'}</td>\n",
       "      <td>{'token': ',', 'tag': 'PUNC'}</td>\n",
       "      <td>{'token': 'kapalit', 'tag': 'CONJ'}</td>\n",
       "      <td>{'token': 'ng', 'tag': 'CONJ'}</td>\n",
       "      <td>{'token': 'P120', 'tag': 'CD'}</td>\n",
       "      <td>{'token': ',', 'tag': 'PUNC'}</td>\n",
       "      <td>{'token': '000', 'tag': 'CD'}</td>\n",
       "      <td>{'token': 'placement', 'tag': 'NOUN'}</td>\n",
       "      <td>{'token': 'fee', 'tag': 'NOUN'}</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'token': 'Pumanaw', 'tag': 'VB'}</td>\n",
       "      <td>{'token': 'ang', 'tag': 'DT'}</td>\n",
       "      <td>{'token': '65', 'tag': 'CD'}</td>\n",
       "      <td>{'token': 'taong', 'tag': 'NOUN'}</td>\n",
       "      <td>{'token': 'gulang', 'tag': 'NOUN'}</td>\n",
       "      <td>{'token': 'na', 'tag': 'CCP'}</td>\n",
       "      <td>{'token': 'mamamahayag', 'tag': 'NOUN'}</td>\n",
       "      <td>{'token': 'dahil', 'tag': 'CONJ'}</td>\n",
       "      <td>{'token': 'sa', 'tag': 'CONJ'}</td>\n",
       "      <td>{'token': 'cardiac', 'tag': 'NOUN'}</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'token': 'ang', 'tag': 'DT'}</td>\n",
       "      <td>{'token': 'bahagi', 'tag': 'NOUN'}</td>\n",
       "      <td>{'token': 'pa', 'tag': 'RB'}</td>\n",
       "      <td>{'token': 'ng', 'tag': 'CONJ'}</td>\n",
       "      <td>{'token': 'birthday', 'tag': 'NOUN'}</td>\n",
       "      <td>{'token': 'message', 'tag': 'NOUN'}</td>\n",
       "      <td>{'token': 'ni', 'tag': 'DT'}</td>\n",
       "      <td>{'token': 'Liza', 'tag': 'PROPN'}</td>\n",
       "      <td>{'token': 'para', 'tag': 'CONJ'}</td>\n",
       "      <td>{'token': 'kay', 'tag': 'DT'}</td>\n",
       "      <td>...</td>\n",
       "      <td>{'token': 'pati', 'tag': 'CONJ'}</td>\n",
       "      <td>{'token': 'na', 'tag': 'RB'}</td>\n",
       "      <td>{'token': 'rin', 'tag': 'RB'}</td>\n",
       "      <td>{'token': 'ng', 'tag': 'CONJ'}</td>\n",
       "      <td>{'token': 'kanilang', 'tag': 'PR'}</td>\n",
       "      <td>{'token': 'mga', 'tag': 'DT'}</td>\n",
       "      <td>{'token': 'kaibigan', 'tag': 'NOUN'}</td>\n",
       "      <td>{'token': 'sa', 'tag': 'CONJ'}</td>\n",
       "      <td>{'token': 'showbiz', 'tag': 'NOUN'}</td>\n",
       "      <td>{'token': '.', 'tag': 'PUNC'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'token': 'Noong', 'tag': 'RB'}</td>\n",
       "      <td>{'token': 'nakaraang', 'tag': 'VB'}</td>\n",
       "      <td>{'token': 'Nobyembre', 'tag': 'PROPN'}</td>\n",
       "      <td>{'token': ',', 'tag': 'PUNC'}</td>\n",
       "      <td>{'token': 'isang', 'tag': 'PR'}</td>\n",
       "      <td>{'token': 'tuta', 'tag': 'NOUN'}</td>\n",
       "      <td>{'token': 'na', 'tag': 'CCP'}</td>\n",
       "      <td>{'token': 'kakaiba', 'tag': 'JJ'}</td>\n",
       "      <td>{'token': 'rin', 'tag': 'RB'}</td>\n",
       "      <td>{'token': 'ang', 'tag': 'DT'}</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'token': 'Mali', 'tag': 'PROPN'}</td>\n",
       "      <td>{'token': 'yata', 'tag': 'RB'}</td>\n",
       "      <td>{'token': 'ang', 'tag': 'DT'}</td>\n",
       "      <td>{'token': 'naisip', 'tag': 'VB'}</td>\n",
       "      <td>{'token': 'kasi', 'tag': 'CONJ'}</td>\n",
       "      <td>{'token': 'namin', 'tag': 'PR'}</td>\n",
       "      <td>{'token': 'noon', 'tag': 'RB'}</td>\n",
       "      <td>{'token': 'na', 'tag': 'CCP'}</td>\n",
       "      <td>{'token': 'kung', 'tag': 'CONJ'}</td>\n",
       "      <td>{'token': 'sakaling', 'tag': 'RB'}</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'token': 'Kaya', 'tag': 'CONJ'}</td>\n",
       "      <td>{'token': 'kapag', 'tag': 'CONJ'}</td>\n",
       "      <td>{'token': 'nagsalubong', 'tag': 'VB'}</td>\n",
       "      <td>{'token': 'po', 'tag': 'RB'}</td>\n",
       "      <td>{'token': 'ang', 'tag': 'DT'}</td>\n",
       "      <td>{'token': 'dalawang', 'tag': 'JJ'}</td>\n",
       "      <td>{'token': 'hangin', 'tag': 'NOUN'}</td>\n",
       "      <td>{'token': 'na', 'tag': 'CCP'}</td>\n",
       "      <td>{'token': 'iyan', 'tag': 'PR'}</td>\n",
       "      <td>{'token': 'ay', 'tag': 'LM'}</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'token': 'Posible', 'tag': 'RB'}</td>\n",
       "      <td>{'token': 'ngayon', 'tag': 'RB'}</td>\n",
       "      <td>{'token': 'hapon', 'tag': 'RB'}</td>\n",
       "      <td>{'token': 'o', 'tag': 'CONJ'}</td>\n",
       "      <td>{'token': 'mamayang', 'tag': 'NOUN'}</td>\n",
       "      <td>{'token': 'gabi', 'tag': 'RB'}</td>\n",
       "      <td>{'token': 'ay', 'tag': 'LM'}</td>\n",
       "      <td>{'token': 'tumama', 'tag': 'VB'}</td>\n",
       "      <td>{'token': 'sa', 'tag': 'CONJ'}</td>\n",
       "      <td>{'token': 'kalupaan', 'tag': 'NOUN'}</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'token': 'Noong', 'tag': 'RB'}</td>\n",
       "      <td>{'token': 'tayo', 'tag': 'PR'}</td>\n",
       "      <td>{'token': 'ay', 'tag': 'LM'}</td>\n",
       "      <td>{'token': 'naging', 'tag': 'VB'}</td>\n",
       "      <td>{'token': 'Chief', 'tag': 'PROPN'}</td>\n",
       "      <td>{'token': 'PNP', 'tag': 'PROPN'}</td>\n",
       "      <td>{'token': 'at', 'tag': 'CONJ'}</td>\n",
       "      <td>{'token': 'dahil', 'tag': 'CONJ'}</td>\n",
       "      <td>{'token': 'sa', 'tag': 'CONJ'}</td>\n",
       "      <td>{'token': 'suporta', 'tag': 'NOUN'}</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'token': '``', 'tag': 'SYM'}</td>\n",
       "      <td>{'token': 'Nagsimula', 'tag': 'VB'}</td>\n",
       "      <td>{'token': 'ang', 'tag': 'CONJ'}</td>\n",
       "      <td>{'token': 'pagbabawal', 'tag': 'NOUN'}</td>\n",
       "      <td>{'token': 'kay', 'tag': 'DT'}</td>\n",
       "      <td>{'token': 'Gordon', 'tag': 'PROPN'}</td>\n",
       "      <td>{'token': 'na', 'tag': 'CCP'}</td>\n",
       "      <td>{'token': 'bumisita', 'tag': 'VB'}</td>\n",
       "      <td>{'token': 'sa', 'tag': 'CONJ'}</td>\n",
       "      <td>{'token': 'Atlanta', 'tag': 'PROPN'}</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'token': 'Ayon', 'tag': 'RB'}</td>\n",
       "      <td>{'token': 'kay', 'tag': 'DT'}</td>\n",
       "      <td>{'token': 'Director', 'tag': 'PROPN'}</td>\n",
       "      <td>{'token': 'General', 'tag': 'PROPN'}</td>\n",
       "      <td>{'token': 'Avelino', 'tag': 'PROPN'}</td>\n",
       "      <td>{'token': 'Razon', 'tag': 'PROPN'}</td>\n",
       "      <td>{'token': 'Jnr', 'tag': 'PROPN'}</td>\n",
       "      <td>{'token': ',', 'tag': 'PUNC'}</td>\n",
       "      <td>{'token': 'hepe', 'tag': 'NOUN'}</td>\n",
       "      <td>{'token': 'ng', 'tag': 'CONJ'}</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'token': 'Intellectually', 'tag': 'RB'}</td>\n",
       "      <td>{'token': 'akin', 'tag': 'PR'}</td>\n",
       "      <td>{'token': 'ang', 'tag': 'DT'}</td>\n",
       "      <td>{'token': 'Mister', 'tag': 'PROPN'}</td>\n",
       "      <td>{'token': 'Philippines', 'tag': 'PROPN'}</td>\n",
       "      <td>{'token': ',', 'tag': 'PUNC'}</td>\n",
       "      <td>{'token': '``', 'tag': 'SYM'}</td>\n",
       "      <td>{'token': 'diin', 'tag': 'VB'}</td>\n",
       "      <td>{'token': 'pa', 'tag': 'RB'}</td>\n",
       "      <td>{'token': 'niya', 'tag': 'NOUN'}</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'token': 'Gaya', 'tag': 'JJ'}</td>\n",
       "      <td>{'token': 'ng', 'tag': 'CONJ'}</td>\n",
       "      <td>{'token': 'pakiusap', 'tag': 'NOUN'}</td>\n",
       "      <td>{'token': 'ng', 'tag': 'CONJ'}</td>\n",
       "      <td>{'token': 'ating', 'tag': 'PR'}</td>\n",
       "      <td>{'token': 'mahal', 'tag': 'PR'}</td>\n",
       "      <td>{'token': 'na', 'tag': 'CCP'}</td>\n",
       "      <td>{'token': 'Pangulong', 'tag': 'PROPN'}</td>\n",
       "      <td>{'token': 'Duterte', 'tag': 'PROPN'}</td>\n",
       "      <td>{'token': ',', 'tag': 'PUNC'}</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'token': 'Unang', 'tag': 'JJ'}</td>\n",
       "      <td>{'token': 'ipinalabas', 'tag': 'VB'}</td>\n",
       "      <td>{'token': 'ang', 'tag': 'DT'}</td>\n",
       "      <td>{'token': 'longest-running', 'tag': 'JJ'}</td>\n",
       "      <td>{'token': 'drama', 'tag': 'NOUN'}</td>\n",
       "      <td>{'token': 'antho-logy', 'tag': 'NOUN'}</td>\n",
       "      <td>{'token': 'sa', 'tag': 'CONJ'}</td>\n",
       "      <td>{'token': 'Asya', 'tag': 'PROPN'}</td>\n",
       "      <td>{'token': 'noong', 'tag': 'RB'}</td>\n",
       "      <td>{'token': '1991', 'tag': 'CD'}</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'token': 'Ang', 'tag': 'DT'}</td>\n",
       "      <td>{'token': 'bongga', 'tag': 'JJ'}</td>\n",
       "      <td>{'token': 'nga', 'tag': 'RB'}</td>\n",
       "      <td>{'token': 'ng', 'tag': 'CONJ'}</td>\n",
       "      <td>{'token': 'movie', 'tag': 'NOUN'}</td>\n",
       "      <td>{'token': ',', 'tag': 'PUNC'}</td>\n",
       "      <td>{'token': 'na', 'tag': 'CCP'}</td>\n",
       "      <td>{'token': 'ganun', 'tag': 'PR'}</td>\n",
       "      <td>{'token': 'karami', 'tag': 'PR'}</td>\n",
       "      <td>{'token': 'agad', 'tag': 'RB'}</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'token': 'Hindi', 'tag': 'RB'}</td>\n",
       "      <td>{'token': 'naman', 'tag': 'RB'}</td>\n",
       "      <td>{'token': 'naisagawa', 'tag': 'VB'}</td>\n",
       "      <td>{'token': 'ang', 'tag': 'DT'}</td>\n",
       "      <td>{'token': 'operasyon', 'tag': 'NOUN'}</td>\n",
       "      <td>{'token': 'para', 'tag': 'CONJ'}</td>\n",
       "      <td>{'token': 'mapaghiwalay', 'tag': 'VB'}</td>\n",
       "      <td>{'token': 'sa', 'tag': 'CONJ'}</td>\n",
       "      <td>{'token': 'nagkakadikit-dikit', 'tag': 'VB'}</td>\n",
       "      <td>{'token': 'niyang', 'tag': 'PR'}</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'token': 'Ngunit', 'tag': 'CONJ'}</td>\n",
       "      <td>{'token': 'kung', 'tag': 'CONJ'}</td>\n",
       "      <td>{'token': 'may', 'tag': 'VB'}</td>\n",
       "      <td>{'token': 'tunay', 'tag': 'JJ'}</td>\n",
       "      <td>{'token': 'na', 'tag': 'CCP'}</td>\n",
       "      <td>{'token': 'makikitang', 'tag': 'VB'}</td>\n",
       "      <td>{'token': 'umiipit', 'tag': 'VB'}</td>\n",
       "      <td>{'token': 'sa', 'tag': 'CONJ'}</td>\n",
       "      <td>{'token': 'nerve', 'tag': 'NOUN'}</td>\n",
       "      <td>{'token': 'o', 'tag': 'CONJ'}</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{'token': 'Ipinagdiriwang', 'tag': 'VB'}</td>\n",
       "      <td>{'token': 'ng', 'tag': 'CONJ'}</td>\n",
       "      <td>{'token': 'BFP', 'tag': 'PROPN'}</td>\n",
       "      <td>{'token': 'ang', 'tag': 'DT'}</td>\n",
       "      <td>{'token': 'Fire', 'tag': 'PROPN'}</td>\n",
       "      <td>{'token': 'Prevention', 'tag': 'PROPN'}</td>\n",
       "      <td>{'token': 'Month', 'tag': 'PROPN'}</td>\n",
       "      <td>{'token': 'tuwing', 'tag': 'RB'}</td>\n",
       "      <td>{'token': 'Marso', 'tag': 'PROPN'}</td>\n",
       "      <td>{'token': 'dahil', 'tag': 'CONJ'}</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'token': 'Maliban', 'tag': 'CONJ'}</td>\n",
       "      <td>{'token': 'sa', 'tag': 'CONJ'}</td>\n",
       "      <td>{'token': 'Dito', 'tag': 'PROPN'}</td>\n",
       "      <td>{'token': 'at', 'tag': 'CONJ'}</td>\n",
       "      <td>{'token': 'Converge', 'tag': 'PROPN'}</td>\n",
       "      <td>{'token': ',', 'tag': 'PUNC'}</td>\n",
       "      <td>{'token': 'sinabi', 'tag': 'VB'}</td>\n",
       "      <td>{'token': 'ng', 'tag': 'CONJ'}</td>\n",
       "      <td>{'token': 'hepe', 'tag': 'NOUN'}</td>\n",
       "      <td>{'token': 'ng', 'tag': 'CONJ'}</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{'token': 'Pero', 'tag': 'CONJ'}</td>\n",
       "      <td>{'token': 'kamakailan', 'tag': 'RB'}</td>\n",
       "      <td>{'token': 'ay', 'tag': 'LM'}</td>\n",
       "      <td>{'token': 'mas', 'tag': 'JJ'}</td>\n",
       "      <td>{'token': 'tinutukan', 'tag': 'VB'}</td>\n",
       "      <td>{'token': 'ito', 'tag': 'PR'}</td>\n",
       "      <td>{'token': 'dahil', 'tag': 'CONJ'}</td>\n",
       "      <td>{'token': 'sa', 'tag': 'CONJ'}</td>\n",
       "      <td>{'token': 'paghahanap', 'tag': 'NOUN'}</td>\n",
       "      <td>{'token': 'sa', 'tag': 'CONJ'}</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>{'token': '``', 'tag': 'SYM'}</td>\n",
       "      <td>{'token': 'Bukod', 'tag': 'CONJ'}</td>\n",
       "      <td>{'token': 'sa', 'tag': 'CONJ'}</td>\n",
       "      <td>{'token': 'last', 'tag': 'JJ'}</td>\n",
       "      <td>{'token': 'year', 'tag': 'NOUN'}</td>\n",
       "      <td>{'token': 'na', 'tag': 'CCP'}</td>\n",
       "      <td>{'token': 'kasama', 'tag': 'CONJ'}</td>\n",
       "      <td>{'token': 'ko', 'tag': 'PR'}</td>\n",
       "      <td>{'token': 'ang', 'tag': 'DT'}</td>\n",
       "      <td>{'token': 'mga', 'tag': 'DT'}</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>{'token': 'Pinaalalahanan', 'tag': 'VB'}</td>\n",
       "      <td>{'token': 'din', 'tag': 'RB'}</td>\n",
       "      <td>{'token': 'ng', 'tag': 'CONJ'}</td>\n",
       "      <td>{'token': 'Pangulo', 'tag': 'PROPN'}</td>\n",
       "      <td>{'token': 'ang', 'tag': 'DT'}</td>\n",
       "      <td>{'token': 'militar', 'tag': 'NOUN'}</td>\n",
       "      <td>{'token': 'sa', 'tag': 'CONJ'}</td>\n",
       "      <td>{'token': 'itinakda', 'tag': 'VB'}</td>\n",
       "      <td>{'token': 'niyang', 'tag': 'PR'}</td>\n",
       "      <td>{'token': 'taning', 'tag': 'NOUN'}</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>{'token': '``', 'tag': 'SYM'}</td>\n",
       "      <td>{'token': 'At', 'tag': 'CONJ'}</td>\n",
       "      <td>{'token': 'kinaumagahan', 'tag': 'NOUN'}</td>\n",
       "      <td>{'token': 'nga', 'tag': 'RB'}</td>\n",
       "      <td>{'token': ',', 'tag': 'PUNC'}</td>\n",
       "      <td>{'token': 'habang', 'tag': 'CONJ'}</td>\n",
       "      <td>{'token': 'tulog', 'tag': 'NOUN'}</td>\n",
       "      <td>{'token': 'na', 'tag': 'CCP'}</td>\n",
       "      <td>{'token': 'tulog', 'tag': 'NOUN'}</td>\n",
       "      <td>{'token': 'pa', 'tag': 'RB'}</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>{'token': '``', 'tag': 'SYM'}</td>\n",
       "      <td>{'token': 'Pero', 'tag': 'CONJ'}</td>\n",
       "      <td>{'token': 'hindi', 'tag': 'RB'}</td>\n",
       "      <td>{'token': 'pa', 'tag': 'RB'}</td>\n",
       "      <td>{'token': 'rin', 'tag': 'RB'}</td>\n",
       "      <td>{'token': 'napigilan', 'tag': 'VB'}</td>\n",
       "      <td>{'token': 'ng', 'tag': 'CONJ'}</td>\n",
       "      <td>{'token': 'aktor', 'tag': 'NOUN'}</td>\n",
       "      <td>{'token': 'ang', 'tag': 'DT'}</td>\n",
       "      <td>{'token': 'kanyang', 'tag': 'PR'}</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>{'token': 'Photo', 'tag': 'PROPN'}</td>\n",
       "      <td>{'token': 'courtesy', 'tag': 'NOUN'}</td>\n",
       "      <td>{'token': ':', 'tag': 'SYM'}</td>\n",
       "      <td>{'token': 'PNP', 'tag': 'PROPN'}</td>\n",
       "      <td>{'token': 'Quezon', 'tag': 'PROPN'}</td>\n",
       "      <td>{'token': 'Nang', 'tag': 'RB'}</td>\n",
       "      <td>{'token': 'magka', 'tag': 'VB'}</td>\n",
       "      <td>{'token': 'abutan', 'tag': 'VB'}</td>\n",
       "      <td>{'token': 'na', 'tag': 'CCP'}</td>\n",
       "      <td>{'token': 'raw', 'tag': 'RB'}</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>{'token': 'Mahirap', 'tag': 'RB'}</td>\n",
       "      <td>{'token': 'daw', 'tag': 'RB'}</td>\n",
       "      <td>{'token': 'ang', 'tag': 'DT'}</td>\n",
       "      <td>{'token': 'mag-isa', 'tag': 'VB'}</td>\n",
       "      <td>{'token': 'ka', 'tag': 'PR'}</td>\n",
       "      <td>{'token': 'lang', 'tag': 'RB'}</td>\n",
       "      <td>{'token': 'sa', 'tag': 'CONJ'}</td>\n",
       "      <td>{'token': 'bahay', 'tag': 'NOUN'}</td>\n",
       "      <td>{'token': 'at', 'tag': 'CONJ'}</td>\n",
       "      <td>{'token': 'walang', 'tag': 'JJ'}</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          0   \\\n",
       "0           {'token': 'San', 'tag': 'PROPN'}   \n",
       "1          {'token': 'Pumanaw', 'tag': 'VB'}   \n",
       "2              {'token': 'ang', 'tag': 'DT'}   \n",
       "3            {'token': 'Noong', 'tag': 'RB'}   \n",
       "4          {'token': 'Mali', 'tag': 'PROPN'}   \n",
       "5           {'token': 'Kaya', 'tag': 'CONJ'}   \n",
       "6          {'token': 'Posible', 'tag': 'RB'}   \n",
       "7            {'token': 'Noong', 'tag': 'RB'}   \n",
       "8              {'token': '``', 'tag': 'SYM'}   \n",
       "9             {'token': 'Ayon', 'tag': 'RB'}   \n",
       "10  {'token': 'Intellectually', 'tag': 'RB'}   \n",
       "11            {'token': 'Gaya', 'tag': 'JJ'}   \n",
       "12           {'token': 'Unang', 'tag': 'JJ'}   \n",
       "13             {'token': 'Ang', 'tag': 'DT'}   \n",
       "14           {'token': 'Hindi', 'tag': 'RB'}   \n",
       "15        {'token': 'Ngunit', 'tag': 'CONJ'}   \n",
       "16  {'token': 'Ipinagdiriwang', 'tag': 'VB'}   \n",
       "17       {'token': 'Maliban', 'tag': 'CONJ'}   \n",
       "18          {'token': 'Pero', 'tag': 'CONJ'}   \n",
       "19             {'token': '``', 'tag': 'SYM'}   \n",
       "20  {'token': 'Pinaalalahanan', 'tag': 'VB'}   \n",
       "21             {'token': '``', 'tag': 'SYM'}   \n",
       "22             {'token': '``', 'tag': 'SYM'}   \n",
       "23        {'token': 'Photo', 'tag': 'PROPN'}   \n",
       "24         {'token': 'Mahirap', 'tag': 'RB'}   \n",
       "\n",
       "                                      1   \\\n",
       "0    {'token': 'Felipe', 'tag': 'PROPN'}   \n",
       "1          {'token': 'ang', 'tag': 'DT'}   \n",
       "2     {'token': 'bahagi', 'tag': 'NOUN'}   \n",
       "3    {'token': 'nakaraang', 'tag': 'VB'}   \n",
       "4         {'token': 'yata', 'tag': 'RB'}   \n",
       "5      {'token': 'kapag', 'tag': 'CONJ'}   \n",
       "6       {'token': 'ngayon', 'tag': 'RB'}   \n",
       "7         {'token': 'tayo', 'tag': 'PR'}   \n",
       "8    {'token': 'Nagsimula', 'tag': 'VB'}   \n",
       "9          {'token': 'kay', 'tag': 'DT'}   \n",
       "10        {'token': 'akin', 'tag': 'PR'}   \n",
       "11        {'token': 'ng', 'tag': 'CONJ'}   \n",
       "12  {'token': 'ipinalabas', 'tag': 'VB'}   \n",
       "13      {'token': 'bongga', 'tag': 'JJ'}   \n",
       "14       {'token': 'naman', 'tag': 'RB'}   \n",
       "15      {'token': 'kung', 'tag': 'CONJ'}   \n",
       "16        {'token': 'ng', 'tag': 'CONJ'}   \n",
       "17        {'token': 'sa', 'tag': 'CONJ'}   \n",
       "18  {'token': 'kamakailan', 'tag': 'RB'}   \n",
       "19     {'token': 'Bukod', 'tag': 'CONJ'}   \n",
       "20         {'token': 'din', 'tag': 'RB'}   \n",
       "21        {'token': 'At', 'tag': 'CONJ'}   \n",
       "22      {'token': 'Pero', 'tag': 'CONJ'}   \n",
       "23  {'token': 'courtesy', 'tag': 'NOUN'}   \n",
       "24         {'token': 'daw', 'tag': 'RB'}   \n",
       "\n",
       "                                          2   \\\n",
       "0              {'token': ',', 'tag': 'PUNC'}   \n",
       "1               {'token': '65', 'tag': 'CD'}   \n",
       "2               {'token': 'pa', 'tag': 'RB'}   \n",
       "3     {'token': 'Nobyembre', 'tag': 'PROPN'}   \n",
       "4              {'token': 'ang', 'tag': 'DT'}   \n",
       "5      {'token': 'nagsalubong', 'tag': 'VB'}   \n",
       "6            {'token': 'hapon', 'tag': 'RB'}   \n",
       "7               {'token': 'ay', 'tag': 'LM'}   \n",
       "8            {'token': 'ang', 'tag': 'CONJ'}   \n",
       "9      {'token': 'Director', 'tag': 'PROPN'}   \n",
       "10             {'token': 'ang', 'tag': 'DT'}   \n",
       "11      {'token': 'pakiusap', 'tag': 'NOUN'}   \n",
       "12             {'token': 'ang', 'tag': 'DT'}   \n",
       "13             {'token': 'nga', 'tag': 'RB'}   \n",
       "14       {'token': 'naisagawa', 'tag': 'VB'}   \n",
       "15             {'token': 'may', 'tag': 'VB'}   \n",
       "16          {'token': 'BFP', 'tag': 'PROPN'}   \n",
       "17         {'token': 'Dito', 'tag': 'PROPN'}   \n",
       "18              {'token': 'ay', 'tag': 'LM'}   \n",
       "19            {'token': 'sa', 'tag': 'CONJ'}   \n",
       "20            {'token': 'ng', 'tag': 'CONJ'}   \n",
       "21  {'token': 'kinaumagahan', 'tag': 'NOUN'}   \n",
       "22           {'token': 'hindi', 'tag': 'RB'}   \n",
       "23              {'token': ':', 'tag': 'SYM'}   \n",
       "24             {'token': 'ang', 'tag': 'DT'}   \n",
       "\n",
       "                                           3   \\\n",
       "0         {'token': 'kapalit', 'tag': 'CONJ'}   \n",
       "1           {'token': 'taong', 'tag': 'NOUN'}   \n",
       "2              {'token': 'ng', 'tag': 'CONJ'}   \n",
       "3               {'token': ',', 'tag': 'PUNC'}   \n",
       "4            {'token': 'naisip', 'tag': 'VB'}   \n",
       "5                {'token': 'po', 'tag': 'RB'}   \n",
       "6               {'token': 'o', 'tag': 'CONJ'}   \n",
       "7            {'token': 'naging', 'tag': 'VB'}   \n",
       "8      {'token': 'pagbabawal', 'tag': 'NOUN'}   \n",
       "9        {'token': 'General', 'tag': 'PROPN'}   \n",
       "10        {'token': 'Mister', 'tag': 'PROPN'}   \n",
       "11             {'token': 'ng', 'tag': 'CONJ'}   \n",
       "12  {'token': 'longest-running', 'tag': 'JJ'}   \n",
       "13             {'token': 'ng', 'tag': 'CONJ'}   \n",
       "14              {'token': 'ang', 'tag': 'DT'}   \n",
       "15            {'token': 'tunay', 'tag': 'JJ'}   \n",
       "16              {'token': 'ang', 'tag': 'DT'}   \n",
       "17             {'token': 'at', 'tag': 'CONJ'}   \n",
       "18              {'token': 'mas', 'tag': 'JJ'}   \n",
       "19             {'token': 'last', 'tag': 'JJ'}   \n",
       "20       {'token': 'Pangulo', 'tag': 'PROPN'}   \n",
       "21              {'token': 'nga', 'tag': 'RB'}   \n",
       "22               {'token': 'pa', 'tag': 'RB'}   \n",
       "23           {'token': 'PNP', 'tag': 'PROPN'}   \n",
       "24          {'token': 'mag-isa', 'tag': 'VB'}   \n",
       "\n",
       "                                          4   \\\n",
       "0             {'token': 'ng', 'tag': 'CONJ'}   \n",
       "1         {'token': 'gulang', 'tag': 'NOUN'}   \n",
       "2       {'token': 'birthday', 'tag': 'NOUN'}   \n",
       "3            {'token': 'isang', 'tag': 'PR'}   \n",
       "4           {'token': 'kasi', 'tag': 'CONJ'}   \n",
       "5              {'token': 'ang', 'tag': 'DT'}   \n",
       "6       {'token': 'mamayang', 'tag': 'NOUN'}   \n",
       "7         {'token': 'Chief', 'tag': 'PROPN'}   \n",
       "8              {'token': 'kay', 'tag': 'DT'}   \n",
       "9       {'token': 'Avelino', 'tag': 'PROPN'}   \n",
       "10  {'token': 'Philippines', 'tag': 'PROPN'}   \n",
       "11           {'token': 'ating', 'tag': 'PR'}   \n",
       "12         {'token': 'drama', 'tag': 'NOUN'}   \n",
       "13         {'token': 'movie', 'tag': 'NOUN'}   \n",
       "14     {'token': 'operasyon', 'tag': 'NOUN'}   \n",
       "15             {'token': 'na', 'tag': 'CCP'}   \n",
       "16         {'token': 'Fire', 'tag': 'PROPN'}   \n",
       "17     {'token': 'Converge', 'tag': 'PROPN'}   \n",
       "18       {'token': 'tinutukan', 'tag': 'VB'}   \n",
       "19          {'token': 'year', 'tag': 'NOUN'}   \n",
       "20             {'token': 'ang', 'tag': 'DT'}   \n",
       "21             {'token': ',', 'tag': 'PUNC'}   \n",
       "22             {'token': 'rin', 'tag': 'RB'}   \n",
       "23       {'token': 'Quezon', 'tag': 'PROPN'}   \n",
       "24              {'token': 'ka', 'tag': 'PR'}   \n",
       "\n",
       "                                         5   \\\n",
       "0            {'token': 'P120', 'tag': 'CD'}   \n",
       "1             {'token': 'na', 'tag': 'CCP'}   \n",
       "2       {'token': 'message', 'tag': 'NOUN'}   \n",
       "3          {'token': 'tuta', 'tag': 'NOUN'}   \n",
       "4           {'token': 'namin', 'tag': 'PR'}   \n",
       "5        {'token': 'dalawang', 'tag': 'JJ'}   \n",
       "6            {'token': 'gabi', 'tag': 'RB'}   \n",
       "7          {'token': 'PNP', 'tag': 'PROPN'}   \n",
       "8       {'token': 'Gordon', 'tag': 'PROPN'}   \n",
       "9        {'token': 'Razon', 'tag': 'PROPN'}   \n",
       "10            {'token': ',', 'tag': 'PUNC'}   \n",
       "11          {'token': 'mahal', 'tag': 'PR'}   \n",
       "12   {'token': 'antho-logy', 'tag': 'NOUN'}   \n",
       "13            {'token': ',', 'tag': 'PUNC'}   \n",
       "14         {'token': 'para', 'tag': 'CONJ'}   \n",
       "15     {'token': 'makikitang', 'tag': 'VB'}   \n",
       "16  {'token': 'Prevention', 'tag': 'PROPN'}   \n",
       "17            {'token': ',', 'tag': 'PUNC'}   \n",
       "18            {'token': 'ito', 'tag': 'PR'}   \n",
       "19            {'token': 'na', 'tag': 'CCP'}   \n",
       "20      {'token': 'militar', 'tag': 'NOUN'}   \n",
       "21       {'token': 'habang', 'tag': 'CONJ'}   \n",
       "22      {'token': 'napigilan', 'tag': 'VB'}   \n",
       "23           {'token': 'Nang', 'tag': 'RB'}   \n",
       "24           {'token': 'lang', 'tag': 'RB'}   \n",
       "\n",
       "                                         6   \\\n",
       "0             {'token': ',', 'tag': 'PUNC'}   \n",
       "1   {'token': 'mamamahayag', 'tag': 'NOUN'}   \n",
       "2              {'token': 'ni', 'tag': 'DT'}   \n",
       "3             {'token': 'na', 'tag': 'CCP'}   \n",
       "4            {'token': 'noon', 'tag': 'RB'}   \n",
       "5        {'token': 'hangin', 'tag': 'NOUN'}   \n",
       "6              {'token': 'ay', 'tag': 'LM'}   \n",
       "7            {'token': 'at', 'tag': 'CONJ'}   \n",
       "8             {'token': 'na', 'tag': 'CCP'}   \n",
       "9          {'token': 'Jnr', 'tag': 'PROPN'}   \n",
       "10            {'token': '``', 'tag': 'SYM'}   \n",
       "11            {'token': 'na', 'tag': 'CCP'}   \n",
       "12           {'token': 'sa', 'tag': 'CONJ'}   \n",
       "13            {'token': 'na', 'tag': 'CCP'}   \n",
       "14   {'token': 'mapaghiwalay', 'tag': 'VB'}   \n",
       "15        {'token': 'umiipit', 'tag': 'VB'}   \n",
       "16       {'token': 'Month', 'tag': 'PROPN'}   \n",
       "17         {'token': 'sinabi', 'tag': 'VB'}   \n",
       "18        {'token': 'dahil', 'tag': 'CONJ'}   \n",
       "19       {'token': 'kasama', 'tag': 'CONJ'}   \n",
       "20           {'token': 'sa', 'tag': 'CONJ'}   \n",
       "21        {'token': 'tulog', 'tag': 'NOUN'}   \n",
       "22           {'token': 'ng', 'tag': 'CONJ'}   \n",
       "23          {'token': 'magka', 'tag': 'VB'}   \n",
       "24           {'token': 'sa', 'tag': 'CONJ'}   \n",
       "\n",
       "                                        7   \\\n",
       "0            {'token': '000', 'tag': 'CD'}   \n",
       "1        {'token': 'dahil', 'tag': 'CONJ'}   \n",
       "2        {'token': 'Liza', 'tag': 'PROPN'}   \n",
       "3        {'token': 'kakaiba', 'tag': 'JJ'}   \n",
       "4            {'token': 'na', 'tag': 'CCP'}   \n",
       "5            {'token': 'na', 'tag': 'CCP'}   \n",
       "6         {'token': 'tumama', 'tag': 'VB'}   \n",
       "7        {'token': 'dahil', 'tag': 'CONJ'}   \n",
       "8       {'token': 'bumisita', 'tag': 'VB'}   \n",
       "9            {'token': ',', 'tag': 'PUNC'}   \n",
       "10          {'token': 'diin', 'tag': 'VB'}   \n",
       "11  {'token': 'Pangulong', 'tag': 'PROPN'}   \n",
       "12       {'token': 'Asya', 'tag': 'PROPN'}   \n",
       "13         {'token': 'ganun', 'tag': 'PR'}   \n",
       "14          {'token': 'sa', 'tag': 'CONJ'}   \n",
       "15          {'token': 'sa', 'tag': 'CONJ'}   \n",
       "16        {'token': 'tuwing', 'tag': 'RB'}   \n",
       "17          {'token': 'ng', 'tag': 'CONJ'}   \n",
       "18          {'token': 'sa', 'tag': 'CONJ'}   \n",
       "19            {'token': 'ko', 'tag': 'PR'}   \n",
       "20      {'token': 'itinakda', 'tag': 'VB'}   \n",
       "21           {'token': 'na', 'tag': 'CCP'}   \n",
       "22       {'token': 'aktor', 'tag': 'NOUN'}   \n",
       "23        {'token': 'abutan', 'tag': 'VB'}   \n",
       "24       {'token': 'bahay', 'tag': 'NOUN'}   \n",
       "\n",
       "                                              8   \\\n",
       "0          {'token': 'placement', 'tag': 'NOUN'}   \n",
       "1                 {'token': 'sa', 'tag': 'CONJ'}   \n",
       "2               {'token': 'para', 'tag': 'CONJ'}   \n",
       "3                  {'token': 'rin', 'tag': 'RB'}   \n",
       "4               {'token': 'kung', 'tag': 'CONJ'}   \n",
       "5                 {'token': 'iyan', 'tag': 'PR'}   \n",
       "6                 {'token': 'sa', 'tag': 'CONJ'}   \n",
       "7                 {'token': 'sa', 'tag': 'CONJ'}   \n",
       "8                 {'token': 'sa', 'tag': 'CONJ'}   \n",
       "9               {'token': 'hepe', 'tag': 'NOUN'}   \n",
       "10                  {'token': 'pa', 'tag': 'RB'}   \n",
       "11          {'token': 'Duterte', 'tag': 'PROPN'}   \n",
       "12               {'token': 'noong', 'tag': 'RB'}   \n",
       "13              {'token': 'karami', 'tag': 'PR'}   \n",
       "14  {'token': 'nagkakadikit-dikit', 'tag': 'VB'}   \n",
       "15             {'token': 'nerve', 'tag': 'NOUN'}   \n",
       "16            {'token': 'Marso', 'tag': 'PROPN'}   \n",
       "17              {'token': 'hepe', 'tag': 'NOUN'}   \n",
       "18        {'token': 'paghahanap', 'tag': 'NOUN'}   \n",
       "19                 {'token': 'ang', 'tag': 'DT'}   \n",
       "20              {'token': 'niyang', 'tag': 'PR'}   \n",
       "21             {'token': 'tulog', 'tag': 'NOUN'}   \n",
       "22                 {'token': 'ang', 'tag': 'DT'}   \n",
       "23                 {'token': 'na', 'tag': 'CCP'}   \n",
       "24                {'token': 'at', 'tag': 'CONJ'}   \n",
       "\n",
       "                                      9   ...  \\\n",
       "0        {'token': 'fee', 'tag': 'NOUN'}  ...   \n",
       "1    {'token': 'cardiac', 'tag': 'NOUN'}  ...   \n",
       "2          {'token': 'kay', 'tag': 'DT'}  ...   \n",
       "3          {'token': 'ang', 'tag': 'DT'}  ...   \n",
       "4     {'token': 'sakaling', 'tag': 'RB'}  ...   \n",
       "5           {'token': 'ay', 'tag': 'LM'}  ...   \n",
       "6   {'token': 'kalupaan', 'tag': 'NOUN'}  ...   \n",
       "7    {'token': 'suporta', 'tag': 'NOUN'}  ...   \n",
       "8   {'token': 'Atlanta', 'tag': 'PROPN'}  ...   \n",
       "9         {'token': 'ng', 'tag': 'CONJ'}  ...   \n",
       "10      {'token': 'niya', 'tag': 'NOUN'}  ...   \n",
       "11         {'token': ',', 'tag': 'PUNC'}  ...   \n",
       "12        {'token': '1991', 'tag': 'CD'}  ...   \n",
       "13        {'token': 'agad', 'tag': 'RB'}  ...   \n",
       "14      {'token': 'niyang', 'tag': 'PR'}  ...   \n",
       "15         {'token': 'o', 'tag': 'CONJ'}  ...   \n",
       "16     {'token': 'dahil', 'tag': 'CONJ'}  ...   \n",
       "17        {'token': 'ng', 'tag': 'CONJ'}  ...   \n",
       "18        {'token': 'sa', 'tag': 'CONJ'}  ...   \n",
       "19         {'token': 'mga', 'tag': 'DT'}  ...   \n",
       "20    {'token': 'taning', 'tag': 'NOUN'}  ...   \n",
       "21          {'token': 'pa', 'tag': 'RB'}  ...   \n",
       "22     {'token': 'kanyang', 'tag': 'PR'}  ...   \n",
       "23         {'token': 'raw', 'tag': 'RB'}  ...   \n",
       "24      {'token': 'walang', 'tag': 'JJ'}  ...   \n",
       "\n",
       "                                  58                            59  \\\n",
       "0                               None                          None   \n",
       "1                               None                          None   \n",
       "2   {'token': 'pati', 'tag': 'CONJ'}  {'token': 'na', 'tag': 'RB'}   \n",
       "3                               None                          None   \n",
       "4                               None                          None   \n",
       "5                               None                          None   \n",
       "6                               None                          None   \n",
       "7                               None                          None   \n",
       "8                               None                          None   \n",
       "9                               None                          None   \n",
       "10                              None                          None   \n",
       "11                              None                          None   \n",
       "12                              None                          None   \n",
       "13                              None                          None   \n",
       "14                              None                          None   \n",
       "15                              None                          None   \n",
       "16                              None                          None   \n",
       "17                              None                          None   \n",
       "18                              None                          None   \n",
       "19                              None                          None   \n",
       "20                              None                          None   \n",
       "21                              None                          None   \n",
       "22                              None                          None   \n",
       "23                              None                          None   \n",
       "24                              None                          None   \n",
       "\n",
       "                               60                              61  \\\n",
       "0                            None                            None   \n",
       "1                            None                            None   \n",
       "2   {'token': 'rin', 'tag': 'RB'}  {'token': 'ng', 'tag': 'CONJ'}   \n",
       "3                            None                            None   \n",
       "4                            None                            None   \n",
       "5                            None                            None   \n",
       "6                            None                            None   \n",
       "7                            None                            None   \n",
       "8                            None                            None   \n",
       "9                            None                            None   \n",
       "10                           None                            None   \n",
       "11                           None                            None   \n",
       "12                           None                            None   \n",
       "13                           None                            None   \n",
       "14                           None                            None   \n",
       "15                           None                            None   \n",
       "16                           None                            None   \n",
       "17                           None                            None   \n",
       "18                           None                            None   \n",
       "19                           None                            None   \n",
       "20                           None                            None   \n",
       "21                           None                            None   \n",
       "22                           None                            None   \n",
       "23                           None                            None   \n",
       "24                           None                            None   \n",
       "\n",
       "                                    62                             63  \\\n",
       "0                                 None                           None   \n",
       "1                                 None                           None   \n",
       "2   {'token': 'kanilang', 'tag': 'PR'}  {'token': 'mga', 'tag': 'DT'}   \n",
       "3                                 None                           None   \n",
       "4                                 None                           None   \n",
       "5                                 None                           None   \n",
       "6                                 None                           None   \n",
       "7                                 None                           None   \n",
       "8                                 None                           None   \n",
       "9                                 None                           None   \n",
       "10                                None                           None   \n",
       "11                                None                           None   \n",
       "12                                None                           None   \n",
       "13                                None                           None   \n",
       "14                                None                           None   \n",
       "15                                None                           None   \n",
       "16                                None                           None   \n",
       "17                                None                           None   \n",
       "18                                None                           None   \n",
       "19                                None                           None   \n",
       "20                                None                           None   \n",
       "21                                None                           None   \n",
       "22                                None                           None   \n",
       "23                                None                           None   \n",
       "24                                None                           None   \n",
       "\n",
       "                                      64                              65  \\\n",
       "0                                   None                            None   \n",
       "1                                   None                            None   \n",
       "2   {'token': 'kaibigan', 'tag': 'NOUN'}  {'token': 'sa', 'tag': 'CONJ'}   \n",
       "3                                   None                            None   \n",
       "4                                   None                            None   \n",
       "5                                   None                            None   \n",
       "6                                   None                            None   \n",
       "7                                   None                            None   \n",
       "8                                   None                            None   \n",
       "9                                   None                            None   \n",
       "10                                  None                            None   \n",
       "11                                  None                            None   \n",
       "12                                  None                            None   \n",
       "13                                  None                            None   \n",
       "14                                  None                            None   \n",
       "15                                  None                            None   \n",
       "16                                  None                            None   \n",
       "17                                  None                            None   \n",
       "18                                  None                            None   \n",
       "19                                  None                            None   \n",
       "20                                  None                            None   \n",
       "21                                  None                            None   \n",
       "22                                  None                            None   \n",
       "23                                  None                            None   \n",
       "24                                  None                            None   \n",
       "\n",
       "                                     66                             67  \n",
       "0                                  None                           None  \n",
       "1                                  None                           None  \n",
       "2   {'token': 'showbiz', 'tag': 'NOUN'}  {'token': '.', 'tag': 'PUNC'}  \n",
       "3                                  None                           None  \n",
       "4                                  None                           None  \n",
       "5                                  None                           None  \n",
       "6                                  None                           None  \n",
       "7                                  None                           None  \n",
       "8                                  None                           None  \n",
       "9                                  None                           None  \n",
       "10                                 None                           None  \n",
       "11                                 None                           None  \n",
       "12                                 None                           None  \n",
       "13                                 None                           None  \n",
       "14                                 None                           None  \n",
       "15                                 None                           None  \n",
       "16                                 None                           None  \n",
       "17                                 None                           None  \n",
       "18                                 None                           None  \n",
       "19                                 None                           None  \n",
       "20                                 None                           None  \n",
       "21                                 None                           None  \n",
       "22                                 None                           None  \n",
       "23                                 None                           None  \n",
       "24                                 None                           None  \n",
       "\n",
       "[25 rows x 68 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_dataframe = pd.read_json(\"sample.json\")\n",
    "display(input_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43e57ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_temp = []\n",
    "tags_temp = []\n",
    "input_sentence = []\n",
    "\n",
    "for i in range(len(input_dataframe)):\n",
    "    tokens_temp.clear()\n",
    "    tags_temp.clear()\n",
    "    \n",
    "    for j in range(input_dataframe.iloc[i].count()):\n",
    "        tokens_temp.append(input_dataframe.iloc[i][j].__getitem__(\"token\"))\n",
    "        tags_temp.append(input_dataframe.iloc[i][j].__getitem__(\"tag\"))\n",
    "        \n",
    "    sentence_temp = ' '.join([str(item) for item in tokens_temp])\n",
    "    \n",
    "    input_sentence.append(sentence_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c70e96d",
   "metadata": {},
   "source": [
    "## POS TAGGERS\n",
    "\n",
    "Let us import the monolingual taggers. Flair for english pos tagger and FSPOST for filipino pos tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbd55134",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/csata/FIL-ENG-POSTagger-Test/conda-venv/lib/python3.8/site-packages/huggingface_hub/file_download.py:629: FutureWarning: `cached_download` is the legacy way to download files from the HF hub, please consider upgrading to `hf_hub_download`\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-13 13:33:47,958 loading file /home/csata/.flair/models/pos-english/a9a73f6cd878edce8a0fa518db76f441f1cc49c2525b2b4557af278ec2f0659e.121306ea62993d04cd1978398b68396931a39eb47754c8a06a87f325ea70ac63\n",
      "2023-03-13 13:33:48,059 SequenceTagger predicts: Dictionary with 53 tags: <unk>, O, UH, ,, VBD, PRP, VB, PRP$, NN, RB, ., DT, JJ, VBP, VBG, IN, CD, NNS, NNP, WRB, VBZ, WDT, CC, TO, MD, VBN, WP, :, RP, EX, JJR, FW, XX, HYPH, POS, RBR, JJS, PDT, NNPS, RBS, AFX, WP$, -LRB-, -RRB-, ``, '', LS, $, SYM, ADD\n"
     ]
    }
   ],
   "source": [
    "# FLAIR POS TAGGER\n",
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "tagger = SequenceTagger.load(\"flair/pos-english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5d623e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FSPOST POS TAGGER\n",
    "import os\n",
    "from nltk.tag.stanford import StanfordPOSTagger\n",
    "\n",
    "# These are Windows formatted directories\n",
    "#model = 'model//filipino-left5words-owlqn2-distsim-pref6-inf2.tagger'\n",
    "#jar = 'lib//stanford-postagger.jar'\n",
    "\n",
    "# These are Linux formatted directories\n",
    "model = 'model/filipino-left5words-owlqn2-distsim-pref6-inf2.tagger'\n",
    "jar = 'lib/stanford-postagger.jar'\n",
    "\n",
    "fspost = StanfordPOSTagger(model, path_to_jar=jar)  # Load Tagger Model\n",
    "fspost._SEPARATOR = '|'  # Set separator for proper tuple formatting (word, tag)\n",
    "\n",
    "def set_java_path(file_path):\n",
    "    \"\"\"\n",
    "    Function for setting java path to make Stanford POS Tagger work. Makes use of the 'os' library. Input \"\" to use\n",
    "    default java path, otherwise set the location.\n",
    "    Args:\n",
    "        file_path (str): The java file path / location.\n",
    "    \"\"\"\n",
    "    if file_path == \"\":\n",
    "        java_path = \"C:/Program Files/Java/jdk1.8.0_111/bin/java.exe\"\n",
    "        print(\"Java path set by default\")\n",
    "    else:\n",
    "        java_path = file_path\n",
    "        print(\"Java path set from given\")\n",
    "    os.environ['JAVAHOME'] = java_path\n",
    "\n",
    "def tag_string(sentence):\n",
    "    \"\"\"\n",
    "    Function for tagging a sentence/string. Output is a (word, pos) tuple. To output a POS-only string, enclose this\n",
    "    function with 'format_pos' function. Ex. fspost.format_pos(fspost.tag_string('this is a string')). Same goes for\n",
    "    Stanford's word|tag notation, use 'format_stanford' function.\n",
    "    Args:\n",
    "        sentence (str): The string to be tagged.\n",
    "    Returns:\n",
    "        tagged_string: a list of string tokens containing POS labeled (word, pos) tuples.\n",
    "    \"\"\"\n",
    "    tokens = sentence.split()  # Tokenize Sentence by whitespaces\n",
    "    # print(tokens)\n",
    "    tagged_string = fspost.tag(tokens)\n",
    "    return tagged_string\n",
    "\n",
    "def tag_string_list(sentence_list):\n",
    "    \"\"\"\n",
    "    Function for tagging a list of sentences. Output is a list of (word, pos) tuple. To output a POS-only string,\n",
    "    enclose the elements in this function with 'format_pos' function. Same goes for Stanford's word|tag notation, use\n",
    "    'format_stanford' function.\n",
    "    Args:\n",
    "        sentence_list (list): The list of strings to be tagged.\n",
    "    Returns:\n",
    "        tagged_list: a list of strings containing POS labelled (word, pos) tuples.\n",
    "    \"\"\"\n",
    "    progress_ctr = 0\n",
    "    tagged_list = []  # Initialize an empty list\n",
    "    for sentence in sentence_list:\n",
    "        tagged_tuple = tag_string(sentence)  # Tag each sentence in the list\n",
    "        tagged_list.append(tagged_tuple)  # Insert tagged sentence in the new list\n",
    "        progress_ctr += 1\n",
    "        print(progress_ctr, \"/\", len(sentence_list))  # Progress Counter\n",
    "    return tagged_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fba20a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Java path set from given\n"
     ]
    }
   ],
   "source": [
    "# WINDOWS\n",
    "# set_java_path(\"C:/Program Files/Java/jdk-19/bin/java.exe\")\n",
    "\n",
    "# LINUX\n",
    "set_java_path(\"/usr/lib/jvm/java-11-openjdk-amd64/bin/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355279da",
   "metadata": {},
   "source": [
    "### Create functions to be used for POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea912637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the eng POS tag\n",
    "def eng_tagger(input_string):\n",
    "    sentence = Sentence(input_string)\n",
    "    tagger.predict(sentence)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "feb5edb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the fil POS tag\n",
    "def fil_tagger(input_string):\n",
    "    return tag_string(input_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e21d94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts the specific tag into generalized tag\n",
    "def convert_eng(pos_tag):\n",
    "    if(pos_tag == \"NN\" or pos_tag == \"NNS\"):\n",
    "        return \"Noun\"\n",
    "    elif(pos_tag == \"NNP\" or pos_tag == \"NNPS\"):\n",
    "        return \"PROPN\"\n",
    "    elif(pos_tag == \"PRP\" or pos_tag == \"PRP$\" or pos_tag == \"WP\" or pos_tag == \"WP$\"):\n",
    "        return \"PR\"\n",
    "    elif(pos_tag == \"DT\"):\n",
    "        return \"DT\"\n",
    "    elif(pos_tag == \"CC\"):\n",
    "        return \"CONJ\"\n",
    "    elif(pos_tag == \"IN\"):\n",
    "        return \"IN\"\n",
    "    elif(pos_tag == \"VB\" or pos_tag == \"VBD\" or pos_tag == \"VBG\" or pos_tag == \"VBN\" \n",
    "         or pos_tag == \"VBP\" or pos_tag == \"VBZ\"):\n",
    "        return \"VB\"\n",
    "    elif(pos_tag == \"JJ\" or pos_tag == \"JJR\" or pos_tag == \"JJS\"):\n",
    "        return \"JJ\"\n",
    "    elif(pos_tag == \"CD\"):\n",
    "        return \"CD\"\n",
    "    elif(pos_tag == \"RB\" or pos_tag == \"RBR\" or pos_tag == \"RBS\" or pos_tag == \"WRB\"):\n",
    "        return \"RB\"\n",
    "    elif(pos_tag == \"UH\"):\n",
    "        return \"UH\"\n",
    "    elif(pos_tag == \"FW\"):\n",
    "        return \"FW\"\n",
    "    elif(pos_tag == \".\" or pos_tag == \",\" or pos_tag == \":\"):\n",
    "        return \"PUNC\"\n",
    "    elif(pos_tag == \"HYPH\" or pos_tag == \"SYM\" or pos_tag == \"$\" or pos_tag == \"\\\"\"):\n",
    "        return \"SYM\"\n",
    "    else:\n",
    "        return pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04781d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts the specific tag into generalized tag\n",
    "def convert_fil(pos_tag):\n",
    "    if(pos_tag == \"NNC\" or pos_tag == \"NNCA\"):\n",
    "        return \"NOUN\"\n",
    "    elif(pos_tag == \"NNP\" or pos_tag == \"NNPA\"):\n",
    "        return \"PROPN\"\n",
    "    elif(pos_tag == \"PRS\" or pos_tag == \"PRP\" or pos_tag == \"PRSP\" or pos_tag == \"PRO\"\n",
    "        or pos_tag == \"PRQ\" or pos_tag == \"PRQP\" or pos_tag == \"PRL\" or pos_tag == \"PRC\"):\n",
    "        return \"PR\"\n",
    "    elif(pos_tag == \"DTC\" or pos_tag == \"DTCP\" or pos_tag == \"DTP\" or pos_tag == \"DTPP\"):\n",
    "        return \"DT\"\n",
    "    elif(pos_tag == \"LM\"):\n",
    "        return \"LM\"\n",
    "    elif(pos_tag == \"CCT\" or pos_tag == \"CCR\" or pos_tag == \"CCB\" or pos_tag == \"CCA\"):\n",
    "        return \"CONJ\"\n",
    "    #elif(pos_tag == \"CCP\"):\n",
    "        #return \"CCP\"\n",
    "    elif(pos_tag == \"CCU\"):\n",
    "        return \"IN\"\n",
    "    elif(pos_tag == \"VBW\" or pos_tag == \"VBS\" or pos_tag == \"VBH\" or pos_tag == \"VBN\"\n",
    "        or pos_tag == \"VBTS\" or pos_tag == \"VBTR\" or pos_tag == \"VBTF\" or pos_tag == \"VBTP\"\n",
    "        or pos_tag == \"VBAF\" or pos_tag == \"VBOF\" or pos_tag == \"VBOB\" or pos_tag == \"VBOL\"\n",
    "        or pos_tag == \"VBOI\" or pos_tag == \"VBRF\"):\n",
    "        return \"VB\"\n",
    "    elif(pos_tag == \"JJD\" or pos_tag == \"JJC\" or pos_tag == \"JJCC\" or pos_tag == \"JJCS\" or pos_tag == \"JJCN\"):\n",
    "        return \"JJ\"\n",
    "    elif(pos_tag == \"JJN\" or pos_tag == \"CDB\"):\n",
    "        return \"CD\"\n",
    "    elif(pos_tag == \"RBD\" or pos_tag == \"RBN\" or pos_tag == \"RBK\" or pos_tag == \"RBP\"\n",
    "        or pos_tag == \"RBB\" or pos_tag == \"RBR\" or pos_tag == \"RBQ\" or pos_tag == \"RBT\"\n",
    "        or pos_tag == \"RBF\" or pos_tag == \"RBW\" or pos_tag == \"RBM\" or pos_tag == \"RBL\"\n",
    "        or pos_tag == \"RBI\" or pos_tag == \"RBS\"):\n",
    "        return \"RB\"\n",
    "    elif(pos_tag == \"RBJ\"):\n",
    "        return \"UH\"\n",
    "    elif(pos_tag == \"FW\"):\n",
    "        return \"FW\"\n",
    "    elif(pos_tag == \"PMP\" or pos_tag == \"PME\" or pos_tag == \"PMQ\" or pos_tag == \"PMC\" or pos_tag == \"PMSC\"):\n",
    "        return \"PUNC\"\n",
    "    elif(pos_tag == \"PMS\"):\n",
    "        return \"SYM\"\n",
    "    else:\n",
    "        return pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e61c509d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text_langid = [] # will be used to store language id\n",
    "sample_text_pos_tags_general = [] # will be used to store generalized pos tags\n",
    "sample_text_pos_tags_specific = [] # will be used to store specific pos tags\n",
    "token_tagset = [] # will be used to store the name of the tagset used for specific tags\n",
    "\n",
    "# Temporary lists to be used for combi 2\n",
    "sample_text_pos_tags_general_eng = []\n",
    "sample_text_pos_tags_specific_eng = []\n",
    "sample_text_pos_tags_general_fil = []\n",
    "sample_text_pos_tags_specific_fil = []\n",
    "\n",
    "def reset_variables(general, specific, token_tagset):\n",
    "    #langid.clear()\n",
    "    general.clear()\n",
    "    specific.clear()\n",
    "    token_tagset.clear()\n",
    "    return\n",
    "\n",
    "def reset_variables_combi2(gen_eng, spec_eng, gen_fil, spec_fil):\n",
    "    gen_eng.clear()\n",
    "    spec_eng.clear()\n",
    "    gen_fil.clear()\n",
    "    spec_fil.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15a2d775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_to_dataframe(input_sentence, general_tags, specific_tags, tagset, tagged_texts):\n",
    "    tagged_texts = tagged_texts.append({\"text\": input_sentence, \"general_tags\": np.array(general_tags),\n",
    "                                        \"specific_tags\": np.array(specific_tags), \"token_tagset\": np.array(tagset)},\n",
    "                                       ignore_index = True)\n",
    "    return tagged_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4c8077c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_string(string_list):\n",
    "    return ' '.join([str(item) for item in string_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c41330a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9eb2527",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenized_text_with_punc(sample_text):\n",
    "    sample_text_tokenized = nltk.word_tokenize(sample_text)\n",
    "    return sample_text_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "421acd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lang_per_token(text_wo_punc):\n",
    "    sample_text_langid = []\n",
    "    #Identifies the language of each tokens to determine which tagger to use\n",
    "    for i in range(len(text_wo_punc)):\n",
    "        sample_text_langid.append(detector.detect_language_of(text_wo_punc[i]))\n",
    "        #print(text_wo_punc[i], \": \", sample_text_langid[i])\n",
    "        \n",
    "    return sample_text_langid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8672b887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_csv(dataframes, output_name):\n",
    "    dataframes['general_tags'] = dataframes['general_tags'].map(list)\n",
    "    dataframes['specific_tags'] = dataframes['specific_tags'].map(list)\n",
    "    dataframes['token_tagset'] = dataframes['token_tagset'].map(list)\n",
    "    dataframes.to_csv(output_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8191c7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isMultipleTags(tag):\n",
    "    if(tag.__contains__('_')):\n",
    "        new_tag = tag.split('_')\n",
    "        return new_tag[0]\n",
    "    else:\n",
    "        return tag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adc923d",
   "metadata": {},
   "source": [
    "## Language Identification then Monolingual Tagging (COMBI 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "832f8934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lang_id_then_mono_tag(input_string):\n",
    "    \n",
    "    sample_text_tokenized = tokenized_text_with_punc(input_string)\n",
    "    \n",
    "    # reset temporary variables\n",
    "    reset_variables(sample_text_pos_tags_general, sample_text_pos_tags_specific,token_tagset)\n",
    "    \n",
    "    sample_text_langid = get_lang_per_token(sample_text_tokenized)\n",
    "    \n",
    "    for i in range(len(sample_text_tokenized)):\n",
    "        if(sample_text_langid[i] == Language.TAGALOG):\n",
    "            token = fil_tagger(sample_text_tokenized[i])\n",
    "            new_token = isMultipleTags(token[0][1])\n",
    "            sample_text_pos_tags_general.append(convert_fil(new_token))\n",
    "            sample_text_pos_tags_specific.append(token[0][1])\n",
    "            token_tagset.append(\"MGNN\")\n",
    "\n",
    "        elif(sample_text_langid[i] == Language.ENGLISH):\n",
    "            token = eng_tagger(sample_text_tokenized[i])\n",
    "            new_token = isMultipleTags(token.get_labels('pos')[0].value)\n",
    "            sample_text_pos_tags_general.append(convert_eng(token.get_labels('pos')[0].value))\n",
    "            sample_text_pos_tags_specific.append(token.get_labels('pos')[0].value)\n",
    "            token_tagset.append(\"Flair\")\n",
    "\n",
    "        else:\n",
    "            token = fil_tagger(sample_text_tokenized[i])\n",
    "            new_token = isMultipleTags(token[0][1])\n",
    "            sample_text_pos_tags_general.append(convert_fil(new_token))\n",
    "            sample_text_pos_tags_specific.append(token[0][1])\n",
    "            token_tagset.append(\"MGNN\")\n",
    "        \n",
    "    global tagged_texts_combi1\n",
    "    temp = tagged_texts_combi1\n",
    "    tagged_texts_combi1 = append_to_dataframe(input_string, sample_text_pos_tags_general,\n",
    "                                              sample_text_pos_tags_specific, token_tagset, temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1c795ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2476/570677048.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tagged_texts = tagged_texts.append({\"text\": input_sentence, \"general_tags\": np.array(general_tags),\n",
      "/tmp/ipykernel_2476/570677048.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tagged_texts = tagged_texts.append({\"text\": input_sentence, \"general_tags\": np.array(general_tags),\n",
      "/tmp/ipykernel_2476/570677048.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tagged_texts = tagged_texts.append({\"text\": input_sentence, \"general_tags\": np.array(general_tags),\n",
      "/tmp/ipykernel_2476/570677048.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tagged_texts = tagged_texts.append({\"text\": input_sentence, \"general_tags\": np.array(general_tags),\n",
      "/tmp/ipykernel_2476/570677048.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tagged_texts = tagged_texts.append({\"text\": input_sentence, \"general_tags\": np.array(general_tags),\n",
      "/tmp/ipykernel_2476/570677048.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tagged_texts = tagged_texts.append({\"text\": input_sentence, \"general_tags\": np.array(general_tags),\n",
      "/tmp/ipykernel_2476/570677048.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tagged_texts = tagged_texts.append({\"text\": input_sentence, \"general_tags\": np.array(general_tags),\n",
      "/tmp/ipykernel_2476/570677048.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tagged_texts = tagged_texts.append({\"text\": input_sentence, \"general_tags\": np.array(general_tags),\n",
      "/tmp/ipykernel_2476/570677048.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tagged_texts = tagged_texts.append({\"text\": input_sentence, \"general_tags\": np.array(general_tags),\n",
      "/tmp/ipykernel_2476/570677048.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tagged_texts = tagged_texts.append({\"text\": input_sentence, \"general_tags\": np.array(general_tags),\n",
      "/tmp/ipykernel_2476/570677048.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tagged_texts = tagged_texts.append({\"text\": input_sentence, \"general_tags\": np.array(general_tags),\n",
      "/tmp/ipykernel_2476/570677048.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tagged_texts = tagged_texts.append({\"text\": input_sentence, \"general_tags\": np.array(general_tags),\n",
      "/tmp/ipykernel_2476/570677048.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tagged_texts = tagged_texts.append({\"text\": input_sentence, \"general_tags\": np.array(general_tags),\n",
      "/tmp/ipykernel_2476/570677048.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tagged_texts = tagged_texts.append({\"text\": input_sentence, \"general_tags\": np.array(general_tags),\n",
      "/tmp/ipykernel_2476/570677048.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tagged_texts = tagged_texts.append({\"text\": input_sentence, \"general_tags\": np.array(general_tags),\n",
      "/tmp/ipykernel_2476/570677048.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tagged_texts = tagged_texts.append({\"text\": input_sentence, \"general_tags\": np.array(general_tags),\n",
      "/tmp/ipykernel_2476/570677048.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tagged_texts = tagged_texts.append({\"text\": input_sentence, \"general_tags\": np.array(general_tags),\n",
      "/tmp/ipykernel_2476/570677048.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tagged_texts = tagged_texts.append({\"text\": input_sentence, \"general_tags\": np.array(general_tags),\n",
      "/tmp/ipykernel_2476/570677048.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tagged_texts = tagged_texts.append({\"text\": input_sentence, \"general_tags\": np.array(general_tags),\n",
      "/tmp/ipykernel_2476/570677048.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tagged_texts = tagged_texts.append({\"text\": input_sentence, \"general_tags\": np.array(general_tags),\n",
      "/tmp/ipykernel_2476/570677048.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tagged_texts = tagged_texts.append({\"text\": input_sentence, \"general_tags\": np.array(general_tags),\n",
      "/tmp/ipykernel_2476/570677048.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tagged_texts = tagged_texts.append({\"text\": input_sentence, \"general_tags\": np.array(general_tags),\n",
      "/tmp/ipykernel_2476/570677048.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tagged_texts = tagged_texts.append({\"text\": input_sentence, \"general_tags\": np.array(general_tags),\n",
      "/tmp/ipykernel_2476/570677048.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tagged_texts = tagged_texts.append({\"text\": input_sentence, \"general_tags\": np.array(general_tags),\n",
      "/tmp/ipykernel_2476/570677048.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tagged_texts = tagged_texts.append({\"text\": input_sentence, \"general_tags\": np.array(general_tags),\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>general_tags</th>\n",
       "      <th>specific_tags</th>\n",
       "      <th>token_tagset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>San Felipe , kapalit ng P120 , 000 placement f...</td>\n",
       "      <td>[PROPN, PROPN, PUNC, CONJ, CONJ, PROPN, PUNC, ...</td>\n",
       "      <td>[NNP, NNP, PMC, CCB, CCB, NNPA, PMC, CDB, NN, ...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pumanaw ang 65 taong gulang na mamamahayag dah...</td>\n",
       "      <td>[VB, DT, CD, NOUN, NOUN, CCP, NOUN, CONJ, CONJ...</td>\n",
       "      <td>[VBAF, DTC, CDB, NNC_CCP, NNC, CCP, NNC, CCR, ...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ang bahagi pa ng birthday message ni Liza para...</td>\n",
       "      <td>[DT, NOUN, RB, CONJ, NOUN, Noun, DT, PROPN, CO...</td>\n",
       "      <td>[DTC, NNC, RBI, CCB, NNC, NN, DTP, NNP, CCT, D...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, MGNN, Flair, MGNN, MG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Noong nakaraang Nobyembre , isang tuta na kaka...</td>\n",
       "      <td>[RB, RB, PROPN, PUNC, PRI, NOUN, CCP, JJ, RB, ...</td>\n",
       "      <td>[RBW_CCP, RBW_CCP, NNP, PMC, PRI_CCP, NNC, CCP...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mali yata ang naisip kasi namin noon na kung s...</td>\n",
       "      <td>[PROPN, RB, DT, VB, CONJ, PR, RB, CCP, CONJ, R...</td>\n",
       "      <td>[NNP, RBM, DTC, VBTS, CCR, PRP, RBW, CCP, CCR,...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Kaya kapag nagsalubong po ang dalawang hangin ...</td>\n",
       "      <td>[CONJ, CONJ, VB, UH, DT, CD, NOUN, CCP, PR, LM...</td>\n",
       "      <td>[CCR, CCR, VBTS, UH, DTC, JJN_CCP, NNC, CCP, P...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, Flair, MGNN, MGNN, MGNN, MG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Posible ngayon hapon o mamayang gabi ay tumama...</td>\n",
       "      <td>[RB, RB, RB, NFP, RB, RB, LM, VB, CONJ, NOUN, ...</td>\n",
       "      <td>[RBT, RBW, RBW, NFP, RBW_CCP, RBW, LM, VBAF, C...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, Flair, MGNN, MGNN, MGNN, MG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Noong tayo ay naging Chief PNP at dahil sa sup...</td>\n",
       "      <td>[RB, PR, LM, VB, PROPN, PROPN, IN, CONJ, CONJ,...</td>\n",
       "      <td>[RBW_CCP, PRP, LM, VBTS, NNP, NNPA, IN, CCR, C...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, Flair, MGNN, Flair, M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>`` Nagsimula ang pagbabawal kay Gordon na bumi...</td>\n",
       "      <td>[SYM, VB, DT, NOUN, DT, PROPN, CCP, VB, CONJ, ...</td>\n",
       "      <td>[PMS, VBTS, DTC, NNC, DTP, NNP, CCP, VBAF, CCT...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ayon kay Director General Avelino Razon Jnr , ...</td>\n",
       "      <td>[RB, DT, Noun, PROPN, PROPN, PROPN, PROPN, PUN...</td>\n",
       "      <td>[RBR, DTP, NN, NNP, NNP, NNP, NNP, PMC, NNC, C...</td>\n",
       "      <td>[MGNN, MGNN, Flair, Flair, MGNN, MGNN, Flair, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Intellectually akin ang Mister Philippines , `...</td>\n",
       "      <td>[RB, PR, DT, PROPN, PROPN, PUNC, SYM, NOUN, RB...</td>\n",
       "      <td>[RB, PRSP, DTC, NNP, NNP, PMC, PMS, NNC, RBI, ...</td>\n",
       "      <td>[Flair, MGNN, MGNN, Flair, MGNN, MGNN, MGNN, M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Gaya ng pakiusap ng ating mahal na Pangulong D...</td>\n",
       "      <td>[JJ, CONJ, NOUN, CONJ, PR, JJ, CCP, PROPN, PRO...</td>\n",
       "      <td>[JJC, CCB, NNC, CCB, PRSP_CCP, JJD, CCP, NNP_C...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Unang ipinalabas ang longest-running drama ant...</td>\n",
       "      <td>[CD, VB, DT, VB, NOUN, Noun, CONJ, PROPN, RB, ...</td>\n",
       "      <td>[JJN_CCP, VBTS, DTC, VBG, NNC, NN, CCT, NNP, R...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, Flair, MGNN, Flair, MGNN, M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Ang bongga nga ng movie , na ganun karami agad...</td>\n",
       "      <td>[DT, NOUN, RB, CONJ, Noun, PUNC, CCP, PR, PRI,...</td>\n",
       "      <td>[DTC, NNC, RBI, CCB, NN, PMC, CCP, PRC, PRI, R...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, Flair, MGNN, MGNN, MG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Hindi naman naisagawa ang operasyon para mapag...</td>\n",
       "      <td>[RB, RB, VB, DT, NOUN, CONJ, VB, CONJ, VB, PR,...</td>\n",
       "      <td>[RBF, RBI, VBTS, DTC, NNC, CCT, VBW, CCT, VBTR...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Ngunit kung may tunay na makikitang umiipit sa...</td>\n",
       "      <td>[CONJ, CONJ, VB, RB, CCP, VB, VB, CONJ, Noun, ...</td>\n",
       "      <td>[CCT, CCR, VBH, RBT, CCP, VBW_CCP, VBTR, CCT, ...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Ipinagdiriwang ng BFP ang Fire Prevention Mont...</td>\n",
       "      <td>[VB, CONJ, PROPN, DT, Noun, Noun, PROPN, RB, P...</td>\n",
       "      <td>[VBTR, CCB, NNPA, DTC, NN, NN, NNP, RBW, NNP, ...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, Flair, Flair, Flair, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Maliban sa Dito at Converge , sinabi ng hepe n...</td>\n",
       "      <td>[CONJ, CONJ, PR, IN, Noun, PUNC, VB, CONJ, NOU...</td>\n",
       "      <td>[CCT, CCT, PRL, IN, NN, PMC, VBTS, CCB, NNC, C...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, Flair, Flair, MGNN, MGNN, M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Pero kamakailan ay mas tinutukan ito dahil sa ...</td>\n",
       "      <td>[CONJ, RB, LM, JJ, VB, PR, CONJ, CONJ, NOUN, C...</td>\n",
       "      <td>[CCT, RBW, LM, JJCC, VBTS_VBOF, PRO, CCR, CCT,...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>`` Bukod sa last year na kasama ko ang mga ana...</td>\n",
       "      <td>[SYM, CONJ, CONJ, JJ, Noun, CCP, CONJ, PR, DT,...</td>\n",
       "      <td>[PMS, CCT, CCT, JJ, NN, CCP, CCB, PRS, DTC, DT...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, Flair, Flair, MGNN, MGNN, M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Pinaalalahanan din ng Pangulo ang militar sa i...</td>\n",
       "      <td>[PROPN, RB, CONJ, PROPN, DT, Noun, CONJ, VB, P...</td>\n",
       "      <td>[NNP, RBI, CCB, NNP, DTC, NN, CCT, VBTS, PRS_C...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, MGNN, Flair, MGNN, MG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>`` At kinaumagahan nga , habang tulog na tulog...</td>\n",
       "      <td>[SYM, IN, VB, RB, PUNC, RB, NOUN, CCP, NOUN, R...</td>\n",
       "      <td>[PMS, IN, VBTR, RBI, PMC, RBW, NNC, CCP, NNC, ...</td>\n",
       "      <td>[MGNN, Flair, MGNN, MGNN, MGNN, MGNN, MGNN, MG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>`` Pero hindi pa rin napigilan ng aktor ang ka...</td>\n",
       "      <td>[SYM, CONJ, RB, RB, RB, VB, CONJ, NOUN, DT, PR...</td>\n",
       "      <td>[PMS, CCT, RBF, RBI, RBI, VBTS, CCB, NNC, DTC,...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Photo courtesy : PNP Quezon Nang magka abutan ...</td>\n",
       "      <td>[Noun, Noun, SYM, PROPN, PROPN, RB, VB, VB, CC...</td>\n",
       "      <td>[NN, NN, PMS, NNPA, NNP, RBW, VBW, VBOF, CCP, ...</td>\n",
       "      <td>[Flair, Flair, MGNN, MGNN, MGNN, MGNN, MGNN, M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Mahirap daw ang mag-isa ka lang sa bahay at wa...</td>\n",
       "      <td>[RB, RB, DT, VB, PR, RB, CONJ, NOUN, IN, VB, C...</td>\n",
       "      <td>[RBD, RBI, DTC, VBW, PRS, RBI, CCT, NNC, IN, V...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  \\\n",
       "0   San Felipe , kapalit ng P120 , 000 placement f...   \n",
       "1   Pumanaw ang 65 taong gulang na mamamahayag dah...   \n",
       "2   ang bahagi pa ng birthday message ni Liza para...   \n",
       "3   Noong nakaraang Nobyembre , isang tuta na kaka...   \n",
       "4   Mali yata ang naisip kasi namin noon na kung s...   \n",
       "5   Kaya kapag nagsalubong po ang dalawang hangin ...   \n",
       "6   Posible ngayon hapon o mamayang gabi ay tumama...   \n",
       "7   Noong tayo ay naging Chief PNP at dahil sa sup...   \n",
       "8   `` Nagsimula ang pagbabawal kay Gordon na bumi...   \n",
       "9   Ayon kay Director General Avelino Razon Jnr , ...   \n",
       "10  Intellectually akin ang Mister Philippines , `...   \n",
       "11  Gaya ng pakiusap ng ating mahal na Pangulong D...   \n",
       "12  Unang ipinalabas ang longest-running drama ant...   \n",
       "13  Ang bongga nga ng movie , na ganun karami agad...   \n",
       "14  Hindi naman naisagawa ang operasyon para mapag...   \n",
       "15  Ngunit kung may tunay na makikitang umiipit sa...   \n",
       "16  Ipinagdiriwang ng BFP ang Fire Prevention Mont...   \n",
       "17  Maliban sa Dito at Converge , sinabi ng hepe n...   \n",
       "18  Pero kamakailan ay mas tinutukan ito dahil sa ...   \n",
       "19  `` Bukod sa last year na kasama ko ang mga ana...   \n",
       "20  Pinaalalahanan din ng Pangulo ang militar sa i...   \n",
       "21  `` At kinaumagahan nga , habang tulog na tulog...   \n",
       "22  `` Pero hindi pa rin napigilan ng aktor ang ka...   \n",
       "23  Photo courtesy : PNP Quezon Nang magka abutan ...   \n",
       "24  Mahirap daw ang mag-isa ka lang sa bahay at wa...   \n",
       "\n",
       "                                         general_tags  \\\n",
       "0   [PROPN, PROPN, PUNC, CONJ, CONJ, PROPN, PUNC, ...   \n",
       "1   [VB, DT, CD, NOUN, NOUN, CCP, NOUN, CONJ, CONJ...   \n",
       "2   [DT, NOUN, RB, CONJ, NOUN, Noun, DT, PROPN, CO...   \n",
       "3   [RB, RB, PROPN, PUNC, PRI, NOUN, CCP, JJ, RB, ...   \n",
       "4   [PROPN, RB, DT, VB, CONJ, PR, RB, CCP, CONJ, R...   \n",
       "5   [CONJ, CONJ, VB, UH, DT, CD, NOUN, CCP, PR, LM...   \n",
       "6   [RB, RB, RB, NFP, RB, RB, LM, VB, CONJ, NOUN, ...   \n",
       "7   [RB, PR, LM, VB, PROPN, PROPN, IN, CONJ, CONJ,...   \n",
       "8   [SYM, VB, DT, NOUN, DT, PROPN, CCP, VB, CONJ, ...   \n",
       "9   [RB, DT, Noun, PROPN, PROPN, PROPN, PROPN, PUN...   \n",
       "10  [RB, PR, DT, PROPN, PROPN, PUNC, SYM, NOUN, RB...   \n",
       "11  [JJ, CONJ, NOUN, CONJ, PR, JJ, CCP, PROPN, PRO...   \n",
       "12  [CD, VB, DT, VB, NOUN, Noun, CONJ, PROPN, RB, ...   \n",
       "13  [DT, NOUN, RB, CONJ, Noun, PUNC, CCP, PR, PRI,...   \n",
       "14  [RB, RB, VB, DT, NOUN, CONJ, VB, CONJ, VB, PR,...   \n",
       "15  [CONJ, CONJ, VB, RB, CCP, VB, VB, CONJ, Noun, ...   \n",
       "16  [VB, CONJ, PROPN, DT, Noun, Noun, PROPN, RB, P...   \n",
       "17  [CONJ, CONJ, PR, IN, Noun, PUNC, VB, CONJ, NOU...   \n",
       "18  [CONJ, RB, LM, JJ, VB, PR, CONJ, CONJ, NOUN, C...   \n",
       "19  [SYM, CONJ, CONJ, JJ, Noun, CCP, CONJ, PR, DT,...   \n",
       "20  [PROPN, RB, CONJ, PROPN, DT, Noun, CONJ, VB, P...   \n",
       "21  [SYM, IN, VB, RB, PUNC, RB, NOUN, CCP, NOUN, R...   \n",
       "22  [SYM, CONJ, RB, RB, RB, VB, CONJ, NOUN, DT, PR...   \n",
       "23  [Noun, Noun, SYM, PROPN, PROPN, RB, VB, VB, CC...   \n",
       "24  [RB, RB, DT, VB, PR, RB, CONJ, NOUN, IN, VB, C...   \n",
       "\n",
       "                                        specific_tags  \\\n",
       "0   [NNP, NNP, PMC, CCB, CCB, NNPA, PMC, CDB, NN, ...   \n",
       "1   [VBAF, DTC, CDB, NNC_CCP, NNC, CCP, NNC, CCR, ...   \n",
       "2   [DTC, NNC, RBI, CCB, NNC, NN, DTP, NNP, CCT, D...   \n",
       "3   [RBW_CCP, RBW_CCP, NNP, PMC, PRI_CCP, NNC, CCP...   \n",
       "4   [NNP, RBM, DTC, VBTS, CCR, PRP, RBW, CCP, CCR,...   \n",
       "5   [CCR, CCR, VBTS, UH, DTC, JJN_CCP, NNC, CCP, P...   \n",
       "6   [RBT, RBW, RBW, NFP, RBW_CCP, RBW, LM, VBAF, C...   \n",
       "7   [RBW_CCP, PRP, LM, VBTS, NNP, NNPA, IN, CCR, C...   \n",
       "8   [PMS, VBTS, DTC, NNC, DTP, NNP, CCP, VBAF, CCT...   \n",
       "9   [RBR, DTP, NN, NNP, NNP, NNP, NNP, PMC, NNC, C...   \n",
       "10  [RB, PRSP, DTC, NNP, NNP, PMC, PMS, NNC, RBI, ...   \n",
       "11  [JJC, CCB, NNC, CCB, PRSP_CCP, JJD, CCP, NNP_C...   \n",
       "12  [JJN_CCP, VBTS, DTC, VBG, NNC, NN, CCT, NNP, R...   \n",
       "13  [DTC, NNC, RBI, CCB, NN, PMC, CCP, PRC, PRI, R...   \n",
       "14  [RBF, RBI, VBTS, DTC, NNC, CCT, VBW, CCT, VBTR...   \n",
       "15  [CCT, CCR, VBH, RBT, CCP, VBW_CCP, VBTR, CCT, ...   \n",
       "16  [VBTR, CCB, NNPA, DTC, NN, NN, NNP, RBW, NNP, ...   \n",
       "17  [CCT, CCT, PRL, IN, NN, PMC, VBTS, CCB, NNC, C...   \n",
       "18  [CCT, RBW, LM, JJCC, VBTS_VBOF, PRO, CCR, CCT,...   \n",
       "19  [PMS, CCT, CCT, JJ, NN, CCP, CCB, PRS, DTC, DT...   \n",
       "20  [NNP, RBI, CCB, NNP, DTC, NN, CCT, VBTS, PRS_C...   \n",
       "21  [PMS, IN, VBTR, RBI, PMC, RBW, NNC, CCP, NNC, ...   \n",
       "22  [PMS, CCT, RBF, RBI, RBI, VBTS, CCB, NNC, DTC,...   \n",
       "23  [NN, NN, PMS, NNPA, NNP, RBW, VBW, VBOF, CCP, ...   \n",
       "24  [RBD, RBI, DTC, VBW, PRS, RBI, CCT, NNC, IN, V...   \n",
       "\n",
       "                                         token_tagset  \n",
       "0   [MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...  \n",
       "1   [MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...  \n",
       "2   [MGNN, MGNN, MGNN, MGNN, MGNN, Flair, MGNN, MG...  \n",
       "3   [MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...  \n",
       "4   [MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...  \n",
       "5   [MGNN, MGNN, MGNN, Flair, MGNN, MGNN, MGNN, MG...  \n",
       "6   [MGNN, MGNN, MGNN, Flair, MGNN, MGNN, MGNN, MG...  \n",
       "7   [MGNN, MGNN, MGNN, MGNN, Flair, MGNN, Flair, M...  \n",
       "8   [MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...  \n",
       "9   [MGNN, MGNN, Flair, Flair, MGNN, MGNN, Flair, ...  \n",
       "10  [Flair, MGNN, MGNN, Flair, MGNN, MGNN, MGNN, M...  \n",
       "11  [MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...  \n",
       "12  [MGNN, MGNN, MGNN, Flair, MGNN, Flair, MGNN, M...  \n",
       "13  [MGNN, MGNN, MGNN, MGNN, Flair, MGNN, MGNN, MG...  \n",
       "14  [MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...  \n",
       "15  [MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...  \n",
       "16  [MGNN, MGNN, MGNN, MGNN, Flair, Flair, Flair, ...  \n",
       "17  [MGNN, MGNN, MGNN, Flair, Flair, MGNN, MGNN, M...  \n",
       "18  [MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...  \n",
       "19  [MGNN, MGNN, MGNN, Flair, Flair, MGNN, MGNN, M...  \n",
       "20  [MGNN, MGNN, MGNN, MGNN, MGNN, Flair, MGNN, MG...  \n",
       "21  [MGNN, Flair, MGNN, MGNN, MGNN, MGNN, MGNN, MG...  \n",
       "22  [MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...  \n",
       "23  [Flair, Flair, MGNN, MGNN, MGNN, MGNN, MGNN, M...  \n",
       "24  [MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(len(input_sentence)):\n",
    "    lang_id_then_mono_tag(input_sentence[i])\n",
    "\n",
    "display(tagged_texts_combi1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68321ce3",
   "metadata": {},
   "source": [
    "## Monolingual Tagging then Language Identification (COMBI 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07fcdfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mono_tag_then_lang_id(input_string):\n",
    "    # Resets temp variables\n",
    "    reset_variables(sample_text_pos_tags_general, sample_text_pos_tags_specific, token_tagset)\n",
    "    reset_variables_combi2(sample_text_pos_tags_general_eng, sample_text_pos_tags_specific_eng,\n",
    "                           sample_text_pos_tags_general_fil, sample_text_pos_tags_specific_fil)\n",
    "    \n",
    "    # Tokenized sentences\n",
    "    sample_text_tokenized = tokenized_text_with_punc(input_string)\n",
    "    \n",
    "    # Flair (English) pos tagging\n",
    "    token_eng = eng_tagger(input_string)\n",
    "    \n",
    "    # Store tags to temporary variables (ENGLISH)\n",
    "    for i in range(len(token_eng.get_labels('pos'))):\n",
    "        new_token = isMultipleTags(token_eng.get_labels('pos')[i].value)\n",
    "        sample_text_pos_tags_general_eng.append(convert_eng(new_token))\n",
    "        sample_text_pos_tags_specific_eng.append(token_eng.get_labels('pos')[i].value)\n",
    "        \n",
    "    # FSPOST (Filipino) pos tagging\n",
    "    token_fil = fil_tagger(input_string)\n",
    "    \n",
    "    # Store tags to temporary variables (FILIPINO)\n",
    "    for i in range(len(token_fil)):\n",
    "        new_token = isMultipleTags(token_fil[i][1])\n",
    "        sample_text_pos_tags_general_fil.append(convert_fil(new_token))\n",
    "        sample_text_pos_tags_specific_fil.append(token_fil[i][1])\n",
    "    \n",
    "    # Get Languages per token (Language Identification )\n",
    "    sample_text_langid = get_lang_per_token(sample_text_tokenized)\n",
    "    \n",
    "    for i in range(len(sample_text_tokenized)):\n",
    "        if(sample_text_langid[i] == Language.TAGALOG):\n",
    "            sample_text_pos_tags_general.append(sample_text_pos_tags_general_fil[i])\n",
    "            sample_text_pos_tags_specific.append(sample_text_pos_tags_specific_fil[i])\n",
    "            token_tagset.append(\"MGNN\")\n",
    "\n",
    "        elif(sample_text_langid[i] == Language.ENGLISH):\n",
    "            sample_text_pos_tags_general.append(sample_text_pos_tags_general_eng[i])\n",
    "            sample_text_pos_tags_specific.append(sample_text_pos_tags_specific_eng[i])\n",
    "            token_tagset.append(\"Flair\")\n",
    "\n",
    "        else:\n",
    "            sample_text_pos_tags_general.append(sample_text_pos_tags_general_fil[i])\n",
    "            sample_text_pos_tags_specific.append(sample_text_pos_tags_specific_fil[i])\n",
    "            token_tagset.append(\"MGNN\")\n",
    "        \n",
    "        \n",
    "    global tagged_texts_combi2\n",
    "    temp = tagged_texts_combi2\n",
    "    tagged_texts_combi2 = append_to_dataframe(input_string, sample_text_pos_tags_general,\n",
    "                                              sample_text_pos_tags_specific, token_tagset, temp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7e39498",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2476/570677048.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tagged_texts = tagged_texts.append({\"text\": input_sentence, \"general_tags\": np.array(general_tags),\n",
      "/tmp/ipykernel_2476/570677048.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tagged_texts = tagged_texts.append({\"text\": input_sentence, \"general_tags\": np.array(general_tags),\n",
      "/tmp/ipykernel_2476/570677048.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tagged_texts = tagged_texts.append({\"text\": input_sentence, \"general_tags\": np.array(general_tags),\n",
      "/tmp/ipykernel_2476/570677048.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tagged_texts = tagged_texts.append({\"text\": input_sentence, \"general_tags\": np.array(general_tags),\n",
      "/tmp/ipykernel_2476/570677048.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tagged_texts = tagged_texts.append({\"text\": input_sentence, \"general_tags\": np.array(general_tags),\n",
      "/tmp/ipykernel_2476/570677048.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tagged_texts = tagged_texts.append({\"text\": input_sentence, \"general_tags\": np.array(general_tags),\n",
      "/tmp/ipykernel_2476/570677048.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tagged_texts = tagged_texts.append({\"text\": input_sentence, \"general_tags\": np.array(general_tags),\n",
      "/tmp/ipykernel_2476/570677048.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tagged_texts = tagged_texts.append({\"text\": input_sentence, \"general_tags\": np.array(general_tags),\n",
      "/tmp/ipykernel_2476/570677048.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tagged_texts = tagged_texts.append({\"text\": input_sentence, \"general_tags\": np.array(general_tags),\n",
      "/tmp/ipykernel_2476/570677048.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tagged_texts = tagged_texts.append({\"text\": input_sentence, \"general_tags\": np.array(general_tags),\n",
      "/tmp/ipykernel_2476/570677048.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tagged_texts = tagged_texts.append({\"text\": input_sentence, \"general_tags\": np.array(general_tags),\n",
      "/tmp/ipykernel_2476/570677048.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tagged_texts = tagged_texts.append({\"text\": input_sentence, \"general_tags\": np.array(general_tags),\n",
      "/tmp/ipykernel_2476/570677048.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tagged_texts = tagged_texts.append({\"text\": input_sentence, \"general_tags\": np.array(general_tags),\n",
      "/tmp/ipykernel_2476/570677048.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tagged_texts = tagged_texts.append({\"text\": input_sentence, \"general_tags\": np.array(general_tags),\n",
      "/tmp/ipykernel_2476/570677048.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tagged_texts = tagged_texts.append({\"text\": input_sentence, \"general_tags\": np.array(general_tags),\n",
      "/tmp/ipykernel_2476/570677048.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tagged_texts = tagged_texts.append({\"text\": input_sentence, \"general_tags\": np.array(general_tags),\n",
      "/tmp/ipykernel_2476/570677048.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tagged_texts = tagged_texts.append({\"text\": input_sentence, \"general_tags\": np.array(general_tags),\n",
      "/tmp/ipykernel_2476/570677048.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tagged_texts = tagged_texts.append({\"text\": input_sentence, \"general_tags\": np.array(general_tags),\n",
      "/tmp/ipykernel_2476/570677048.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tagged_texts = tagged_texts.append({\"text\": input_sentence, \"general_tags\": np.array(general_tags),\n",
      "/tmp/ipykernel_2476/570677048.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tagged_texts = tagged_texts.append({\"text\": input_sentence, \"general_tags\": np.array(general_tags),\n",
      "/tmp/ipykernel_2476/570677048.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tagged_texts = tagged_texts.append({\"text\": input_sentence, \"general_tags\": np.array(general_tags),\n",
      "/tmp/ipykernel_2476/570677048.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tagged_texts = tagged_texts.append({\"text\": input_sentence, \"general_tags\": np.array(general_tags),\n",
      "/tmp/ipykernel_2476/570677048.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tagged_texts = tagged_texts.append({\"text\": input_sentence, \"general_tags\": np.array(general_tags),\n",
      "/tmp/ipykernel_2476/570677048.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tagged_texts = tagged_texts.append({\"text\": input_sentence, \"general_tags\": np.array(general_tags),\n",
      "/tmp/ipykernel_2476/570677048.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tagged_texts = tagged_texts.append({\"text\": input_sentence, \"general_tags\": np.array(general_tags),\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>general_tags</th>\n",
       "      <th>specific_tags</th>\n",
       "      <th>token_tagset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>San Felipe , kapalit ng P120 , 000 placement f...</td>\n",
       "      <td>[PROPN, PROPN, PUNC, CONJ, CONJ, CD, PUNC, CD,...</td>\n",
       "      <td>[NNP, NNP, PMC, CCB, CCB, CDB, PMC, CDB, NN, N...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pumanaw ang 65 taong gulang na mamamahayag dah...</td>\n",
       "      <td>[VB, DT, CD, NOUN, NOUN, CCP, NOUN, CONJ, CONJ...</td>\n",
       "      <td>[VBAF, DTC, CDB, NNC_CCP, NNC, CCP, NNC, CCR, ...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ang bahagi pa ng birthday message ni Liza para...</td>\n",
       "      <td>[DT, NOUN, RB, CONJ, NOUN, Noun, DT, PROPN, CO...</td>\n",
       "      <td>[DTC, NNC, RBI, CCB, NNC, NN, DTP, NNP, CCT, D...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, MGNN, Flair, MGNN, MG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Noong nakaraang Nobyembre , isang tuta na kaka...</td>\n",
       "      <td>[RB, RB, PROPN, PUNC, PRI, NOUN, CCP, JJ, RB, ...</td>\n",
       "      <td>[RBW_CCP, RBW_CCP, NNP, PMC, PRI_CCP, NNC, CCP...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mali yata ang naisip kasi namin noon na kung s...</td>\n",
       "      <td>[PROPN, RB, DT, VB, CONJ, PR, RB, CCP, CONJ, R...</td>\n",
       "      <td>[NNP, RBM, DTC, VBTS, CCR, PRP, RBW, CCP, CCR,...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Kaya kapag nagsalubong po ang dalawang hangin ...</td>\n",
       "      <td>[CONJ, CONJ, VB, FW, DT, CD, NOUN, CCP, PR, LM...</td>\n",
       "      <td>[CCR, CCR, VBTS, FW, DTC, JJN_CCP, NNC, CCP, P...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, Flair, MGNN, MGNN, MGNN, MG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Posible ngayon hapon o mamayang gabi ay tumama...</td>\n",
       "      <td>[RB, RB, RB, FW, NOUN, RB, LM, VB, CONJ, NOUN,...</td>\n",
       "      <td>[RBT, RBW, RBW, FW, NNC_CCP, RBW, LM, VBAF, CC...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, Flair, MGNN, MGNN, MGNN, MG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Noong tayo ay naging Chief PNP at dahil sa sup...</td>\n",
       "      <td>[RB, PR, LM, VB, PROPN, PROPN, IN, CONJ, CONJ,...</td>\n",
       "      <td>[RBW_CCP, PRP, LM, VBTS, NNP, NNPA, IN, CCR, C...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, Flair, MGNN, Flair, M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>`` Nagsimula ang pagbabawal kay Gordon na bumi...</td>\n",
       "      <td>[SYM, VB, DT, NOUN, DT, PROPN, CCP, VB, CONJ, ...</td>\n",
       "      <td>[PMS, VBTS, DTC, NNC, DTP, NNP, CCP, VBAF, CCT...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ayon kay Director General Avelino Razon Jnr , ...</td>\n",
       "      <td>[RB, DT, PROPN, PROPN, PROPN, PROPN, PROPN, PU...</td>\n",
       "      <td>[RBR, DTP, NNP, NNP, NNP, NNP, NNP, PMC, NNC, ...</td>\n",
       "      <td>[MGNN, MGNN, Flair, Flair, MGNN, MGNN, Flair, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Intellectually akin ang Mister Philippines , `...</td>\n",
       "      <td>[RB, PR, DT, PROPN, PROPN, PUNC, CD, NOUN, RB,...</td>\n",
       "      <td>[RB, PRSP, DTC, NNP, NNP, PMC, CDB, NNC, RBI, ...</td>\n",
       "      <td>[Flair, MGNN, MGNN, Flair, MGNN, MGNN, MGNN, M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Gaya ng pakiusap ng ating mahal na Pangulong D...</td>\n",
       "      <td>[JJ, CONJ, NOUN, CONJ, PR, JJ, CCP, PROPN, PRO...</td>\n",
       "      <td>[JJC, CCB, NNC, CCB, PRSP_CCP, JJD, CCP, NNP_C...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Unang ipinalabas ang longest-running drama ant...</td>\n",
       "      <td>[CD, VB, DT, JJ, FW, Noun, CONJ, PROPN, RB, CD...</td>\n",
       "      <td>[JJN_CCP, VBTS, DTC, JJ, FW, NN, CCT, NNP, RBW...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, Flair, MGNN, Flair, MGNN, M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Ang bongga nga ng movie , na ganun karami agad...</td>\n",
       "      <td>[DT, FW, RB, CONJ, FW, PUNC, CCP, PR, PRI, RB,...</td>\n",
       "      <td>[DTC, FW, RBI, CCB, FW, PMC, CCP, PRC, PRI, RB...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, Flair, MGNN, MGNN, MG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Hindi naman naisagawa ang operasyon para mapag...</td>\n",
       "      <td>[RB, RB, VB, DT, NOUN, CONJ, VB, CONJ, VB, PR,...</td>\n",
       "      <td>[RBF, RBI, VBTS, DTC, NNC, CCT, VBW, CCT, VBTR...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Ngunit kung may tunay na makikitang umiipit sa...</td>\n",
       "      <td>[CONJ, CONJ, VB, JJ, CCP, RB, VB, CONJ, FW, FW...</td>\n",
       "      <td>[CCT, CCR, VBH, JJD, CCP, RBD_CCP, VBTR, CCT, ...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Ipinagdiriwang ng BFP ang Fire Prevention Mont...</td>\n",
       "      <td>[VB, CONJ, PROPN, DT, Noun, Noun, Noun, RB, PR...</td>\n",
       "      <td>[VBTR, CCB, NNPA, DTC, NN, NN, NN, RBW, NNP, C...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, Flair, Flair, Flair, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Maliban sa Dito at Converge , sinabi ng hepe n...</td>\n",
       "      <td>[CONJ, CONJ, PR, IN, PROPN, PUNC, VB, CONJ, NO...</td>\n",
       "      <td>[CCT, CCT, PRL, IN, NNP, PMC, VBTS, CCB, NNC, ...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, Flair, Flair, MGNN, MGNN, M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Pero kamakailan ay mas tinutukan ito dahil sa ...</td>\n",
       "      <td>[CONJ, RB, LM, JJ, VB, PR, CONJ, CONJ, NOUN, C...</td>\n",
       "      <td>[CCT, RBW, LM, JJCC, VBTS_VBOF, PRO, CCR, CCT,...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>`` Bukod sa last year na kasama ko ang mga ana...</td>\n",
       "      <td>[SYM, CONJ, CONJ, JJ, Noun, CCP, CONJ, PR, DT,...</td>\n",
       "      <td>[PMS, CCT, CCT, JJ, NN, CCP, CCB, PRS, DTC, DT...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, Flair, Flair, MGNN, MGNN, M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Pinaalalahanan din ng Pangulo ang militar sa i...</td>\n",
       "      <td>[VB, RB, CONJ, PROPN, DT, FW, CONJ, VB, PR, NO...</td>\n",
       "      <td>[VBTS, RBI, CCB, NNP, DTC, FW, CCT, VBTS, PRS_...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, MGNN, Flair, MGNN, MG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>`` At kinaumagahan nga , habang tulog na tulog...</td>\n",
       "      <td>[SYM, IN, VB, RB, PUNC, RB, NOUN, CCP, NOUN, R...</td>\n",
       "      <td>[PMS, IN, VBOF, RBI, PMC, RBW, NNC, CCP, NNC, ...</td>\n",
       "      <td>[MGNN, Flair, MGNN, MGNN, MGNN, MGNN, MGNN, MG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>`` Pero hindi pa rin napigilan ng aktor ang ka...</td>\n",
       "      <td>[SYM, CONJ, RB, RB, RB, VB, CONJ, NOUN, DT, PR...</td>\n",
       "      <td>[PMS, CCT, RBF, RBI, RBI, VBTS, CCB, NNC, DTC,...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Photo courtesy : PNP Quezon Nang magka abutan ...</td>\n",
       "      <td>[Noun, Noun, SYM, PROPN, PROPN, RB, VB, VB, CC...</td>\n",
       "      <td>[NN, NN, PMS, NNPA, NNP, RBW, VBW, VBOF, CCP, ...</td>\n",
       "      <td>[Flair, Flair, MGNN, MGNN, MGNN, MGNN, MGNN, M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Mahirap daw ang mag-isa ka lang sa bahay at wa...</td>\n",
       "      <td>[RB, RB, DT, VB, PR, RB, CONJ, NOUN, IN, VB, C...</td>\n",
       "      <td>[RBD, RBI, DTC, VBW, PRS, RBI, CCT, NNC, IN, V...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  \\\n",
       "0   San Felipe , kapalit ng P120 , 000 placement f...   \n",
       "1   Pumanaw ang 65 taong gulang na mamamahayag dah...   \n",
       "2   ang bahagi pa ng birthday message ni Liza para...   \n",
       "3   Noong nakaraang Nobyembre , isang tuta na kaka...   \n",
       "4   Mali yata ang naisip kasi namin noon na kung s...   \n",
       "5   Kaya kapag nagsalubong po ang dalawang hangin ...   \n",
       "6   Posible ngayon hapon o mamayang gabi ay tumama...   \n",
       "7   Noong tayo ay naging Chief PNP at dahil sa sup...   \n",
       "8   `` Nagsimula ang pagbabawal kay Gordon na bumi...   \n",
       "9   Ayon kay Director General Avelino Razon Jnr , ...   \n",
       "10  Intellectually akin ang Mister Philippines , `...   \n",
       "11  Gaya ng pakiusap ng ating mahal na Pangulong D...   \n",
       "12  Unang ipinalabas ang longest-running drama ant...   \n",
       "13  Ang bongga nga ng movie , na ganun karami agad...   \n",
       "14  Hindi naman naisagawa ang operasyon para mapag...   \n",
       "15  Ngunit kung may tunay na makikitang umiipit sa...   \n",
       "16  Ipinagdiriwang ng BFP ang Fire Prevention Mont...   \n",
       "17  Maliban sa Dito at Converge , sinabi ng hepe n...   \n",
       "18  Pero kamakailan ay mas tinutukan ito dahil sa ...   \n",
       "19  `` Bukod sa last year na kasama ko ang mga ana...   \n",
       "20  Pinaalalahanan din ng Pangulo ang militar sa i...   \n",
       "21  `` At kinaumagahan nga , habang tulog na tulog...   \n",
       "22  `` Pero hindi pa rin napigilan ng aktor ang ka...   \n",
       "23  Photo courtesy : PNP Quezon Nang magka abutan ...   \n",
       "24  Mahirap daw ang mag-isa ka lang sa bahay at wa...   \n",
       "\n",
       "                                         general_tags  \\\n",
       "0   [PROPN, PROPN, PUNC, CONJ, CONJ, CD, PUNC, CD,...   \n",
       "1   [VB, DT, CD, NOUN, NOUN, CCP, NOUN, CONJ, CONJ...   \n",
       "2   [DT, NOUN, RB, CONJ, NOUN, Noun, DT, PROPN, CO...   \n",
       "3   [RB, RB, PROPN, PUNC, PRI, NOUN, CCP, JJ, RB, ...   \n",
       "4   [PROPN, RB, DT, VB, CONJ, PR, RB, CCP, CONJ, R...   \n",
       "5   [CONJ, CONJ, VB, FW, DT, CD, NOUN, CCP, PR, LM...   \n",
       "6   [RB, RB, RB, FW, NOUN, RB, LM, VB, CONJ, NOUN,...   \n",
       "7   [RB, PR, LM, VB, PROPN, PROPN, IN, CONJ, CONJ,...   \n",
       "8   [SYM, VB, DT, NOUN, DT, PROPN, CCP, VB, CONJ, ...   \n",
       "9   [RB, DT, PROPN, PROPN, PROPN, PROPN, PROPN, PU...   \n",
       "10  [RB, PR, DT, PROPN, PROPN, PUNC, CD, NOUN, RB,...   \n",
       "11  [JJ, CONJ, NOUN, CONJ, PR, JJ, CCP, PROPN, PRO...   \n",
       "12  [CD, VB, DT, JJ, FW, Noun, CONJ, PROPN, RB, CD...   \n",
       "13  [DT, FW, RB, CONJ, FW, PUNC, CCP, PR, PRI, RB,...   \n",
       "14  [RB, RB, VB, DT, NOUN, CONJ, VB, CONJ, VB, PR,...   \n",
       "15  [CONJ, CONJ, VB, JJ, CCP, RB, VB, CONJ, FW, FW...   \n",
       "16  [VB, CONJ, PROPN, DT, Noun, Noun, Noun, RB, PR...   \n",
       "17  [CONJ, CONJ, PR, IN, PROPN, PUNC, VB, CONJ, NO...   \n",
       "18  [CONJ, RB, LM, JJ, VB, PR, CONJ, CONJ, NOUN, C...   \n",
       "19  [SYM, CONJ, CONJ, JJ, Noun, CCP, CONJ, PR, DT,...   \n",
       "20  [VB, RB, CONJ, PROPN, DT, FW, CONJ, VB, PR, NO...   \n",
       "21  [SYM, IN, VB, RB, PUNC, RB, NOUN, CCP, NOUN, R...   \n",
       "22  [SYM, CONJ, RB, RB, RB, VB, CONJ, NOUN, DT, PR...   \n",
       "23  [Noun, Noun, SYM, PROPN, PROPN, RB, VB, VB, CC...   \n",
       "24  [RB, RB, DT, VB, PR, RB, CONJ, NOUN, IN, VB, C...   \n",
       "\n",
       "                                        specific_tags  \\\n",
       "0   [NNP, NNP, PMC, CCB, CCB, CDB, PMC, CDB, NN, N...   \n",
       "1   [VBAF, DTC, CDB, NNC_CCP, NNC, CCP, NNC, CCR, ...   \n",
       "2   [DTC, NNC, RBI, CCB, NNC, NN, DTP, NNP, CCT, D...   \n",
       "3   [RBW_CCP, RBW_CCP, NNP, PMC, PRI_CCP, NNC, CCP...   \n",
       "4   [NNP, RBM, DTC, VBTS, CCR, PRP, RBW, CCP, CCR,...   \n",
       "5   [CCR, CCR, VBTS, FW, DTC, JJN_CCP, NNC, CCP, P...   \n",
       "6   [RBT, RBW, RBW, FW, NNC_CCP, RBW, LM, VBAF, CC...   \n",
       "7   [RBW_CCP, PRP, LM, VBTS, NNP, NNPA, IN, CCR, C...   \n",
       "8   [PMS, VBTS, DTC, NNC, DTP, NNP, CCP, VBAF, CCT...   \n",
       "9   [RBR, DTP, NNP, NNP, NNP, NNP, NNP, PMC, NNC, ...   \n",
       "10  [RB, PRSP, DTC, NNP, NNP, PMC, CDB, NNC, RBI, ...   \n",
       "11  [JJC, CCB, NNC, CCB, PRSP_CCP, JJD, CCP, NNP_C...   \n",
       "12  [JJN_CCP, VBTS, DTC, JJ, FW, NN, CCT, NNP, RBW...   \n",
       "13  [DTC, FW, RBI, CCB, FW, PMC, CCP, PRC, PRI, RB...   \n",
       "14  [RBF, RBI, VBTS, DTC, NNC, CCT, VBW, CCT, VBTR...   \n",
       "15  [CCT, CCR, VBH, JJD, CCP, RBD_CCP, VBTR, CCT, ...   \n",
       "16  [VBTR, CCB, NNPA, DTC, NN, NN, NN, RBW, NNP, C...   \n",
       "17  [CCT, CCT, PRL, IN, NNP, PMC, VBTS, CCB, NNC, ...   \n",
       "18  [CCT, RBW, LM, JJCC, VBTS_VBOF, PRO, CCR, CCT,...   \n",
       "19  [PMS, CCT, CCT, JJ, NN, CCP, CCB, PRS, DTC, DT...   \n",
       "20  [VBTS, RBI, CCB, NNP, DTC, FW, CCT, VBTS, PRS_...   \n",
       "21  [PMS, IN, VBOF, RBI, PMC, RBW, NNC, CCP, NNC, ...   \n",
       "22  [PMS, CCT, RBF, RBI, RBI, VBTS, CCB, NNC, DTC,...   \n",
       "23  [NN, NN, PMS, NNPA, NNP, RBW, VBW, VBOF, CCP, ...   \n",
       "24  [RBD, RBI, DTC, VBW, PRS, RBI, CCT, NNC, IN, V...   \n",
       "\n",
       "                                         token_tagset  \n",
       "0   [MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...  \n",
       "1   [MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...  \n",
       "2   [MGNN, MGNN, MGNN, MGNN, MGNN, Flair, MGNN, MG...  \n",
       "3   [MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...  \n",
       "4   [MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...  \n",
       "5   [MGNN, MGNN, MGNN, Flair, MGNN, MGNN, MGNN, MG...  \n",
       "6   [MGNN, MGNN, MGNN, Flair, MGNN, MGNN, MGNN, MG...  \n",
       "7   [MGNN, MGNN, MGNN, MGNN, Flair, MGNN, Flair, M...  \n",
       "8   [MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...  \n",
       "9   [MGNN, MGNN, Flair, Flair, MGNN, MGNN, Flair, ...  \n",
       "10  [Flair, MGNN, MGNN, Flair, MGNN, MGNN, MGNN, M...  \n",
       "11  [MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...  \n",
       "12  [MGNN, MGNN, MGNN, Flair, MGNN, Flair, MGNN, M...  \n",
       "13  [MGNN, MGNN, MGNN, MGNN, Flair, MGNN, MGNN, MG...  \n",
       "14  [MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...  \n",
       "15  [MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...  \n",
       "16  [MGNN, MGNN, MGNN, MGNN, Flair, Flair, Flair, ...  \n",
       "17  [MGNN, MGNN, MGNN, Flair, Flair, MGNN, MGNN, M...  \n",
       "18  [MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...  \n",
       "19  [MGNN, MGNN, MGNN, Flair, Flair, MGNN, MGNN, M...  \n",
       "20  [MGNN, MGNN, MGNN, MGNN, MGNN, Flair, MGNN, MG...  \n",
       "21  [MGNN, Flair, MGNN, MGNN, MGNN, MGNN, MGNN, MG...  \n",
       "22  [MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...  \n",
       "23  [Flair, Flair, MGNN, MGNN, MGNN, MGNN, MGNN, M...  \n",
       "24  [MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(len(input_sentence)):\n",
    "    mono_tag_then_lang_id(input_sentence[i])\n",
    "    \n",
    "display(tagged_texts_combi2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "370c3e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_to_csv(tagged_texts_combi1, \"combi1_output.csv\")\n",
    "dataframe_to_csv(tagged_texts_combi2, \"combi2_output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8d1ad85b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>general_tags</th>\n",
       "      <th>specific_tags</th>\n",
       "      <th>token_tagset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>San Felipe , kapalit ng P120 , 000 placement f...</td>\n",
       "      <td>[PROPN, PROPN, PUNC, CONJ, CONJ, PROPN, PUNC, ...</td>\n",
       "      <td>[NNP, NNP, PMC, CCB, CCB, NNPA, PMC, CDB, NN, ...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pumanaw ang 65 taong gulang na mamamahayag dah...</td>\n",
       "      <td>[VB, DT, CD, NOUN, NOUN, CCP, NOUN, CONJ, CONJ...</td>\n",
       "      <td>[VBAF, DTC, CDB, NNC_CCP, NNC, CCP, NNC, CCR, ...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ang bahagi pa ng birthday message ni Liza para...</td>\n",
       "      <td>[DT, NOUN, RB, CONJ, NOUN, Noun, DT, PROPN, CO...</td>\n",
       "      <td>[DTC, NNC, RBI, CCB, NNC, NN, DTP, NNP, CCT, D...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, MGNN, Flair, MGNN, MG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Noong nakaraang Nobyembre , isang tuta na kaka...</td>\n",
       "      <td>[RB, RB, PROPN, PUNC, PRI, NOUN, CCP, JJ, RB, ...</td>\n",
       "      <td>[RBW_CCP, RBW_CCP, NNP, PMC, PRI_CCP, NNC, CCP...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mali yata ang naisip kasi namin noon na kung s...</td>\n",
       "      <td>[PROPN, RB, DT, VB, CONJ, PR, RB, CCP, CONJ, R...</td>\n",
       "      <td>[NNP, RBM, DTC, VBTS, CCR, PRP, RBW, CCP, CCR,...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Kaya kapag nagsalubong po ang dalawang hangin ...</td>\n",
       "      <td>[CONJ, CONJ, VB, UH, DT, CD, NOUN, CCP, PR, LM...</td>\n",
       "      <td>[CCR, CCR, VBTS, UH, DTC, JJN_CCP, NNC, CCP, P...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, Flair, MGNN, MGNN, MGNN, MG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Posible ngayon hapon o mamayang gabi ay tumama...</td>\n",
       "      <td>[RB, RB, RB, NFP, RB, RB, LM, VB, CONJ, NOUN, ...</td>\n",
       "      <td>[RBT, RBW, RBW, NFP, RBW_CCP, RBW, LM, VBAF, C...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, Flair, MGNN, MGNN, MGNN, MG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Noong tayo ay naging Chief PNP at dahil sa sup...</td>\n",
       "      <td>[RB, PR, LM, VB, PROPN, PROPN, IN, CONJ, CONJ,...</td>\n",
       "      <td>[RBW_CCP, PRP, LM, VBTS, NNP, NNPA, IN, CCR, C...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, Flair, MGNN, Flair, M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>`` Nagsimula ang pagbabawal kay Gordon na bumi...</td>\n",
       "      <td>[SYM, VB, DT, NOUN, DT, PROPN, CCP, VB, CONJ, ...</td>\n",
       "      <td>[PMS, VBTS, DTC, NNC, DTP, NNP, CCP, VBAF, CCT...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ayon kay Director General Avelino Razon Jnr , ...</td>\n",
       "      <td>[RB, DT, Noun, PROPN, PROPN, PROPN, PROPN, PUN...</td>\n",
       "      <td>[RBR, DTP, NN, NNP, NNP, NNP, NNP, PMC, NNC, C...</td>\n",
       "      <td>[MGNN, MGNN, Flair, Flair, MGNN, MGNN, Flair, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Intellectually akin ang Mister Philippines , `...</td>\n",
       "      <td>[RB, PR, DT, PROPN, PROPN, PUNC, SYM, NOUN, RB...</td>\n",
       "      <td>[RB, PRSP, DTC, NNP, NNP, PMC, PMS, NNC, RBI, ...</td>\n",
       "      <td>[Flair, MGNN, MGNN, Flair, MGNN, MGNN, MGNN, M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Gaya ng pakiusap ng ating mahal na Pangulong D...</td>\n",
       "      <td>[JJ, CONJ, NOUN, CONJ, PR, JJ, CCP, PROPN, PRO...</td>\n",
       "      <td>[JJC, CCB, NNC, CCB, PRSP_CCP, JJD, CCP, NNP_C...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Unang ipinalabas ang longest-running drama ant...</td>\n",
       "      <td>[CD, VB, DT, VB, NOUN, Noun, CONJ, PROPN, RB, ...</td>\n",
       "      <td>[JJN_CCP, VBTS, DTC, VBG, NNC, NN, CCT, NNP, R...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, Flair, MGNN, Flair, MGNN, M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Ang bongga nga ng movie , na ganun karami agad...</td>\n",
       "      <td>[DT, NOUN, RB, CONJ, Noun, PUNC, CCP, PR, PRI,...</td>\n",
       "      <td>[DTC, NNC, RBI, CCB, NN, PMC, CCP, PRC, PRI, R...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, Flair, MGNN, MGNN, MG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Hindi naman naisagawa ang operasyon para mapag...</td>\n",
       "      <td>[RB, RB, VB, DT, NOUN, CONJ, VB, CONJ, VB, PR,...</td>\n",
       "      <td>[RBF, RBI, VBTS, DTC, NNC, CCT, VBW, CCT, VBTR...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Ngunit kung may tunay na makikitang umiipit sa...</td>\n",
       "      <td>[CONJ, CONJ, VB, RB, CCP, VB, VB, CONJ, Noun, ...</td>\n",
       "      <td>[CCT, CCR, VBH, RBT, CCP, VBW_CCP, VBTR, CCT, ...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Ipinagdiriwang ng BFP ang Fire Prevention Mont...</td>\n",
       "      <td>[VB, CONJ, PROPN, DT, Noun, Noun, PROPN, RB, P...</td>\n",
       "      <td>[VBTR, CCB, NNPA, DTC, NN, NN, NNP, RBW, NNP, ...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, Flair, Flair, Flair, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Maliban sa Dito at Converge , sinabi ng hepe n...</td>\n",
       "      <td>[CONJ, CONJ, PR, IN, Noun, PUNC, VB, CONJ, NOU...</td>\n",
       "      <td>[CCT, CCT, PRL, IN, NN, PMC, VBTS, CCB, NNC, C...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, Flair, Flair, MGNN, MGNN, M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Pero kamakailan ay mas tinutukan ito dahil sa ...</td>\n",
       "      <td>[CONJ, RB, LM, JJ, VB, PR, CONJ, CONJ, NOUN, C...</td>\n",
       "      <td>[CCT, RBW, LM, JJCC, VBTS_VBOF, PRO, CCR, CCT,...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>`` Bukod sa last year na kasama ko ang mga ana...</td>\n",
       "      <td>[SYM, CONJ, CONJ, JJ, Noun, CCP, CONJ, PR, DT,...</td>\n",
       "      <td>[PMS, CCT, CCT, JJ, NN, CCP, CCB, PRS, DTC, DT...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, Flair, Flair, MGNN, MGNN, M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Pinaalalahanan din ng Pangulo ang militar sa i...</td>\n",
       "      <td>[PROPN, RB, CONJ, PROPN, DT, Noun, CONJ, VB, P...</td>\n",
       "      <td>[NNP, RBI, CCB, NNP, DTC, NN, CCT, VBTS, PRS_C...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, MGNN, Flair, MGNN, MG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>`` At kinaumagahan nga , habang tulog na tulog...</td>\n",
       "      <td>[SYM, IN, VB, RB, PUNC, RB, NOUN, CCP, NOUN, R...</td>\n",
       "      <td>[PMS, IN, VBTR, RBI, PMC, RBW, NNC, CCP, NNC, ...</td>\n",
       "      <td>[MGNN, Flair, MGNN, MGNN, MGNN, MGNN, MGNN, MG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>`` Pero hindi pa rin napigilan ng aktor ang ka...</td>\n",
       "      <td>[SYM, CONJ, RB, RB, RB, VB, CONJ, NOUN, DT, PR...</td>\n",
       "      <td>[PMS, CCT, RBF, RBI, RBI, VBTS, CCB, NNC, DTC,...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Photo courtesy : PNP Quezon Nang magka abutan ...</td>\n",
       "      <td>[Noun, Noun, SYM, PROPN, PROPN, RB, VB, VB, CC...</td>\n",
       "      <td>[NN, NN, PMS, NNPA, NNP, RBW, VBW, VBOF, CCP, ...</td>\n",
       "      <td>[Flair, Flair, MGNN, MGNN, MGNN, MGNN, MGNN, M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Mahirap daw ang mag-isa ka lang sa bahay at wa...</td>\n",
       "      <td>[RB, RB, DT, VB, PR, RB, CONJ, NOUN, IN, VB, C...</td>\n",
       "      <td>[RBD, RBI, DTC, VBW, PRS, RBI, CCT, NNC, IN, V...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  \\\n",
       "0   San Felipe , kapalit ng P120 , 000 placement f...   \n",
       "1   Pumanaw ang 65 taong gulang na mamamahayag dah...   \n",
       "2   ang bahagi pa ng birthday message ni Liza para...   \n",
       "3   Noong nakaraang Nobyembre , isang tuta na kaka...   \n",
       "4   Mali yata ang naisip kasi namin noon na kung s...   \n",
       "5   Kaya kapag nagsalubong po ang dalawang hangin ...   \n",
       "6   Posible ngayon hapon o mamayang gabi ay tumama...   \n",
       "7   Noong tayo ay naging Chief PNP at dahil sa sup...   \n",
       "8   `` Nagsimula ang pagbabawal kay Gordon na bumi...   \n",
       "9   Ayon kay Director General Avelino Razon Jnr , ...   \n",
       "10  Intellectually akin ang Mister Philippines , `...   \n",
       "11  Gaya ng pakiusap ng ating mahal na Pangulong D...   \n",
       "12  Unang ipinalabas ang longest-running drama ant...   \n",
       "13  Ang bongga nga ng movie , na ganun karami agad...   \n",
       "14  Hindi naman naisagawa ang operasyon para mapag...   \n",
       "15  Ngunit kung may tunay na makikitang umiipit sa...   \n",
       "16  Ipinagdiriwang ng BFP ang Fire Prevention Mont...   \n",
       "17  Maliban sa Dito at Converge , sinabi ng hepe n...   \n",
       "18  Pero kamakailan ay mas tinutukan ito dahil sa ...   \n",
       "19  `` Bukod sa last year na kasama ko ang mga ana...   \n",
       "20  Pinaalalahanan din ng Pangulo ang militar sa i...   \n",
       "21  `` At kinaumagahan nga , habang tulog na tulog...   \n",
       "22  `` Pero hindi pa rin napigilan ng aktor ang ka...   \n",
       "23  Photo courtesy : PNP Quezon Nang magka abutan ...   \n",
       "24  Mahirap daw ang mag-isa ka lang sa bahay at wa...   \n",
       "\n",
       "                                         general_tags  \\\n",
       "0   [PROPN, PROPN, PUNC, CONJ, CONJ, PROPN, PUNC, ...   \n",
       "1   [VB, DT, CD, NOUN, NOUN, CCP, NOUN, CONJ, CONJ...   \n",
       "2   [DT, NOUN, RB, CONJ, NOUN, Noun, DT, PROPN, CO...   \n",
       "3   [RB, RB, PROPN, PUNC, PRI, NOUN, CCP, JJ, RB, ...   \n",
       "4   [PROPN, RB, DT, VB, CONJ, PR, RB, CCP, CONJ, R...   \n",
       "5   [CONJ, CONJ, VB, UH, DT, CD, NOUN, CCP, PR, LM...   \n",
       "6   [RB, RB, RB, NFP, RB, RB, LM, VB, CONJ, NOUN, ...   \n",
       "7   [RB, PR, LM, VB, PROPN, PROPN, IN, CONJ, CONJ,...   \n",
       "8   [SYM, VB, DT, NOUN, DT, PROPN, CCP, VB, CONJ, ...   \n",
       "9   [RB, DT, Noun, PROPN, PROPN, PROPN, PROPN, PUN...   \n",
       "10  [RB, PR, DT, PROPN, PROPN, PUNC, SYM, NOUN, RB...   \n",
       "11  [JJ, CONJ, NOUN, CONJ, PR, JJ, CCP, PROPN, PRO...   \n",
       "12  [CD, VB, DT, VB, NOUN, Noun, CONJ, PROPN, RB, ...   \n",
       "13  [DT, NOUN, RB, CONJ, Noun, PUNC, CCP, PR, PRI,...   \n",
       "14  [RB, RB, VB, DT, NOUN, CONJ, VB, CONJ, VB, PR,...   \n",
       "15  [CONJ, CONJ, VB, RB, CCP, VB, VB, CONJ, Noun, ...   \n",
       "16  [VB, CONJ, PROPN, DT, Noun, Noun, PROPN, RB, P...   \n",
       "17  [CONJ, CONJ, PR, IN, Noun, PUNC, VB, CONJ, NOU...   \n",
       "18  [CONJ, RB, LM, JJ, VB, PR, CONJ, CONJ, NOUN, C...   \n",
       "19  [SYM, CONJ, CONJ, JJ, Noun, CCP, CONJ, PR, DT,...   \n",
       "20  [PROPN, RB, CONJ, PROPN, DT, Noun, CONJ, VB, P...   \n",
       "21  [SYM, IN, VB, RB, PUNC, RB, NOUN, CCP, NOUN, R...   \n",
       "22  [SYM, CONJ, RB, RB, RB, VB, CONJ, NOUN, DT, PR...   \n",
       "23  [Noun, Noun, SYM, PROPN, PROPN, RB, VB, VB, CC...   \n",
       "24  [RB, RB, DT, VB, PR, RB, CONJ, NOUN, IN, VB, C...   \n",
       "\n",
       "                                        specific_tags  \\\n",
       "0   [NNP, NNP, PMC, CCB, CCB, NNPA, PMC, CDB, NN, ...   \n",
       "1   [VBAF, DTC, CDB, NNC_CCP, NNC, CCP, NNC, CCR, ...   \n",
       "2   [DTC, NNC, RBI, CCB, NNC, NN, DTP, NNP, CCT, D...   \n",
       "3   [RBW_CCP, RBW_CCP, NNP, PMC, PRI_CCP, NNC, CCP...   \n",
       "4   [NNP, RBM, DTC, VBTS, CCR, PRP, RBW, CCP, CCR,...   \n",
       "5   [CCR, CCR, VBTS, UH, DTC, JJN_CCP, NNC, CCP, P...   \n",
       "6   [RBT, RBW, RBW, NFP, RBW_CCP, RBW, LM, VBAF, C...   \n",
       "7   [RBW_CCP, PRP, LM, VBTS, NNP, NNPA, IN, CCR, C...   \n",
       "8   [PMS, VBTS, DTC, NNC, DTP, NNP, CCP, VBAF, CCT...   \n",
       "9   [RBR, DTP, NN, NNP, NNP, NNP, NNP, PMC, NNC, C...   \n",
       "10  [RB, PRSP, DTC, NNP, NNP, PMC, PMS, NNC, RBI, ...   \n",
       "11  [JJC, CCB, NNC, CCB, PRSP_CCP, JJD, CCP, NNP_C...   \n",
       "12  [JJN_CCP, VBTS, DTC, VBG, NNC, NN, CCT, NNP, R...   \n",
       "13  [DTC, NNC, RBI, CCB, NN, PMC, CCP, PRC, PRI, R...   \n",
       "14  [RBF, RBI, VBTS, DTC, NNC, CCT, VBW, CCT, VBTR...   \n",
       "15  [CCT, CCR, VBH, RBT, CCP, VBW_CCP, VBTR, CCT, ...   \n",
       "16  [VBTR, CCB, NNPA, DTC, NN, NN, NNP, RBW, NNP, ...   \n",
       "17  [CCT, CCT, PRL, IN, NN, PMC, VBTS, CCB, NNC, C...   \n",
       "18  [CCT, RBW, LM, JJCC, VBTS_VBOF, PRO, CCR, CCT,...   \n",
       "19  [PMS, CCT, CCT, JJ, NN, CCP, CCB, PRS, DTC, DT...   \n",
       "20  [NNP, RBI, CCB, NNP, DTC, NN, CCT, VBTS, PRS_C...   \n",
       "21  [PMS, IN, VBTR, RBI, PMC, RBW, NNC, CCP, NNC, ...   \n",
       "22  [PMS, CCT, RBF, RBI, RBI, VBTS, CCB, NNC, DTC,...   \n",
       "23  [NN, NN, PMS, NNPA, NNP, RBW, VBW, VBOF, CCP, ...   \n",
       "24  [RBD, RBI, DTC, VBW, PRS, RBI, CCT, NNC, IN, V...   \n",
       "\n",
       "                                         token_tagset  \n",
       "0   [MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...  \n",
       "1   [MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...  \n",
       "2   [MGNN, MGNN, MGNN, MGNN, MGNN, Flair, MGNN, MG...  \n",
       "3   [MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...  \n",
       "4   [MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...  \n",
       "5   [MGNN, MGNN, MGNN, Flair, MGNN, MGNN, MGNN, MG...  \n",
       "6   [MGNN, MGNN, MGNN, Flair, MGNN, MGNN, MGNN, MG...  \n",
       "7   [MGNN, MGNN, MGNN, MGNN, Flair, MGNN, Flair, M...  \n",
       "8   [MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...  \n",
       "9   [MGNN, MGNN, Flair, Flair, MGNN, MGNN, Flair, ...  \n",
       "10  [Flair, MGNN, MGNN, Flair, MGNN, MGNN, MGNN, M...  \n",
       "11  [MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...  \n",
       "12  [MGNN, MGNN, MGNN, Flair, MGNN, Flair, MGNN, M...  \n",
       "13  [MGNN, MGNN, MGNN, MGNN, Flair, MGNN, MGNN, MG...  \n",
       "14  [MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...  \n",
       "15  [MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...  \n",
       "16  [MGNN, MGNN, MGNN, MGNN, Flair, Flair, Flair, ...  \n",
       "17  [MGNN, MGNN, MGNN, Flair, Flair, MGNN, MGNN, M...  \n",
       "18  [MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...  \n",
       "19  [MGNN, MGNN, MGNN, Flair, Flair, MGNN, MGNN, M...  \n",
       "20  [MGNN, MGNN, MGNN, MGNN, MGNN, Flair, MGNN, MG...  \n",
       "21  [MGNN, Flair, MGNN, MGNN, MGNN, MGNN, MGNN, MG...  \n",
       "22  [MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...  \n",
       "23  [Flair, Flair, MGNN, MGNN, MGNN, MGNN, MGNN, M...  \n",
       "24  [MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>general_tags</th>\n",
       "      <th>specific_tags</th>\n",
       "      <th>token_tagset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>San Felipe , kapalit ng P120 , 000 placement f...</td>\n",
       "      <td>[PROPN, PROPN, PUNC, CONJ, CONJ, CD, PUNC, CD,...</td>\n",
       "      <td>[NNP, NNP, PMC, CCB, CCB, CDB, PMC, CDB, NN, N...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pumanaw ang 65 taong gulang na mamamahayag dah...</td>\n",
       "      <td>[VB, DT, CD, NOUN, NOUN, CCP, NOUN, CONJ, CONJ...</td>\n",
       "      <td>[VBAF, DTC, CDB, NNC_CCP, NNC, CCP, NNC, CCR, ...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ang bahagi pa ng birthday message ni Liza para...</td>\n",
       "      <td>[DT, NOUN, RB, CONJ, NOUN, Noun, DT, PROPN, CO...</td>\n",
       "      <td>[DTC, NNC, RBI, CCB, NNC, NN, DTP, NNP, CCT, D...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, MGNN, Flair, MGNN, MG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Noong nakaraang Nobyembre , isang tuta na kaka...</td>\n",
       "      <td>[RB, RB, PROPN, PUNC, PRI, NOUN, CCP, JJ, RB, ...</td>\n",
       "      <td>[RBW_CCP, RBW_CCP, NNP, PMC, PRI_CCP, NNC, CCP...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mali yata ang naisip kasi namin noon na kung s...</td>\n",
       "      <td>[PROPN, RB, DT, VB, CONJ, PR, RB, CCP, CONJ, R...</td>\n",
       "      <td>[NNP, RBM, DTC, VBTS, CCR, PRP, RBW, CCP, CCR,...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Kaya kapag nagsalubong po ang dalawang hangin ...</td>\n",
       "      <td>[CONJ, CONJ, VB, FW, DT, CD, NOUN, CCP, PR, LM...</td>\n",
       "      <td>[CCR, CCR, VBTS, FW, DTC, JJN_CCP, NNC, CCP, P...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, Flair, MGNN, MGNN, MGNN, MG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Posible ngayon hapon o mamayang gabi ay tumama...</td>\n",
       "      <td>[RB, RB, RB, FW, NOUN, RB, LM, VB, CONJ, NOUN,...</td>\n",
       "      <td>[RBT, RBW, RBW, FW, NNC_CCP, RBW, LM, VBAF, CC...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, Flair, MGNN, MGNN, MGNN, MG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Noong tayo ay naging Chief PNP at dahil sa sup...</td>\n",
       "      <td>[RB, PR, LM, VB, PROPN, PROPN, IN, CONJ, CONJ,...</td>\n",
       "      <td>[RBW_CCP, PRP, LM, VBTS, NNP, NNPA, IN, CCR, C...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, Flair, MGNN, Flair, M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>`` Nagsimula ang pagbabawal kay Gordon na bumi...</td>\n",
       "      <td>[SYM, VB, DT, NOUN, DT, PROPN, CCP, VB, CONJ, ...</td>\n",
       "      <td>[PMS, VBTS, DTC, NNC, DTP, NNP, CCP, VBAF, CCT...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ayon kay Director General Avelino Razon Jnr , ...</td>\n",
       "      <td>[RB, DT, PROPN, PROPN, PROPN, PROPN, PROPN, PU...</td>\n",
       "      <td>[RBR, DTP, NNP, NNP, NNP, NNP, NNP, PMC, NNC, ...</td>\n",
       "      <td>[MGNN, MGNN, Flair, Flair, MGNN, MGNN, Flair, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Intellectually akin ang Mister Philippines , `...</td>\n",
       "      <td>[RB, PR, DT, PROPN, PROPN, PUNC, CD, NOUN, RB,...</td>\n",
       "      <td>[RB, PRSP, DTC, NNP, NNP, PMC, CDB, NNC, RBI, ...</td>\n",
       "      <td>[Flair, MGNN, MGNN, Flair, MGNN, MGNN, MGNN, M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Gaya ng pakiusap ng ating mahal na Pangulong D...</td>\n",
       "      <td>[JJ, CONJ, NOUN, CONJ, PR, JJ, CCP, PROPN, PRO...</td>\n",
       "      <td>[JJC, CCB, NNC, CCB, PRSP_CCP, JJD, CCP, NNP_C...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Unang ipinalabas ang longest-running drama ant...</td>\n",
       "      <td>[CD, VB, DT, JJ, FW, Noun, CONJ, PROPN, RB, CD...</td>\n",
       "      <td>[JJN_CCP, VBTS, DTC, JJ, FW, NN, CCT, NNP, RBW...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, Flair, MGNN, Flair, MGNN, M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Ang bongga nga ng movie , na ganun karami agad...</td>\n",
       "      <td>[DT, FW, RB, CONJ, FW, PUNC, CCP, PR, PRI, RB,...</td>\n",
       "      <td>[DTC, FW, RBI, CCB, FW, PMC, CCP, PRC, PRI, RB...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, Flair, MGNN, MGNN, MG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Hindi naman naisagawa ang operasyon para mapag...</td>\n",
       "      <td>[RB, RB, VB, DT, NOUN, CONJ, VB, CONJ, VB, PR,...</td>\n",
       "      <td>[RBF, RBI, VBTS, DTC, NNC, CCT, VBW, CCT, VBTR...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Ngunit kung may tunay na makikitang umiipit sa...</td>\n",
       "      <td>[CONJ, CONJ, VB, JJ, CCP, RB, VB, CONJ, FW, FW...</td>\n",
       "      <td>[CCT, CCR, VBH, JJD, CCP, RBD_CCP, VBTR, CCT, ...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Ipinagdiriwang ng BFP ang Fire Prevention Mont...</td>\n",
       "      <td>[VB, CONJ, PROPN, DT, Noun, Noun, Noun, RB, PR...</td>\n",
       "      <td>[VBTR, CCB, NNPA, DTC, NN, NN, NN, RBW, NNP, C...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, Flair, Flair, Flair, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Maliban sa Dito at Converge , sinabi ng hepe n...</td>\n",
       "      <td>[CONJ, CONJ, PR, IN, PROPN, PUNC, VB, CONJ, NO...</td>\n",
       "      <td>[CCT, CCT, PRL, IN, NNP, PMC, VBTS, CCB, NNC, ...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, Flair, Flair, MGNN, MGNN, M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Pero kamakailan ay mas tinutukan ito dahil sa ...</td>\n",
       "      <td>[CONJ, RB, LM, JJ, VB, PR, CONJ, CONJ, NOUN, C...</td>\n",
       "      <td>[CCT, RBW, LM, JJCC, VBTS_VBOF, PRO, CCR, CCT,...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>`` Bukod sa last year na kasama ko ang mga ana...</td>\n",
       "      <td>[SYM, CONJ, CONJ, JJ, Noun, CCP, CONJ, PR, DT,...</td>\n",
       "      <td>[PMS, CCT, CCT, JJ, NN, CCP, CCB, PRS, DTC, DT...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, Flair, Flair, MGNN, MGNN, M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Pinaalalahanan din ng Pangulo ang militar sa i...</td>\n",
       "      <td>[VB, RB, CONJ, PROPN, DT, FW, CONJ, VB, PR, NO...</td>\n",
       "      <td>[VBTS, RBI, CCB, NNP, DTC, FW, CCT, VBTS, PRS_...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, MGNN, Flair, MGNN, MG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>`` At kinaumagahan nga , habang tulog na tulog...</td>\n",
       "      <td>[SYM, IN, VB, RB, PUNC, RB, NOUN, CCP, NOUN, R...</td>\n",
       "      <td>[PMS, IN, VBOF, RBI, PMC, RBW, NNC, CCP, NNC, ...</td>\n",
       "      <td>[MGNN, Flair, MGNN, MGNN, MGNN, MGNN, MGNN, MG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>`` Pero hindi pa rin napigilan ng aktor ang ka...</td>\n",
       "      <td>[SYM, CONJ, RB, RB, RB, VB, CONJ, NOUN, DT, PR...</td>\n",
       "      <td>[PMS, CCT, RBF, RBI, RBI, VBTS, CCB, NNC, DTC,...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Photo courtesy : PNP Quezon Nang magka abutan ...</td>\n",
       "      <td>[Noun, Noun, SYM, PROPN, PROPN, RB, VB, VB, CC...</td>\n",
       "      <td>[NN, NN, PMS, NNPA, NNP, RBW, VBW, VBOF, CCP, ...</td>\n",
       "      <td>[Flair, Flair, MGNN, MGNN, MGNN, MGNN, MGNN, M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Mahirap daw ang mag-isa ka lang sa bahay at wa...</td>\n",
       "      <td>[RB, RB, DT, VB, PR, RB, CONJ, NOUN, IN, VB, C...</td>\n",
       "      <td>[RBD, RBI, DTC, VBW, PRS, RBI, CCT, NNC, IN, V...</td>\n",
       "      <td>[MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  \\\n",
       "0   San Felipe , kapalit ng P120 , 000 placement f...   \n",
       "1   Pumanaw ang 65 taong gulang na mamamahayag dah...   \n",
       "2   ang bahagi pa ng birthday message ni Liza para...   \n",
       "3   Noong nakaraang Nobyembre , isang tuta na kaka...   \n",
       "4   Mali yata ang naisip kasi namin noon na kung s...   \n",
       "5   Kaya kapag nagsalubong po ang dalawang hangin ...   \n",
       "6   Posible ngayon hapon o mamayang gabi ay tumama...   \n",
       "7   Noong tayo ay naging Chief PNP at dahil sa sup...   \n",
       "8   `` Nagsimula ang pagbabawal kay Gordon na bumi...   \n",
       "9   Ayon kay Director General Avelino Razon Jnr , ...   \n",
       "10  Intellectually akin ang Mister Philippines , `...   \n",
       "11  Gaya ng pakiusap ng ating mahal na Pangulong D...   \n",
       "12  Unang ipinalabas ang longest-running drama ant...   \n",
       "13  Ang bongga nga ng movie , na ganun karami agad...   \n",
       "14  Hindi naman naisagawa ang operasyon para mapag...   \n",
       "15  Ngunit kung may tunay na makikitang umiipit sa...   \n",
       "16  Ipinagdiriwang ng BFP ang Fire Prevention Mont...   \n",
       "17  Maliban sa Dito at Converge , sinabi ng hepe n...   \n",
       "18  Pero kamakailan ay mas tinutukan ito dahil sa ...   \n",
       "19  `` Bukod sa last year na kasama ko ang mga ana...   \n",
       "20  Pinaalalahanan din ng Pangulo ang militar sa i...   \n",
       "21  `` At kinaumagahan nga , habang tulog na tulog...   \n",
       "22  `` Pero hindi pa rin napigilan ng aktor ang ka...   \n",
       "23  Photo courtesy : PNP Quezon Nang magka abutan ...   \n",
       "24  Mahirap daw ang mag-isa ka lang sa bahay at wa...   \n",
       "\n",
       "                                         general_tags  \\\n",
       "0   [PROPN, PROPN, PUNC, CONJ, CONJ, CD, PUNC, CD,...   \n",
       "1   [VB, DT, CD, NOUN, NOUN, CCP, NOUN, CONJ, CONJ...   \n",
       "2   [DT, NOUN, RB, CONJ, NOUN, Noun, DT, PROPN, CO...   \n",
       "3   [RB, RB, PROPN, PUNC, PRI, NOUN, CCP, JJ, RB, ...   \n",
       "4   [PROPN, RB, DT, VB, CONJ, PR, RB, CCP, CONJ, R...   \n",
       "5   [CONJ, CONJ, VB, FW, DT, CD, NOUN, CCP, PR, LM...   \n",
       "6   [RB, RB, RB, FW, NOUN, RB, LM, VB, CONJ, NOUN,...   \n",
       "7   [RB, PR, LM, VB, PROPN, PROPN, IN, CONJ, CONJ,...   \n",
       "8   [SYM, VB, DT, NOUN, DT, PROPN, CCP, VB, CONJ, ...   \n",
       "9   [RB, DT, PROPN, PROPN, PROPN, PROPN, PROPN, PU...   \n",
       "10  [RB, PR, DT, PROPN, PROPN, PUNC, CD, NOUN, RB,...   \n",
       "11  [JJ, CONJ, NOUN, CONJ, PR, JJ, CCP, PROPN, PRO...   \n",
       "12  [CD, VB, DT, JJ, FW, Noun, CONJ, PROPN, RB, CD...   \n",
       "13  [DT, FW, RB, CONJ, FW, PUNC, CCP, PR, PRI, RB,...   \n",
       "14  [RB, RB, VB, DT, NOUN, CONJ, VB, CONJ, VB, PR,...   \n",
       "15  [CONJ, CONJ, VB, JJ, CCP, RB, VB, CONJ, FW, FW...   \n",
       "16  [VB, CONJ, PROPN, DT, Noun, Noun, Noun, RB, PR...   \n",
       "17  [CONJ, CONJ, PR, IN, PROPN, PUNC, VB, CONJ, NO...   \n",
       "18  [CONJ, RB, LM, JJ, VB, PR, CONJ, CONJ, NOUN, C...   \n",
       "19  [SYM, CONJ, CONJ, JJ, Noun, CCP, CONJ, PR, DT,...   \n",
       "20  [VB, RB, CONJ, PROPN, DT, FW, CONJ, VB, PR, NO...   \n",
       "21  [SYM, IN, VB, RB, PUNC, RB, NOUN, CCP, NOUN, R...   \n",
       "22  [SYM, CONJ, RB, RB, RB, VB, CONJ, NOUN, DT, PR...   \n",
       "23  [Noun, Noun, SYM, PROPN, PROPN, RB, VB, VB, CC...   \n",
       "24  [RB, RB, DT, VB, PR, RB, CONJ, NOUN, IN, VB, C...   \n",
       "\n",
       "                                        specific_tags  \\\n",
       "0   [NNP, NNP, PMC, CCB, CCB, CDB, PMC, CDB, NN, N...   \n",
       "1   [VBAF, DTC, CDB, NNC_CCP, NNC, CCP, NNC, CCR, ...   \n",
       "2   [DTC, NNC, RBI, CCB, NNC, NN, DTP, NNP, CCT, D...   \n",
       "3   [RBW_CCP, RBW_CCP, NNP, PMC, PRI_CCP, NNC, CCP...   \n",
       "4   [NNP, RBM, DTC, VBTS, CCR, PRP, RBW, CCP, CCR,...   \n",
       "5   [CCR, CCR, VBTS, FW, DTC, JJN_CCP, NNC, CCP, P...   \n",
       "6   [RBT, RBW, RBW, FW, NNC_CCP, RBW, LM, VBAF, CC...   \n",
       "7   [RBW_CCP, PRP, LM, VBTS, NNP, NNPA, IN, CCR, C...   \n",
       "8   [PMS, VBTS, DTC, NNC, DTP, NNP, CCP, VBAF, CCT...   \n",
       "9   [RBR, DTP, NNP, NNP, NNP, NNP, NNP, PMC, NNC, ...   \n",
       "10  [RB, PRSP, DTC, NNP, NNP, PMC, CDB, NNC, RBI, ...   \n",
       "11  [JJC, CCB, NNC, CCB, PRSP_CCP, JJD, CCP, NNP_C...   \n",
       "12  [JJN_CCP, VBTS, DTC, JJ, FW, NN, CCT, NNP, RBW...   \n",
       "13  [DTC, FW, RBI, CCB, FW, PMC, CCP, PRC, PRI, RB...   \n",
       "14  [RBF, RBI, VBTS, DTC, NNC, CCT, VBW, CCT, VBTR...   \n",
       "15  [CCT, CCR, VBH, JJD, CCP, RBD_CCP, VBTR, CCT, ...   \n",
       "16  [VBTR, CCB, NNPA, DTC, NN, NN, NN, RBW, NNP, C...   \n",
       "17  [CCT, CCT, PRL, IN, NNP, PMC, VBTS, CCB, NNC, ...   \n",
       "18  [CCT, RBW, LM, JJCC, VBTS_VBOF, PRO, CCR, CCT,...   \n",
       "19  [PMS, CCT, CCT, JJ, NN, CCP, CCB, PRS, DTC, DT...   \n",
       "20  [VBTS, RBI, CCB, NNP, DTC, FW, CCT, VBTS, PRS_...   \n",
       "21  [PMS, IN, VBOF, RBI, PMC, RBW, NNC, CCP, NNC, ...   \n",
       "22  [PMS, CCT, RBF, RBI, RBI, VBTS, CCB, NNC, DTC,...   \n",
       "23  [NN, NN, PMS, NNPA, NNP, RBW, VBW, VBOF, CCP, ...   \n",
       "24  [RBD, RBI, DTC, VBW, PRS, RBI, CCT, NNC, IN, V...   \n",
       "\n",
       "                                         token_tagset  \n",
       "0   [MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...  \n",
       "1   [MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...  \n",
       "2   [MGNN, MGNN, MGNN, MGNN, MGNN, Flair, MGNN, MG...  \n",
       "3   [MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...  \n",
       "4   [MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...  \n",
       "5   [MGNN, MGNN, MGNN, Flair, MGNN, MGNN, MGNN, MG...  \n",
       "6   [MGNN, MGNN, MGNN, Flair, MGNN, MGNN, MGNN, MG...  \n",
       "7   [MGNN, MGNN, MGNN, MGNN, Flair, MGNN, Flair, M...  \n",
       "8   [MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...  \n",
       "9   [MGNN, MGNN, Flair, Flair, MGNN, MGNN, Flair, ...  \n",
       "10  [Flair, MGNN, MGNN, Flair, MGNN, MGNN, MGNN, M...  \n",
       "11  [MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...  \n",
       "12  [MGNN, MGNN, MGNN, Flair, MGNN, Flair, MGNN, M...  \n",
       "13  [MGNN, MGNN, MGNN, MGNN, Flair, MGNN, MGNN, MG...  \n",
       "14  [MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...  \n",
       "15  [MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...  \n",
       "16  [MGNN, MGNN, MGNN, MGNN, Flair, Flair, Flair, ...  \n",
       "17  [MGNN, MGNN, MGNN, Flair, Flair, MGNN, MGNN, M...  \n",
       "18  [MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...  \n",
       "19  [MGNN, MGNN, MGNN, Flair, Flair, MGNN, MGNN, M...  \n",
       "20  [MGNN, MGNN, MGNN, MGNN, MGNN, Flair, MGNN, MG...  \n",
       "21  [MGNN, Flair, MGNN, MGNN, MGNN, MGNN, MGNN, MG...  \n",
       "22  [MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...  \n",
       "23  [Flair, Flair, MGNN, MGNN, MGNN, MGNN, MGNN, M...  \n",
       "24  [MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGNN, MGN...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(tagged_texts_combi1)\n",
    "display(tagged_texts_combi2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfb7104",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = tag_string(\"Noong nakaraang Nobyembre , isang tuta na kakaiba rin ang hitsura ang isinilang naman sa Mati city .\")\n",
    "#test = tag_string(\"Pumanaw ang 65 taong gulang\")\n",
    "test = tag_string(input_sentence[1])\n",
    "print(test[2].get_item)\n",
    "test[0].__dir__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9fb4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(token_tagset)\n",
    "display(input_sentence[24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff40814",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tagged_texts_combi1['general_tags'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a99184b",
   "metadata": {},
   "source": [
    "# TO BE REMOVED EVERYTHING BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25537417",
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_variables(sample_text_pos_tags_general, sample_text_pos_tags_specific)\n",
    "reset_variables_combi2(sample_text_pos_tags_general_eng, sample_text_pos_tags_specific_eng,\n",
    "                       sample_text_pos_tags_general_fil, sample_text_pos_tags_specific_fil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b430bea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flair (English) pos tagging\n",
    "token_eng = eng_tagger(sample_text)\n",
    "\n",
    "for i in range(len(token_eng.get_labels('pos'))):\n",
    "    sample_text_pos_tags_general_eng.append(convert_eng(token_eng.get_labels('pos')[i].value))\n",
    "    sample_text_pos_tags_specific_eng.append(convert_eng(token_eng.get_labels('pos')[i].value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d6fb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FSPOST (Filipino) pos tagging\n",
    "sentence = nltk.word_tokenize(sample_text)\n",
    "sentence = join_string(sentence)\n",
    "token_fil = fil_tagger(sentence)\n",
    "\n",
    "for i in range(len(token_fil)):\n",
    "    sample_text_pos_tags_general_fil.append(convert_fil(token_fil[i][1]))\n",
    "    sample_text_pos_tags_specific_fil.append(convert_fil(token_fil[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9b1189",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Language identification model cannot identify punctuations or symbol.\n",
    "#Create a copy of the sentence without punctuations or symbols\n",
    "text_without_punc = sample_text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "#Tokenize the sample text without punctuation\n",
    "text_without_punc_tokenized = nltk.word_tokenize(text_without_punc)\n",
    "sample_text_tokenized = nltk.word_tokenize(sample_text)\n",
    "\n",
    "#IF ABOVE CODE HAS LOOKUP ERROR: RUN CODE ABOVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243032f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identifies the language of each tokens to determine which tagger to use\n",
    "for i in range(len(text_without_punc_tokenized)):\n",
    "    sample_text_langid.append(detector.detect_language_of(text_without_punc_tokenized[i]))\n",
    "    print(text_without_punc_tokenized[i], \": \", sample_text_langid[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9823a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0\n",
    "for i in range(len(sample_text_tokenized)):\n",
    "    if(sample_text_tokenized[i] == text_without_punc_tokenized[j]):\n",
    "        if(sample_text_langid[j] == Language.TAGALOG):\n",
    "            sample_text_pos_tags_general.append(sample_text_pos_tags_general_fil[i])\n",
    "            sample_text_pos_tags_specific.append(sample_text_pos_tags_specific_fil[i])\n",
    "            \n",
    "        elif(sample_text_langid[j] == Language.ENGLISH):\n",
    "            token = eng_tagger(text_without_punc_tokenized[j])\n",
    "            sample_text_pos_tags_general.append(convert_eng(token.get_labels('pos')[0].value))\n",
    "            sample_text_pos_tags_specific.append(token.get_labels('pos')[0].value)\n",
    "            \n",
    "        j = j + 1\n",
    "        \n",
    "        if(j == len(text_without_punc_tokenized)):\n",
    "            j = 0\n",
    "    else:\n",
    "        token = fil_tagger(sample_text_tokenized[i])\n",
    "        sample_text_pos_tags_general.append(sample_text_pos_tags_general_fil[i])\n",
    "        sample_text_pos_tags_specific.append(sample_text_pos_tags_specific_fil[i])\n",
    "        \n",
    "    print(sample_text_tokenized[i], \": General POS Tag -> \", sample_text_pos_tags_general[i], \" - Specific POS Tag -> \", sample_text_pos_tags_specific[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4442ce59",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample_text_pos_tags_specific)\n",
    "append_to_dataframe(sample_text, sample_text_pos_tags_general, sample_text_pos_tags_specific, tagged_texts_combi2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e269e0f",
   "metadata": {},
   "source": [
    "## DO NOT RUN ANYTHING BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac93f72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = Sentence(sample_text)\n",
    "#tagger.predict(test)\n",
    "\n",
    "test = eng_tagger(\"ako\")\n",
    "\n",
    "#print(test.get_labels('pos')[0])\n",
    "\n",
    "#print(test[0].get_labels('pos').value)\n",
    "\n",
    "label = test.get_labels('pos')[0].value\n",
    "print(test.get_labels('pos')[0].value)\n",
    "\n",
    "#for label in test.get_labels('pos'):\n",
    "    #print(label.value)\n",
    "    \n",
    "#print(test)\n",
    "#print(test.to_tagged_string())\n",
    "#for entity in test.get_spans('pos'):\n",
    "    #print(entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e7742b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = tag_string(sample_text)\n",
    "test = fil_tagger(sample_text)\n",
    "print(test[0])\n",
    "#print(dir(test2[0].__getattribute__('pos')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b296133",
   "metadata": {},
   "source": [
    "### Flair Testing (with FW tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22542e6",
   "metadata": {},
   "source": [
    "Import Flair and tagger to use (pos-english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53b2436",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "# gian was here\n",
    "# load tagger\n",
    "tagger = SequenceTagger.load(\"flair/pos-english\")\n",
    "#tagger = SequenceTagger.load(\"pos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24365057",
   "metadata": {},
   "source": [
    "Generate POS tags with infinite loop for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cddcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type C or c to cancel loop\n",
    "while True:\n",
    "    input_sentence = input(\"Enter sample sentence: \")\n",
    "    \n",
    "    if input_sentence == \"c\" or input_sentence == \"C\":\n",
    "        break\n",
    "        \n",
    "    sentence_test = Sentence(input_sentence)\n",
    "    tagger.predict(sentence_test)\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(sentence_test)\n",
    "    \n",
    "    \n",
    "    # print predicted NER spans\n",
    "    print('The following NER tags are found:')\n",
    "    # iterate over entities and print\n",
    "    for entity in sentence_test.get_spans('pos'):\n",
    "        print(entity)\n",
    "        \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73360371",
   "metadata": {},
   "source": [
    "### FSPOST (Go & Nocon, 2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31af9dcf",
   "metadata": {},
   "source": [
    "Use FSPOST pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fee2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "from nltk.tag.stanford import StanfordPOSTagger\n",
    "\n",
    "# These are Windows formatted directories\n",
    "#model = 'model//filipino-left5words-owlqn2-distsim-pref6-inf2.tagger'\n",
    "#jar = 'lib//stanford-postagger.jar'\n",
    "\n",
    "# These are Linux formatted directories\n",
    "model = 'model/filipino-left5words-owlqn2-distsim-pref6-inf2.tagger'\n",
    "jar = 'lib/stanford-postagger.jar'\n",
    "\n",
    "fspost = StanfordPOSTagger(model, path_to_jar=jar)  # Load Tagger Model\n",
    "fspost._SEPARATOR = '|'  # Set separator for proper tuple formatting (word, tag)\n",
    "\n",
    "def set_java_path(file_path):\n",
    "    \"\"\"\n",
    "    Function for setting java path to make Stanford POS Tagger work. Makes use of the 'os' library. Input \"\" to use\n",
    "    default java path, otherwise set the location.\n",
    "    Args:\n",
    "        file_path (str): The java file path / location.\n",
    "    \"\"\"\n",
    "    if file_path == \"\":\n",
    "        java_path = \"C:/Program Files/Java/jdk1.8.0_111/bin/java.exe\"\n",
    "        print(\"Java path set by default\")\n",
    "    else:\n",
    "        java_path = file_path\n",
    "        print(\"Java path set from given\")\n",
    "    os.environ['JAVAHOME'] = java_path\n",
    "\n",
    "def tag_string(sentence):\n",
    "    \"\"\"\n",
    "    Function for tagging a sentence/string. Output is a (word, pos) tuple. To output a POS-only string, enclose this\n",
    "    function with 'format_pos' function. Ex. fspost.format_pos(fspost.tag_string('this is a string')). Same goes for\n",
    "    Stanford's word|tag notation, use 'format_stanford' function.\n",
    "    Args:\n",
    "        sentence (str): The string to be tagged.\n",
    "    Returns:\n",
    "        tagged_string: a list of string tokens containing POS labeled (word, pos) tuples.\n",
    "    \"\"\"\n",
    "    tokens = sentence.split()  # Tokenize Sentence by whitespaces\n",
    "    # print(tokens)\n",
    "    tagged_string = fspost.tag(tokens)\n",
    "    return tagged_string\n",
    "\n",
    "def tag_string_list(sentence_list):\n",
    "    \"\"\"\n",
    "    Function for tagging a list of sentences. Output is a list of (word, pos) tuple. To output a POS-only string,\n",
    "    enclose the elements in this function with 'format_pos' function. Same goes for Stanford's word|tag notation, use\n",
    "    'format_stanford' function.\n",
    "    Args:\n",
    "        sentence_list (list): The list of strings to be tagged.\n",
    "    Returns:\n",
    "        tagged_list: a list of strings containing POS labelled (word, pos) tuples.\n",
    "    \"\"\"\n",
    "    progress_ctr = 0\n",
    "    tagged_list = []  # Initialize an empty list\n",
    "    for sentence in sentence_list:\n",
    "        tagged_tuple = tag_string(sentence)  # Tag each sentence in the list\n",
    "        tagged_list.append(tagged_tuple)  # Insert tagged sentence in the new list\n",
    "        progress_ctr += 1\n",
    "        print(progress_ctr, \"/\", len(sentence_list))  # Progress Counter\n",
    "    return tagged_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1212e2ad",
   "metadata": {},
   "source": [
    "[REQUIRED] Set JDK Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b94167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WINDOWS\n",
    "# set_java_path(\"C:/Program Files/Java/jdk-19/bin/java.exe\")\n",
    "\n",
    "# LINUX\n",
    "set_java_path(\"/usr/lib/jvm/java-11-openjdk-amd64/bin/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7625aa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type C or c to cancel loop\n",
    "while True:\n",
    "    input_sentence_mgnn = input(\"Enter sample sentence: \")\n",
    "    \n",
    "    if input_sentence_mgnn == \"c\" or input_sentence_mgnn == \"C\":\n",
    "        break\n",
    "        \n",
    "    print(tag_string(input_sentence_mgnn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff25f46f",
   "metadata": {},
   "source": [
    "## Get sample sentence from FilWordNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf8f173",
   "metadata": {},
   "source": [
    "Import FilWordNet Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345c408d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "filword_corpus = pd.read_csv(\"processed_corpus_oct_2022.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be099d0",
   "metadata": {},
   "source": [
    "Generate random string from FilWordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361ea3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gets the sentences with the source type online_forums, social_media, news_sites\n",
    "raw_sentences = filword_corpus[filword_corpus.source_type.isin(['online_forums', 'social_media', 'news_sites'])]\n",
    "\n",
    "#Drops the rows with a substring XX_...\n",
    "raw_sentences = raw_sentences.loc[~raw_sentences['text'].str.contains('XX_\\w{1,}')]\n",
    "#Drops the rows with a special character not included in ASCII dec 32-126\n",
    "sentences = raw_sentences.loc[~raw_sentences['text'].str.contains('[^\\x20-\\x7E]')]\n",
    "\n",
    "#Resets the index to start at 0. Since we removed some rows from the original data,\n",
    "#resetting the index must be performed\n",
    "sentences = sentences.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55807252",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "randInd = random.randrange(len(sentences))\n",
    "filword_randtext = sentences.text[randInd]\n",
    "\n",
    "print(filword_randtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9689d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make example sentence\n",
    "sentence = Sentence(filword_randtext)\n",
    "#AAAAAAAAA\n",
    "# Hello world!\n",
    "# predict NER tags\n",
    "tagger.predict(sentence)\n",
    "\n",
    "# print sentence\n",
    "print(sentence)\n",
    "\n",
    "# print predicted NER spans\n",
    "print('The following NER tags are found:')\n",
    "# iterate over entities and print\n",
    "for entity in sentence.get_spans('pos'):\n",
    "    print(entity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0683b590",
   "metadata": {},
   "source": [
    "## Combined POS Tagger - Combination 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7b5d57",
   "metadata": {},
   "source": [
    "### Language Identification then Monolingual Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c3c793",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37982c1c",
   "metadata": {},
   "source": [
    "## ENGPOSTs Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74afe353",
   "metadata": {},
   "source": [
    "### spaCy Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f79eda",
   "metadata": {},
   "source": [
    "Import spaCy and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bc3858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "spacy_nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d06aa3",
   "metadata": {},
   "source": [
    "Generate POS Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6fa3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_spacy(sentence):\n",
    "    \n",
    "    doc = spacy_nlp(sentence)\n",
    "    \n",
    "    for token in doc:\n",
    "        print(token, \": \", token.pos_, \": \", spacy.explain(token.pos_))\n",
    "\n",
    "print_spacy(filword_randtext)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f53130f",
   "metadata": {},
   "source": [
    "### NLTK Testing (default ENGPOST, with FW tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55fac8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "# [IMPORTANT] if this is your first time running this Python Notebook, run this:\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "\n",
    "text = word_tokenize(filword_randtext)\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0419175",
   "metadata": {},
   "source": [
    "## FILPOSTs Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a88f445",
   "metadata": {},
   "source": [
    "### LSTM Based Filipino POS Tagger (Cruz, 2020)  ***unfinished***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80e8745",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as datautils\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils.utils import predict, normalize, produce_vocab, proc_set, init_weights, accuracy\n",
    "from utils.model import LSTMTagger\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "def main():\n",
    "    '''\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--do_train', action='store_true', help='Train a part of speech tagger.')\n",
    "    parser.add_argument('--do_predict', action='store_true', help='Use a trained model to predict parts of speech.')\n",
    "    parser.add_argument('--seed', type=int, default=1234, help='Random seed.')\n",
    "    parser.add_argument('--checkpoint', type=str, default='checkpoint', help='Location to save model.')\n",
    "    parser.add_argument('--overwrite_save_directory', action='store_true', help='Overwrite the save directory if it exists.')\n",
    "\n",
    "    parser.add_argument('--train_data', type=str, help='Training text dataset.')\n",
    "    parser.add_argument('--evaluation_data', type=str, help='Evaluation text dataset.')\n",
    "    parser.add_argument('--train_tags', type=str, help='Training tags dataset.')\n",
    "    parser.add_argument('--evaluation_tags', type=str, help='Evaluation tags dataset.')\n",
    "    parser.add_argument('--no_cuda', action='store_true', help='Do not use a GPU.')\n",
    "    \n",
    "    parser.add_argument('--embedding_dim', type=int, default=300, help='Embedding dimension.')\n",
    "    parser.add_argument('--num_layers', type=int, default=1, help='Number of recurrent layers.')\n",
    "    parser.add_argument('--bidirectional', action='store_true', help='Use a bidirectional RNN.')\n",
    "    parser.add_argument('--hidden_dim', type=int, default=512, help='Hidden dimension.')\n",
    "    parser.add_argument('--dropout', type=float, default=0.5, help='Dropout probability.')\n",
    "    parser.add_argument('--recur_dropout', type=float, default=0.1, help='Recurrent dropout probability.')\n",
    "    parser.add_argument('--min_freq', type=int, default=1, help='Minimum frequency of words to be added to vocabulary.')\n",
    "    parser.add_argument('--msl', type=int, default=128, help='Maximum sequence length of text.')\n",
    "    parser.add_argument('--bs', type=int, default=128, help='Batch size.')\n",
    "    parser.add_argument('--learning_rate', type=float, default=3e-4, help='Learning rate.')\n",
    "    parser.add_argument('--weight_decay', type=float, default=0.0, help='Weight decay.')\n",
    "    parser.add_argument('--epochs', type=int, default=10, help='Number of epochs to train.')\n",
    "    parser.add_argument('--sentence', type=str, default='Hello', help='Sentence to predict')\n",
    "    '''\n",
    "    \n",
    "    # args = parser.parse_args()\n",
    "    torch.manual_seed(args.seed);\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    '''\n",
    "    if args.do_train:\n",
    "        # Load Dataset\n",
    "        print(\"Loading dataset\")\n",
    "        with open(args.train_data, 'r') as f:\n",
    "            train_words = [line.strip() for line in f]\n",
    "        with open(args.evaluation_data, 'r') as f:\n",
    "            test_words = [line.strip() for line in f]\n",
    "        with open(args.train_tags, 'r') as f:\n",
    "            train_tags = [line.strip() for line in f]\n",
    "        with open(args.evaluation_tags, 'r') as f:\n",
    "            test_tags = [line.strip() for line in f]\n",
    "\n",
    "        # Normalize text\n",
    "        print(\"Normalizing text and producing vocabularies.\")\n",
    "        train_words = [normalize(line) for line in train_words]\n",
    "        test_words = [normalize(line) for line in test_words]\n",
    "\n",
    "        # Produce vocabularies\n",
    "        word_vocab, idx2word, word2idx = produce_vocab(train_words, min_freq=args.min_freq)\n",
    "        tags_vocab, idx2tag, tag2idx  = produce_vocab(train_tags, min_freq=args.min_freq)\n",
    "        print(\"Training word vocabulary has {:,} unique tokens.\".format(len(word_vocab)))\n",
    "        print(\"Training tags vocabulary has {:,} unique tokens.\".format(len(tags_vocab)))\n",
    "\n",
    "        # Produce sets\n",
    "        X_train = proc_set(train_words, word2idx, word_vocab, msl=args.msl)\n",
    "        y_train = proc_set(train_tags , tag2idx,  tags_vocab,  msl=args.msl)\n",
    "        X_test = proc_set(test_words, word2idx, word_vocab, msl=args.msl)\n",
    "        y_test = proc_set(test_tags , tag2idx,  tags_vocab,  msl=args.msl)\n",
    "\n",
    "        # Convert to tensors\n",
    "        X_train, y_train = torch.LongTensor(X_train), torch.LongTensor(y_train)\n",
    "        X_test, y_test = torch.LongTensor(X_test), torch.LongTensor(y_test)\n",
    "\n",
    "        # Produce dataloaders\n",
    "        train_set = datautils.TensorDataset(X_train, y_train)\n",
    "        test_set = datautils.TensorDataset(X_test, y_test)\n",
    "        train_sampler = datautils.RandomSampler(train_set)\n",
    "        train_loader = datautils.DataLoader(train_set, sampler=train_sampler, batch_size=args.bs)\n",
    "        test_loader = datautils.DataLoader(test_set, shuffle=False, batch_size=args.bs)\n",
    "\n",
    "        print(\"Training batches: {}\\nEvaluation batches: {}\".format(len(train_loader), len(test_loader)))\n",
    "\n",
    "        # Training setup\n",
    "        model = LSTMTagger(word_vocab_sz=len(word_vocab), \n",
    "                           tag_vocab_sz=len(tags_vocab), \n",
    "                           embedding_dim=args.embedding_dim, \n",
    "                           hidden_dim=args.hidden_dim, \n",
    "                           dropout=args.dropout,\n",
    "                           num_layers=args.num_layers,\n",
    "                           recur_dropout=args.recur_dropout,\n",
    "                           bidirectional=args.bidirectional).to(device)\n",
    "        model.apply(init_weights)\n",
    "        criterion = nn.CrossEntropyLoss(ignore_index=tag2idx['<pad>'])\n",
    "        optimizer = optim.Adam(model.parameters(), lr=args.learning_rate, weight_decay=args.weight_decay)\n",
    "\n",
    "        print(\"Model has {:,} trainable parameters.\".format(sum(p.numel() for p in model.parameters() if p.requires_grad)))   \n",
    "\n",
    "        # Training\n",
    "        for e in range(1, args.epochs + 1):\n",
    "            model.train()\n",
    "            train_loss, train_acc = 0, 0\n",
    "            for x, y in tqdm(train_loader):\n",
    "                x, y = x.transpose(1, 0).to(device), y.transpose(1, 0).to(device)\n",
    "                out = model(x)\n",
    "                loss = criterion(out.flatten(0, 1), y.flatten(0))\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                train_acc += accuracy(out, y, tag2idx)\n",
    "            train_loss /= len(train_loader)\n",
    "            train_acc /= len(train_loader)\n",
    "\n",
    "            model.eval()\n",
    "            test_loss, test_acc = 0, 0\n",
    "            for x, y in tqdm(test_loader):\n",
    "                with torch.no_grad():\n",
    "                    x, y = x.transpose(1, 0).to(device), y.transpose(1, 0).to(device)\n",
    "                    out = model(x)\n",
    "                    loss = criterion(out.flatten(0, 1), y.flatten(0))\n",
    "                test_loss += loss.item()\n",
    "                test_acc += accuracy(out, y, tag2idx)\n",
    "            test_loss /= len(test_loader)\n",
    "            test_acc /= len(test_loader)\n",
    "\n",
    "            print(\"Epoch {:4} | Train Loss {:.4f} | Train Acc {:.2f}% | Test Loss {:.4f} | Test Acc {:.2f}%\".format(e, train_loss, train_acc, test_loss, test_acc))  \n",
    "        \n",
    "        # Save model\n",
    "        if args.overwrite_save_directory:\n",
    "            if os.path.exists(args.checkpoint): os.system('rm -r '+ args.checkpoint + '/')\n",
    "\n",
    "        print('Saving model and vocabularies.')\n",
    "        os.mkdir(args.checkpoint)\n",
    "        with open(args.checkpoint + '/model.bin', 'wb') as f:\n",
    "            torch.save(model.state_dict(), f)\n",
    "        with open(args.checkpoint + '/settings.bin', 'wb') as f:\n",
    "            torch.save([word_vocab, word2idx, idx2word, tags_vocab, tag2idx, idx2tag, args.msl, \n",
    "                        args.embedding_dim, args.hidden_dim, args.dropout, args.bidirectional, \n",
    "                        args.num_layers, args.recur_dropout], f)\n",
    "    '''\n",
    "    #if args.do_predict:\n",
    "        # Load the vocabularies\n",
    "    with open('checkpoint/settings.bin', 'rb') as f:\n",
    "        word_vocab, word2idx, idx2word, tags_vocab, tag2idx, idx2tag, msl, embedding_dim, hidden_dim, dropout, bidirectional, num_layers, recur_dropout = torch.load(f)\n",
    "\n",
    "        # Produce a blank model\n",
    "    model = LSTMTagger(word_vocab_sz=len(word_vocab), \n",
    "                        tag_vocab_sz=len(tags_vocab), \n",
    "                        embedding_dim=embedding_dim, \n",
    "                        hidden_dim=hidden_dim, \n",
    "                        dropout=dropout,\n",
    "                        num_layers=num_layers,\n",
    "                        recur_dropout=recur_dropout,\n",
    "                        bidirectional=bidirectional)\n",
    "\n",
    "    # Load checkpoints and put the model in eval mode\n",
    "    with open('checkpoint/model.bin', 'rb') as f:\n",
    "        model.load_state_dict(torch.load(f))\n",
    "    model = model.cpu()\n",
    "    model.eval();\n",
    "\n",
    "    preds = predict(args.sentence, word2idx, idx2tag, word_vocab, msl, model)\n",
    "    print(preds)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
