{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc8b4b7d",
   "metadata": {},
   "source": [
    "# Testing Different Monolingual Filipino and English Part of Speech (POS) Taggers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62008160",
   "metadata": {},
   "source": [
    "### PLEASE TAKE NOTE!!!\n",
    "- [IMPORTANT] Always refresh kernel, clear outputs, and save before exiting to avoid git conflicts\n",
    "- Current formatting of this .ipynb is not final, will reformat when testing sample data from FilWordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9a8e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lingua import Language, LanguageDetectorBuilder #used for language identification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfbc41b",
   "metadata": {},
   "source": [
    "Initialize language Identification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebb1186",
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = [Language.ENGLISH, Language.TAGALOG]\n",
    "detector = LanguageDetectorBuilder.from_languages(*languages).build()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7935269c",
   "metadata": {},
   "source": [
    "Initialize the dataframe that will hold the sentences and its pos tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e071b57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_format = {\n",
    "    \"text\": [],\n",
    "    \"general_tags\": [],\n",
    "    \"specific_tags\": [],\n",
    "    \"token_tagset\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d488a09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_texts_combi1_ff = pd.DataFrame(df_format)\n",
    "tagged_texts_combi2_ff = pd.DataFrame(df_format)\n",
    "\n",
    "tagged_texts_combi1_sf = pd.DataFrame(df_format)\n",
    "tagged_texts_combi2_sf = pd.DataFrame(df_format)\n",
    "\n",
    "display(tagged_texts_combi1_ff)\n",
    "display(tagged_texts_combi2_ff)\n",
    "\n",
    "display(tagged_texts_combi1_sf)\n",
    "display(tagged_texts_combi2_sf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c92704",
   "metadata": {},
   "source": [
    "## Loading the test data\n",
    "\n",
    "Let us load the .json input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcf2ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dataframe = pd.read_json(\"input_data_validated_cleaned_v2.json\")\n",
    "display(input_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e57ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_temp = []\n",
    "tags_temp = []\n",
    "input_sentence = []\n",
    "\n",
    "for i in range(len(input_dataframe)):\n",
    "    tokens_temp.clear()\n",
    "    tags_temp.clear()\n",
    "    \n",
    "    for j in range(input_dataframe.iloc[i].count()):\n",
    "        tokens_temp.append(input_dataframe.iloc[i][j].__getitem__(\"token\"))\n",
    "        tags_temp.append(input_dataframe.iloc[i][j].__getitem__(\"tag\"))\n",
    "        \n",
    "    sentence_temp = ' '.join([str(item) for item in tokens_temp])\n",
    "    \n",
    "    input_sentence.append(sentence_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c70e96d",
   "metadata": {},
   "source": [
    "## POS TAGGERS\n",
    "\n",
    "Let us import the monolingual taggers. Flair for english pos tagger and FSPOST for filipino pos tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd55134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FLAIR POS TAGGER\n",
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "flair_tagger = SequenceTagger.load(\"flair/pos-english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3df152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPACY POS TAGGER\n",
    "import spacy\n",
    "\n",
    "spacy_tagger = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d623e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FSPOST POS TAGGER\n",
    "import os\n",
    "from nltk.tag.stanford import StanfordPOSTagger\n",
    "\n",
    "# These are Windows formatted directories\n",
    "#model = 'model//filipino-left5words-owlqn2-distsim-pref6-inf2.tagger'\n",
    "#jar = 'lib//stanford-postagger.jar'\n",
    "\n",
    "# These are Linux formatted directories\n",
    "model = 'model/filipino-left5words-owlqn2-distsim-pref6-inf2.tagger'\n",
    "jar = 'lib/stanford-postagger.jar'\n",
    "\n",
    "fspost = StanfordPOSTagger(model, path_to_jar=jar)  # Load Tagger Model\n",
    "fspost._SEPARATOR = '|'  # Set separator for proper tuple formatting (word, tag)\n",
    "\n",
    "def set_java_path(file_path):\n",
    "    \"\"\"\n",
    "    Function for setting java path to make Stanford POS Tagger work. Makes use of the 'os' library. Input \"\" to use\n",
    "    default java path, otherwise set the location.\n",
    "    Args:\n",
    "        file_path (str): The java file path / location.\n",
    "    \"\"\"\n",
    "    if file_path == \"\":\n",
    "        java_path = \"C:/Program Files/Java/jdk1.8.0_111/bin/java.exe\"\n",
    "        print(\"Java path set by default\")\n",
    "    else:\n",
    "        java_path = file_path\n",
    "        print(\"Java path set from given\")\n",
    "    os.environ['JAVAHOME'] = java_path\n",
    "\n",
    "def tag_string(sentence):\n",
    "    \"\"\"\n",
    "    Function for tagging a sentence/string. Output is a (word, pos) tuple. To output a POS-only string, enclose this\n",
    "    function with 'format_pos' function. Ex. fspost.format_pos(fspost.tag_string('this is a string')). Same goes for\n",
    "    Stanford's word|tag notation, use 'format_stanford' function.\n",
    "    Args:\n",
    "        sentence (str): The string to be tagged.\n",
    "    Returns:\n",
    "        tagged_string: a list of string tokens containing POS labeled (word, pos) tuples.\n",
    "    \"\"\"\n",
    "    tokens = sentence.split()  # Tokenize Sentence by whitespaces\n",
    "    # print(tokens)\n",
    "    tagged_string = fspost.tag(tokens)\n",
    "    return tagged_string\n",
    "\n",
    "def tag_string_list(sentence_list):\n",
    "    \"\"\"\n",
    "    Function for tagging a list of sentences. Output is a list of (word, pos) tuple. To output a POS-only string,\n",
    "    enclose the elements in this function with 'format_pos' function. Same goes for Stanford's word|tag notation, use\n",
    "    'format_stanford' function.\n",
    "    Args:\n",
    "        sentence_list (list): The list of strings to be tagged.\n",
    "    Returns:\n",
    "        tagged_list: a list of strings containing POS labelled (word, pos) tuples.\n",
    "    \"\"\"\n",
    "    progress_ctr = 0\n",
    "    tagged_list = []  # Initialize an empty list\n",
    "    for sentence in sentence_list:\n",
    "        tagged_tuple = tag_string(sentence)  # Tag each sentence in the list\n",
    "        tagged_list.append(tagged_tuple)  # Insert tagged sentence in the new list\n",
    "        progress_ctr += 1\n",
    "        print(progress_ctr, \"/\", len(sentence_list))  # Progress Counter\n",
    "    return tagged_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fba20a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WINDOWS\n",
    "# set_java_path(\"C:/Program Files/Java/jdk-19/bin/java.exe\")\n",
    "\n",
    "# LINUX\n",
    "set_java_path(\"/usr/lib/jvm/java-11-openjdk-amd64/bin/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355279da",
   "metadata": {},
   "source": [
    "### Create functions to be used for POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea912637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the eng POS tag (Flair version)\n",
    "def eng_tagger_flair(input_string):\n",
    "    sentence = Sentence(input_string)\n",
    "    flair_tagger.predict(sentence)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a14812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eng_tagger_spacy(input_string):\n",
    "    return spacy_tagger(input_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb5edb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the fil POS tag\n",
    "def fil_tagger(input_string):\n",
    "    return tag_string(input_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e21d94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts the specific tag into generalized tag\n",
    "def convert_eng(pos_tag):\n",
    "    if(pos_tag == \"NN\" or pos_tag == \"NNS\"):\n",
    "        return \"NOUN\"\n",
    "    elif(pos_tag == \"NNP\" or pos_tag == \"NNPS\"):\n",
    "        return \"PROPN\"\n",
    "    elif(pos_tag == \"PRP\" or pos_tag == \"PRP$\" or pos_tag == \"WP\" or pos_tag == \"WP$\"):\n",
    "        return \"PR\"\n",
    "    elif(pos_tag == \"DT\" or pos_tag == \"WDT\"):\n",
    "        return \"DT\"\n",
    "    elif(pos_tag == \"CC\"):\n",
    "        return \"CONJ\"\n",
    "    elif(pos_tag == \"IN\"):\n",
    "        return \"IN\"\n",
    "    elif(pos_tag == \"VB\"):\n",
    "        return \"VB\"\n",
    "    elif(pos_tag == \"VBD\" or pos_tag == \"VBN\"):\n",
    "        return \"VBPT\"\n",
    "    elif(pos_tag == \"VBP\" or pos_tag == \"VBZ\" or pos_tag == \"VBG\"):\n",
    "        return \"VBPR\"\n",
    "    elif(pos_tag == \"JJ\" or pos_tag == \"JJR\" or pos_tag == \"JJS\"):\n",
    "        return \"JJ\"\n",
    "    elif(pos_tag == \"CD\"):\n",
    "        return \"CD\"\n",
    "    elif(pos_tag == \"RB\" or pos_tag == \"RBR\" or pos_tag == \"RBS\" or pos_tag == \"WRB\" or pos_tag == \"RP\"):\n",
    "        return \"RB\"\n",
    "    elif(pos_tag == \"UH\"):\n",
    "        return \"UH\"\n",
    "    elif(pos_tag == \"FW\"):\n",
    "        return \"FW\"\n",
    "    elif(pos_tag == \".\" or pos_tag == \",\" or pos_tag == \":\" or pos_tag == \"NFP\" or pos_tag == \"(\" or pos_tag == \")\"\n",
    "        or pos_tag == \"''\" or pos_tag == '\"\"' or pos_tag == \"``\" or pos_tag == \"`\" or pos_tag == \"-RRB-\"\n",
    "        or pos_tag == \"-LRB-\"):\n",
    "        return \"PUNC\"\n",
    "    elif(pos_tag == \"HYPH\" or pos_tag == \"SYM\" or pos_tag == \"$\" or pos_tag == \"\\\"\" or pos_tag == \"LS\"):\n",
    "        return \"SYM\"\n",
    "    else:\n",
    "        return pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04781d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts the specific tag into generalized tag\n",
    "def convert_fil(pos_tag):\n",
    "    if(pos_tag == \"NNC\" or pos_tag == \"NNCA\"):\n",
    "        return \"NOUN\"\n",
    "    elif(pos_tag == \"NNP\" or pos_tag == \"NNPA\"):\n",
    "        return \"PROPN\"\n",
    "    elif(pos_tag == \"PRS\" or pos_tag == \"PRP\" or pos_tag == \"PRSP\" or pos_tag == \"PRO\"\n",
    "        or pos_tag == \"PRQ\" or pos_tag == \"PRQP\" or pos_tag == \"PRL\" or pos_tag == \"PRC\"\n",
    "        or pos_tag == \"PRF\" or pos_tag == \"PRI\"):\n",
    "        return \"PR\"\n",
    "    elif(pos_tag == \"DTC\" or pos_tag == \"DTCP\" or pos_tag == \"DTP\" or pos_tag == \"DTPP\"):\n",
    "        return \"DT\"\n",
    "    elif(pos_tag == \"LM\"):\n",
    "        return \"LM\"\n",
    "    elif(pos_tag == \"CCT\" or pos_tag == \"CCR\" or pos_tag == \"CCB\" or pos_tag == \"CCA\"):\n",
    "        return \"CONJ\"\n",
    "    elif(pos_tag == \"CCP\"):\n",
    "        return \"CCP\"\n",
    "    elif(pos_tag == \"CCU\"):\n",
    "        return \"IN\"\n",
    "    elif(pos_tag == \"VBW\" or pos_tag == \"VBS\" or pos_tag == \"VBH\" or pos_tag == \"VBN\"\n",
    "        or pos_tag == \"VBAF\" or pos_tag == \"VBOF\" or pos_tag == \"VBOB\" or pos_tag == \"VBOL\"\n",
    "        or pos_tag == \"VBOI\" or pos_tag == \"VBRF\"):\n",
    "        return \"VB\"\n",
    "    elif(pos_tag == \"VBTS\" or pos_tag == \"VBTP\"):\n",
    "        return \"VBPT\"\n",
    "    elif(pos_tag == \"VBTR\"):\n",
    "        return \"VBPR\"\n",
    "    elif(pos_tag == \"VBTF\"):\n",
    "        return \"VBFT\"\n",
    "    elif(pos_tag == \"JJD\" or pos_tag == \"JJC\" or pos_tag == \"JJCC\" or pos_tag == \"JJCS\" or pos_tag == \"JJCN\"):\n",
    "        return \"JJ\"\n",
    "    elif(pos_tag == \"JJN\" or pos_tag == \"CDB\"):\n",
    "        return \"CD\"\n",
    "    elif(pos_tag == \"RBD\" or pos_tag == \"RBN\" or pos_tag == \"RBK\" or pos_tag == \"RBP\"\n",
    "        or pos_tag == \"RBB\" or pos_tag == \"RBR\" or pos_tag == \"RBQ\" or pos_tag == \"RBT\"\n",
    "        or pos_tag == \"RBF\" or pos_tag == \"RBW\" or pos_tag == \"RBM\" or pos_tag == \"RBL\"\n",
    "        or pos_tag == \"RBI\" or pos_tag == \"RBS\"):\n",
    "        return \"RB\"\n",
    "    elif(pos_tag == \"RBJ\"):\n",
    "        return \"UH\"\n",
    "    elif(pos_tag == \"FW\"):\n",
    "        return \"FW\"\n",
    "    elif(pos_tag == \"PMP\" or pos_tag == \"PME\" or pos_tag == \"PMQ\" or pos_tag == \"PMC\" or pos_tag == \"PMSC\"):\n",
    "        return \"PUNC\"\n",
    "    elif(pos_tag == \"PMS\"):\n",
    "        return \"SYM\"\n",
    "    else:\n",
    "        return pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61c509d",
   "metadata": {},
   "outputs": [],
   "source": [
    "langid = [] # will be used to store language id\n",
    "\n",
    "def reset_variables(general, specific, token_tagset):\n",
    "    #langid.clear()\n",
    "    general.clear()\n",
    "    specific.clear()\n",
    "    token_tagset.clear()\n",
    "    return\n",
    "\n",
    "def reset_variables_combi2(gen_eng, spec_eng, gen_fil, spec_fil):\n",
    "    gen_eng.clear()\n",
    "    spec_eng.clear()\n",
    "    gen_fil.clear()\n",
    "    spec_fil.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456baed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables to be used for Flair-FSPOST Tagger\n",
    "\n",
    "pos_tags_general_ff = [] # will be used to store generalized pos tags\n",
    "pos_tags_specific_ff = [] # will be used to store specific pos tags\n",
    "token_tagset_ff = [] # will be used to store the name of the tagset used for specific tags\n",
    "\n",
    "# Temporary lists to be used for combi 2\n",
    "pos_tags_general_eng_ff = []\n",
    "pos_tags_specific_eng_ff = []\n",
    "pos_tags_general_fil_ff = []\n",
    "pos_tags_specific_fil_ff = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854669e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables to be used for Spacy-FSPOST Tagger\n",
    "\n",
    "pos_tags_general_sf = [] # will be used to store generalized pos tags\n",
    "pos_tags_specific_sf = [] # will be used to store specific pos tags\n",
    "token_tagset_sf = [] # will be used to store the name of the tagset used for specific tags\n",
    "\n",
    "# Temporary lists to be used for combi 2\n",
    "pos_tags_general_eng_sf = []\n",
    "pos_tags_specific_eng_sf = []\n",
    "pos_tags_general_fil_sf = []\n",
    "pos_tags_specific_fil_sf = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a2d775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_to_dataframe(input_sentence, general_tags, specific_tags, tagset, tagged_texts):\n",
    "    #tagged_texts = tagged_texts.append({\"text\": input_sentence, \"general_tags\": np.array(general_tags),\n",
    "                                       # \"specific_tags\": np.array(specific_tags), \"token_tagset\": np.array(tagset)},\n",
    "                                       #ignore_index = True)\n",
    "    tagged_texts = pd.concat([tagged_texts, pd.DataFrame.from_records([{\"text\": input_sentence,\n",
    "                            \"general_tags\": np.array(general_tags), \"specific_tags\": np.array(specific_tags),\n",
    "                            \"token_tagset\": np.array(tagset)}])], ignore_index = True)\n",
    "    return tagged_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c8077c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_string(string_list):\n",
    "    return ' '.join([str(item) for item in string_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c41330a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9eb2527",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenized_text_with_punc(input_text):\n",
    "    input_text_tokenized = nltk.word_tokenize(input_text)\n",
    "    return input_text_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421acd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lang_per_token(text_wo_punc):\n",
    "    langid = []\n",
    "    #Identifies the language of each tokens to determine which tagger to use\n",
    "    for i in range(len(text_wo_punc)):\n",
    "        langid.append(detector.detect_language_of(text_wo_punc[i]))\n",
    "        \n",
    "    return langid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8672b887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_csv(dataframes, output_name):\n",
    "    dataframes['general_tags'] = dataframes['general_tags'].map(list)\n",
    "    dataframes['specific_tags'] = dataframes['specific_tags'].map(list)\n",
    "    dataframes['token_tagset'] = dataframes['token_tagset'].map(list)\n",
    "    dataframes.to_csv(output_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e28df50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isMultipleTags(tag):\n",
    "    if(tag.__contains__('_')):\n",
    "        new_tag = tag.split('_')\n",
    "        return new_tag[0]\n",
    "    else:\n",
    "        return tag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adc923d",
   "metadata": {},
   "source": [
    "## Language Identification then Monolingual Tagging (COMBI 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832f8934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lang_id_then_mono_tag(input_string):\n",
    "    \n",
    "    input_text_tokenized = tokenized_text_with_punc(input_string)\n",
    "    \n",
    "    # reset temporary variables\n",
    "    reset_variables(pos_tags_general_ff, pos_tags_specific_ff, token_tagset_ff) # Flair-FSPOST version\n",
    "    reset_variables(pos_tags_general_sf, pos_tags_specific_sf, token_tagset_sf) # Spacy-FSPOST version\n",
    "    \n",
    "    langid = get_lang_per_token(input_text_tokenized)\n",
    "    \n",
    "    for i in range(len(input_text_tokenized)):\n",
    "        if(langid[i] == Language.TAGALOG):\n",
    "            token = fil_tagger(input_text_tokenized[i])\n",
    "            new_token = isMultipleTags(token[0][1])\n",
    "            \n",
    "            # Flair-FSPOST dataframes\n",
    "            pos_tags_general_ff.append(convert_fil(new_token))\n",
    "            pos_tags_specific_ff.append(new_token)\n",
    "            token_tagset_ff.append(\"MGNN\")\n",
    "            \n",
    "            # Spacy-FSPOST dataframes\n",
    "            pos_tags_general_sf.append(convert_fil(new_token))\n",
    "            pos_tags_specific_sf.append(new_token)\n",
    "            token_tagset_sf.append(\"MGNN\")\n",
    "\n",
    "        elif(langid[i] == Language.ENGLISH):\n",
    "            \n",
    "            # Flair-FSPOST dataframes\n",
    "            token = eng_tagger_flair(input_text_tokenized[i])\n",
    "            new_token = isMultipleTags(token.get_labels('pos')[0].value)\n",
    "            pos_tags_general_ff.append(convert_eng(new_token))\n",
    "            pos_tags_specific_ff.append(new_token)\n",
    "            token_tagset_ff.append(\"Flair\")\n",
    "            \n",
    "             # Spacy-FSPOST dataframes\n",
    "            token = eng_tagger_spacy(input_text_tokenized[i])\n",
    "            new_token = isMultipleTags(token[0].tag_)\n",
    "            pos_tags_general_sf.append(convert_eng(new_token))\n",
    "            pos_tags_specific_sf.append(new_token)\n",
    "            token_tagset_sf.append(\"Spacy\")\n",
    "\n",
    "        else:\n",
    "            token = fil_tagger(input_text_tokenized[i])\n",
    "            new_token = isMultipleTags(token[0][1])\n",
    "            \n",
    "            # Flair-FSPOST dataframes\n",
    "            pos_tags_general_ff.append(convert_fil(new_token))\n",
    "            pos_tags_specific_ff.append(new_token)\n",
    "            token_tagset_ff.append(\"MGNN\")\n",
    "            \n",
    "            # Spacy-FSPOST dataframes\n",
    "            pos_tags_general_sf.append(convert_fil(new_token))\n",
    "            pos_tags_specific_sf.append(new_token)\n",
    "            token_tagset_sf.append(\"MGNN\")\n",
    "        \n",
    "    global tagged_texts_combi1_ff\n",
    "    temp = tagged_texts_combi1_ff\n",
    "    tagged_texts_combi1_ff = append_to_dataframe(input_string, pos_tags_general_ff,\n",
    "                                              pos_tags_specific_ff, token_tagset_ff, temp)\n",
    "    \n",
    "    global tagged_texts_combi1_sf\n",
    "    temp = tagged_texts_combi1_sf\n",
    "    tagged_texts_combi1_sf = append_to_dataframe(input_string, pos_tags_general_sf,\n",
    "                                                 pos_tags_specific_sf, token_tagset_sf, temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c795ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0\n",
    "for i in range(len(input_sentence)):\n",
    "    lang_id_then_mono_tag(input_sentence[i])\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(\"pass \", j)\n",
    "        j = j + 1\n",
    "display(tagged_texts_combi1_ff)\n",
    "display(tagged_texts_combi1_sf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68321ce3",
   "metadata": {},
   "source": [
    "## Monolingual Tagging then Language Identification (COMBI 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fcdfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mono_tag_then_lang_id(input_string):\n",
    "    # Resets temp variables FLair version\n",
    "    reset_variables(pos_tags_general_ff, pos_tags_specific_ff, token_tagset_ff)\n",
    "    reset_variables_combi2(pos_tags_general_eng_ff, pos_tags_specific_eng_ff,\n",
    "                           pos_tags_general_fil_ff, pos_tags_specific_fil_ff)\n",
    "    \n",
    "    # Resets temp variables Spacy version\n",
    "    reset_variables(pos_tags_general_sf, pos_tags_specific_sf, token_tagset_sf)\n",
    "    reset_variables_combi2(pos_tags_general_eng_sf, pos_tags_specific_eng_sf,\n",
    "                           pos_tags_general_fil_sf, pos_tags_specific_fil_sf)\n",
    "    \n",
    "    # Tokenized sentences\n",
    "    input_text_tokenized = tokenized_text_with_punc(input_string)\n",
    "    \n",
    "    # Flair (English) pos tagging\n",
    "    token_eng_flair = eng_tagger_flair(input_string)\n",
    "    # Spacy (English) pos tagging\n",
    "    token_eng_spacy = eng_tagger_spacy(input_string)\n",
    "    \n",
    "    # Store tags to temporary variables (ENGLISH - Flair Tagger)\n",
    "    for i in range(len(token_eng_flair.get_labels('pos'))):\n",
    "        new_token = isMultipleTags(token_eng_flair.get_labels('pos')[i].value)\n",
    "        pos_tags_general_eng_ff.append(convert_eng(new_token))\n",
    "        pos_tags_specific_eng_ff.append(new_token)\n",
    "        \n",
    "   # Store tags to temporary variables (ENGLISH - Spacy Tagger)\n",
    "    for i in range(len(token_eng_spacy)):\n",
    "        new_token = isMultipleTags(token_eng_spacy[i].tag_)\n",
    "        pos_tags_general_eng_sf.append(convert_eng(new_token))\n",
    "        pos_tags_specific_eng_sf.append(new_token)\n",
    "         \n",
    "        \n",
    "    # FSPOST (Filipino) pos tagging\n",
    "    token_fil = fil_tagger(input_string)\n",
    "    \n",
    "    # Store tags to temporary variables (FILIPINO Tagger)\n",
    "    for i in range(len(token_fil)):\n",
    "        new_token = isMultipleTags(token_fil[i][1])\n",
    "        \n",
    "        # Store filipino tags on Flair-FSPOST dataframe\n",
    "        pos_tags_general_fil_ff.append(convert_fil(new_token))\n",
    "        pos_tags_specific_fil_ff.append(new_token)\n",
    "        \n",
    "        # Store filipino tags on Spacy-FSPOST dataframe\n",
    "        pos_tags_general_fil_sf.append(convert_fil(new_token))\n",
    "        pos_tags_specific_fil_sf.append(new_token)\n",
    "    \n",
    "    # Get Languages per token ( Language Identification )\n",
    "    langid = get_lang_per_token(input_text_tokenized)\n",
    "    \n",
    "    for i in range(len(input_text_tokenized)):\n",
    "        if(langid[i] == Language.TAGALOG):\n",
    "            pos_tags_general_ff.append(pos_tags_general_fil_ff[i])\n",
    "            pos_tags_specific_ff.append(pos_tags_specific_fil_ff[i])\n",
    "            token_tagset_ff.append(\"MGNN\")\n",
    "            \n",
    "            pos_tags_general_sf.append(pos_tags_general_fil_sf[i])\n",
    "            pos_tags_specific_sf.append(pos_tags_specific_fil_sf[i])\n",
    "            token_tagset_sf.append(\"MGNN\")\n",
    "\n",
    "        elif(langid[i] == Language.ENGLISH):\n",
    "            pos_tags_general_ff.append(pos_tags_general_eng_ff[i])\n",
    "            pos_tags_specific_ff.append(pos_tags_specific_eng_ff[i])\n",
    "            token_tagset_ff.append(\"Flair\")\n",
    "            \n",
    "            pos_tags_general_sf.append(pos_tags_general_eng_sf[i])\n",
    "            pos_tags_specific_sf.append(pos_tags_specific_eng_sf[i])\n",
    "            token_tagset_sf.append(\"Spacy\")\n",
    "\n",
    "        else:\n",
    "            pos_tags_general_ff.append(pos_tags_general_fil_ff[i])\n",
    "            pos_tags_specific_ff.append(pos_tags_specific_fil_ff[i])\n",
    "            token_tagset_ff.append(\"MGNN\")\n",
    "            \n",
    "            pos_tags_general_sf.append(pos_tags_general_fil_sf[i])\n",
    "            pos_tags_specific_sf.append(pos_tags_specific_fil_sf[i])\n",
    "            token_tagset_sf.append(\"MGNN\")\n",
    "        \n",
    "        \n",
    "    global tagged_texts_combi2_ff\n",
    "    temp = tagged_texts_combi2_ff\n",
    "    tagged_texts_combi2_ff = append_to_dataframe(input_string, pos_tags_general_ff,\n",
    "                                              pos_tags_specific_ff, token_tagset_ff, temp)\n",
    "    \n",
    "    global tagged_texts_combi2_sf\n",
    "    temp = tagged_texts_combi2_sf\n",
    "    tagged_texts_combi2_sf = append_to_dataframe(input_string, pos_tags_general_sf,\n",
    "                                              pos_tags_specific_sf, token_tagset_sf, temp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e39498",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0\n",
    "for i in range(len(input_sentence)):\n",
    "    #try:\n",
    "    mono_tag_then_lang_id(input_sentence[i])\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(\"pass \", j)\n",
    "        j = j + 1\n",
    "            \n",
    "    #except:\n",
    "    #print(i, ': ', input_sentence[i])\n",
    "        \n",
    "display(tagged_texts_combi2_ff)\n",
    "display(tagged_texts_combi2_sf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370c3e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_to_csv(tagged_texts_combi1_ff, \"Flair-FSPOST-Combination-1.csv\")\n",
    "dataframe_to_csv(tagged_texts_combi2_ff, \"Flair-FSPOST-Combination-2.csv\")\n",
    "\n",
    "dataframe_to_csv(tagged_texts_combi1_sf, \"Spacy-FSPOST-Combination-1.csv\")\n",
    "dataframe_to_csv(tagged_texts_combi2_sf, \"Spacy-FSPOST-Combination-2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1ad85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(tagged_texts_combi1_ff)\n",
    "display(tagged_texts_combi2_ff)\n",
    "display(tagged_texts_combi1_sf)\n",
    "display(tagged_texts_combi2_sf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed55716",
   "metadata": {},
   "source": [
    "## Results evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df461cbb",
   "metadata": {},
   "source": [
    "Reading the output csv files of each combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c806a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_combi1_output = pd.read_csv(\"Flair-FSPOST-Combination-1.csv\")\n",
    "ff_combi2_output = pd.read_csv(\"Flair-FSPOST-Combination-2.csv\")\n",
    "sf_combi1_output = pd.read_csv(\"Spacy-FSPOST-Combination-1.csv\")\n",
    "sf_combi2_output = pd.read_csv(\"Spacy-FSPOST-Combination-2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3546072",
   "metadata": {},
   "source": [
    "### Declaring functions to be used for results evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53b6aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed_columns(output):\n",
    "    output['general_tags'] = output['general_tags'].apply(eval)\n",
    "    output['specific_tags'] = output['specific_tags'].apply(eval)\n",
    "    output['token_tagset'] = output['token_tagset'].apply(eval)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fbea9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_1D(series):\n",
    "    return pd.Series([x for _list in series for x in _list])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db483b09",
   "metadata": {},
   "source": [
    "### Taking the number of each POS tags per combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5011ee5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_combi1_output = fixed_columns(ff_combi1_output)\n",
    "ff_combi2_output = fixed_columns(ff_combi2_output)\n",
    "sf_combi1_output = fixed_columns(sf_combi1_output)\n",
    "sf_combi2_output = fixed_columns(sf_combi2_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3376a26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_combi1_tag_counts = to_1D(ff_combi1_output['general_tags']).value_counts()\n",
    "ff_combi1_total = ff_combi1_tag_counts.sum()\n",
    "\n",
    "ff_combi2_tag_counts = to_1D(ff_combi2_output['general_tags']).value_counts()\n",
    "ff_combi2_total = ff_combi2_tag_counts.sum()\n",
    "\n",
    "sf_combi1_tag_counts = to_1D(sf_combi1_output['general_tags']).value_counts()\n",
    "sf_combi1_total = sf_combi1_tag_counts.sum()\n",
    "\n",
    "sf_combi2_tag_counts = to_1D(sf_combi2_output['general_tags']).value_counts()\n",
    "sf_combi2_total = sf_combi2_tag_counts.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8378a1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tag_counts(tag_counts, total, tagger):\n",
    "    print(tag_counts)\n",
    "    print(tagger, \" total tokens: \", total, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bbf0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_tag_counts(ff_combi1_tag_counts, ff_combi1_total, \"Flair-FSPOST Combi1\")\n",
    "print_tag_counts(ff_combi2_tag_counts, ff_combi2_total, \"Flair-FSPOST Combi2\")\n",
    "print_tag_counts(sf_combi1_tag_counts, sf_combi1_total, \"Spacy-FSPOST Combi1\")\n",
    "print_tag_counts(sf_combi2_tag_counts, sf_combi2_total, \"Spacy-FSPOST Combi2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b644bbd8",
   "metadata": {},
   "source": [
    "### Taking overall accuracy of each combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee86b3e",
   "metadata": {},
   "source": [
    "Let us first read the correct tags from our input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a738610d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_temp = []\n",
    "tags_list = []\n",
    "\n",
    "for i in range(len(input_dataframe)):\n",
    "    pos_temp.clear()\n",
    "    \n",
    "    for j in range(input_dataframe.iloc[i].count()):\n",
    "        pos_temp.append(input_dataframe.iloc[i][j].__getitem__(\"tag\"))\n",
    "    \n",
    "    temp = np.array(pos_temp)\n",
    "    tags_list.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2538c9b4",
   "metadata": {},
   "source": [
    "Let us print the number of tags present in the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84d3bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_counts = to_1D(tags_list).value_counts()\n",
    "test_data_counts_total = test_data_counts.sum()\n",
    "\n",
    "print_tag_counts(test_data_counts, test_data_counts_total, \"Test data counts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1977ef08",
   "metadata": {},
   "source": [
    "Almost all POS tags in our tagset is present in our test data. Although ADD, PDT and AFX are missing in our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dffa70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_overall_accuracy(output):\n",
    "    accuracy = []\n",
    "    for i in range(len(tags_list)):\n",
    "        counter = 0\n",
    "        for j in range(len(tags_list[i])):\n",
    "            if tags_list[i][j] == 'VB':\n",
    "                if (output['general_tags'][i][j] == 'VB' or output['general_tags'][i][j] == 'VBPT' or\n",
    "                output['general_tags'][i][j] == 'VBPR' or output['general_tags'][i][j] == 'VBFT'):\n",
    "                    counter = counter + 1\n",
    "            elif tags_list[i][j] == output['general_tags'][i][j]:\n",
    "                counter = counter + 1\n",
    "                \n",
    "        accuracy.append(counter / len(tags_list[i]))\n",
    "        \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662a1cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_overall_accuracy(output, tagger):\n",
    "    accuracy = get_overall_accuracy(output)\n",
    "    print(tagger, ' accuracy: %f' % (sum(accuracy) / len(accuracy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ca2d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_overall_accuracy(ff_combi1_output, \"Flair-FSPOST Combi1\")\n",
    "print_overall_accuracy(sf_combi1_output, \"Spacy-FSPOST Combi1\")\n",
    "print_overall_accuracy(ff_combi2_output, \"Flair-FSPOST Combi2\")\n",
    "print_overall_accuracy(sf_combi2_output, \"Spacy-FSPOST Combi2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158fdab9",
   "metadata": {},
   "source": [
    "### Taking each pos tag accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8d3e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_tags = ['NOUN', 'PROPN', 'PR', 'DT', 'LM', 'CONJ', 'CCP', 'IN', 'VB', 'JJ', 'CD', 'RB', 'UH',\n",
    "                 'TS', 'FW', 'PUNC', 'SYM', 'EX', 'TO', 'ADD', 'POS', 'PDT', 'XX', 'MD', 'AFX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a03c74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_per_tags(output, tag):\n",
    "    counter_right = 0\n",
    "    counter_total = 0\n",
    "    for i in range(len(tags_list)):\n",
    "        for j in range(len(tags_list[i])):\n",
    "            if tags_list[i][j] == tag:\n",
    "                counter_total = counter_total + 1\n",
    "                if tags_list[i][j] == 'VB':\n",
    "                    if (output['general_tags'][i][j] == 'VB' or output['general_tags'][i][j] == 'VBPT' or\n",
    "                    output['general_tags'][i][j] == 'VBPR' or output['general_tags'][i][j] == 'VBFT'):\n",
    "                        counter_right = counter_right + 1\n",
    "                elif tags_list[i][j] == output['general_tags'][i][j]:\n",
    "                    counter_right = counter_right + 1\n",
    "    \n",
    "    if counter_total == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return counter_right / counter_total * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ef4a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_accuracy_per_tags(output, tagger):\n",
    "    print(\"Tagger: \", tagger)\n",
    "    for i in range(len(possible_tags)):\n",
    "        accuracy = get_accuracy_per_tags(output, possible_tags[i])\n",
    "        if accuracy != None:\n",
    "            print('POS Tag: ', possible_tags[i], ' accuracy: %f' % accuracy)\n",
    "            \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32901a2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print_accuracy_per_tags(ff_combi1_output, \"Flair-FSPOST Combi1\")\n",
    "print_accuracy_per_tags(sf_combi1_output, \"Spacy-FSPOST Combi1\")\n",
    "print_accuracy_per_tags(ff_combi2_output, \"Flair-FSPOST Combi2\")\n",
    "print_accuracy_per_tags(sf_combi2_output, \"Spacy-FSPOST Combi2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2ba98f",
   "metadata": {},
   "source": [
    "### Generating confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2d924e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1349c51f",
   "metadata": {},
   "source": [
    "Taking the actual and predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e410cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tags(tag_list, tag):\n",
    "    tags = []\n",
    "    \n",
    "    for i in range(len(tag_list)):\n",
    "        for j in range(len(tag_list[i])):\n",
    "            if tag_list[i][j] == tag:\n",
    "                tags.append(True)\n",
    "                \n",
    "            else:\n",
    "                tags.append(False)\n",
    "                \n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81847f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_confu_matrix(combi, top_tags):\n",
    "    actual_tags = []\n",
    "    predicted_tags = []\n",
    "\n",
    "    for i in range(len(top_tags)):\n",
    "        actual_tags = get_tags(tags_list, top_tags[i])\n",
    "        predicted_tags = get_tags(combi['general_tags'], top_tags[i])\n",
    "\n",
    "        confusion_matrix_ff_combi1 = metrics.confusion_matrix(actual_tags, predicted_tags)\n",
    "\n",
    "        cm_display_ff_combi1 = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix_ff_combi1, \n",
    "                                                          display_labels = [False, True])\n",
    "\n",
    "        cm_display_ff_combi1.plot()\n",
    "        plt.show()\n",
    "\n",
    "        accuracy = metrics.accuracy_score(actual_tags, predicted_tags)\n",
    "        precision = metrics.precision_score(actual_tags, predicted_tags)\n",
    "        specificity = metrics.recall_score(actual_tags, predicted_tags, pos_label = 0)\n",
    "        print(\"Accuracy: \", accuracy)\n",
    "        print(\"Precision: \", precision)\n",
    "        print(\"Specificity: \", specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e82cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_combi1_top_tags = ['CCP', 'NOUN']\n",
    "sf_combi1_top_tags = ['CCP', 'NOUN']\n",
    "ff_combi2_top_tags = ['CCP', 'NOUN']\n",
    "sf_combi2_top_tags = ['CCP', 'NOUN']\n",
    "\n",
    "generate_confu_matrix(ff_combi1_output, ff_combi1_top_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230b8754",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_confu_matrix(sf_combi1_output, sf_combi1_top_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05123096",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_confu_matrix(ff_combi2_output, ff_combi2_top_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6479db86",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_confu_matrix(sf_combi2_output, sf_combi2_top_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53a1c55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74671a29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
